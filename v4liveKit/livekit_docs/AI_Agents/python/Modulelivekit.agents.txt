================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/reference/python/v1/livekit/agents/index.html
Title: 
Crawled: 2025-11-01 21:08:02
================================================================================

LiveKit Agents for Python

See

https://docs.livekit.io/agents/

for quickstarts,

documentation, and examples.

Sub-modules

livekit.agents.beta

livekit.agents.cli

livekit.agents.inference

livekit.agents.ipc

livekit.agents.jupyter

livekit.agents.llm

livekit.agents.metrics

livekit.agents.resources

livekit.agents.stt

livekit.agents.tokenize

livekit.agents.tts

livekit.agents.utils

livekit.agents.vad

livekit.agents.voice

Functions

def

function_tool

(

f: F | Raw_F | None = None,

*,

name: str | None = None,

description: str | None = None,

raw_schema: RawFunctionDescription | dict[str, Any] | None = None) ‑> livekit.agents.llm.tool_context.FunctionTool | livekit.agents.llm.tool_context.RawFunctionTool | Callable[[~F], livekit.agents.llm.tool_context.FunctionTool] | Callable[[~Raw_F], livekit.agents.llm.tool_context.RawFunctionTool]

Expand source code

def function_tool(

f: F | Raw_F | None = None,

*,

name: str | None = None,

description: str | None = None,

raw_schema: RawFunctionDescription | dict[str, Any] | None = None,

) -> (

FunctionTool

| RawFunctionTool

| Callable[[F], FunctionTool]

| Callable[[Raw_F], RawFunctionTool]

):

def deco_raw(func: Raw_F) -> RawFunctionTool:

assert raw_schema is not None

if not raw_schema.get("name"):

raise ValueError("raw function name cannot be empty")

if "parameters" not in raw_schema:

# support empty parameters

raise ValueError("raw function description must contain a parameters key")

info = _RawFunctionToolInfo(raw_schema={**raw_schema}, name=raw_schema["name"])

setattr(func, "__livekit_raw_tool_info", info)

return cast(RawFunctionTool, func)

def deco_func(func: F) -> FunctionTool:

from docstring_parser import parse_from_object

docstring = parse_from_object(func)

info = _FunctionToolInfo(

name=name or func.__name__,

description=description or docstring.description,

)

setattr(func, "__livekit_tool_info", info)

return cast(FunctionTool, func)

if f is not None:

return deco_raw(cast(Raw_F, f)) if raw_schema is not None else deco_func(cast(F, f))

return deco_raw if raw_schema is not None else deco_func

def

get_job_context

(

) ‑> livekit.agents.job.JobContext

Expand source code

def get_job_context() -> JobContext:

ctx = _JobContextVar.get(None)

if ctx is None:

raise RuntimeError(

"no job context found, are you running this code inside a job entrypoint?"

)

return ctx

def

mock_tools

(

agent: type[

Agent

],

mocks: dict[str, Callable]) ‑> Generator[None, None, None]

Expand source code

@contextmanager

def mock_tools(agent: type[Agent], mocks: dict[str, Callable]) -> Generator[None, None, None]:

"""

Temporarily assign a set of mock tool callables to a specific Agent type within the current context.

Usage:

with mock_tools(MyAgentClass, {"tool_name": mock_fn}):

# inside this block, MyAgentClass will see the given mocks

"""  # noqa: E501

current = _MockToolsContextVar.get({})

updated = {**current, agent: mocks}  # create a new dict

token = _MockToolsContextVar.set(updated)

try:

yield

finally:

_MockToolsContextVar.reset(token)

Temporarily assign a set of mock tool callables to a specific Agent type within the current context.

Usage

with mock_tools(MyAgentClass, {"tool_name": mock_fn}):

# inside this block, MyAgentClass will see the given mocks

Classes

class

APIConnectOptions

(

max_retry: int = 3, retry_interval: float = 2.0, timeout: float = 10.0)

Expand source code

@dataclass(frozen=True)

class APIConnectOptions:

max_retry: int = 3

"""

Maximum number of retries to connect to the API.

"""

retry_interval: float = 2.0

"""

Interval between retries to connect to the API in seconds.

"""

timeout: float = 10.0

"""

Timeout for connecting to the API in seconds.

"""

def __post_init__(self) -> None:

if self.max_retry < 0:

raise ValueError("max_retry must be greater than or equal to 0")

if self.retry_interval < 0:

raise ValueError("retry_interval must be greater than or equal to 0")

if self.timeout < 0:

raise ValueError("timeout must be greater than or equal to 0")

def _interval_for_retry(self, num_retries: int) -> float:

"""

Return the interval for the given number of retries.

The first retry is immediate, and then uses specified retry_interval

"""

if num_retries == 0:

return 0.1

return self.retry_interval

APIConnectOptions(max_retry: int = 3, retry_interval: float = 2.0, timeout: float = 10.0)

Instance variables

var

max_retry

: int

Maximum number of retries to connect to the API.

var

retry_interval

: float

Interval between retries to connect to the API in seconds.

var

timeout

: float

Timeout for connecting to the API in seconds.

class

APIConnectionError

(

message: str = 'Connection error.', *, retryable: bool = True)

Expand source code

class APIConnectionError(APIError):

"""Raised when an API request failed due to a connection error."""

def __init__(self, message: str = "Connection error.", *, retryable: bool = True) -> None:

super().__init__(message, body=None, retryable=retryable)

Raised when an API request failed due to a connection error.

Ancestors

livekit.agents._exceptions.APIError

builtins.Exception

builtins.BaseException

Subclasses

livekit.agents._exceptions.APITimeoutError

class

APIError

(

message: str, *, body: object | None = None, retryable: bool = True)

Expand source code

class APIError(Exception):

"""Raised when an API request failed.

This is used on our TTS/STT/LLM plugins."""

message: str

"""

The error message returned by the API.

"""

body: object | None

"""The API response body, if available.

If the API returned a valid json, the body will contains

the decodede result.

"""

retryable: bool = False

"""Whether the error can be retried."""

def __init__(self, message: str, *, body: object | None = None, retryable: bool = True) -> None:

super().__init__(message)

self.message = message

self.body = body

self.retryable = retryable

def __str__(self) -> str:

return f"{self.message} (body={self.body}, retryable={self.retryable})"

Raised when an API request failed.

This is used on our TTS/STT/LLM plugins.

Ancestors

builtins.Exception

builtins.BaseException

Subclasses

livekit.agents._exceptions.APIConnectionError

livekit.agents._exceptions.APIStatusError

Class variables

var

body

: object | None

The API response body, if available.

If the API returned a valid json, the body will contains

the decodede result.

var

message

: str

The error message returned by the API.

var

retryable

: bool

Whether the error can be retried.

class

APIStatusError

(

message: str,

*,

status_code: int = -1,

request_id: str | None = None,

body: object | None = None,

retryable: bool | None = None)

Expand source code

class APIStatusError(APIError):

"""Raised when an API response has a status code of 4xx or 5xx."""

status_code: int

"""The status code of the API response."""

request_id: str | None

"""The request ID of the API response, if available."""

def __init__(

self,

message: str,

*,

status_code: int = -1,

request_id: str | None = None,

body: object | None = None,

retryable: bool | None = None,

) -> None:

if retryable is None:

retryable = True

# 4xx errors are not retryable

if status_code >= 400 and status_code < 500:

retryable = False

super().__init__(message, body=body, retryable=retryable)

self.status_code = status_code

self.request_id = request_id

def __str__(self) -> str:

return (

f"{self.message} "

f"(status_code={self.status_code}, "

f"request_id={self.request_id}, "

f"body={self.body}, "

f"retryable={self.retryable})"

)

Raised when an API response has a status code of 4xx or 5xx.

Ancestors

livekit.agents._exceptions.APIError

builtins.Exception

builtins.BaseException

Class variables

var

request_id

: str | None

The request ID of the API response, if available.

var

status_code

: int

The status code of the API response.

class

APITimeoutError

(

message: str = 'Request timed out.', *, retryable: bool = True)

Expand source code

class APITimeoutError(APIConnectionError):

"""Raised when an API request timed out."""

def __init__(self, message: str = "Request timed out.", *, retryable: bool = True) -> None:

super().__init__(message, retryable=retryable)

Raised when an API request timed out.

Ancestors

livekit.agents._exceptions.APIConnectionError

livekit.agents._exceptions.APIError

builtins.Exception

builtins.BaseException

class

Agent

(

*,

instructions: str,

chat_ctx: NotGivenOr[

ChatContext

| None] = NOT_GIVEN,

tools: list[

FunctionTool

|

RawFunctionTool

] | None = None,

turn_detection: NotGivenOr[TurnDetectionMode | None] = NOT_GIVEN,

stt: NotGivenOr[

STT

| STTModels | str | None] = NOT_GIVEN,

vad: NotGivenOr[

VAD

| None] = NOT_GIVEN,

llm: NotGivenOr[

LLM

|

RealtimeModel

| LLMModels | str | None] = NOT_GIVEN,

tts: NotGivenOr[

TTS

| TTSModels | str | None] = NOT_GIVEN,

mcp_servers: NotGivenOr[list[mcp.MCPServer] | None] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

min_consecutive_speech_delay: NotGivenOr[float] = NOT_GIVEN,

use_tts_aligned_transcript: NotGivenOr[bool] = NOT_GIVEN,

min_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

max_endpointing_delay: NotGivenOr[float] = NOT_GIVEN)

Expand source code

class Agent:

def __init__(

self,

*,

instructions: str,

chat_ctx: NotGivenOr[llm.ChatContext | None] = NOT_GIVEN,

tools: list[llm.FunctionTool | llm.RawFunctionTool] | None = None,

turn_detection: NotGivenOr[TurnDetectionMode | None] = NOT_GIVEN,

stt: NotGivenOr[stt.STT | STTModels | str | None] = NOT_GIVEN,

vad: NotGivenOr[vad.VAD | None] = NOT_GIVEN,

llm: NotGivenOr[llm.LLM | llm.RealtimeModel | LLMModels | str | None] = NOT_GIVEN,

tts: NotGivenOr[tts.TTS | TTSModels | str | None] = NOT_GIVEN,

mcp_servers: NotGivenOr[list[mcp.MCPServer] | None] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

min_consecutive_speech_delay: NotGivenOr[float] = NOT_GIVEN,

use_tts_aligned_transcript: NotGivenOr[bool] = NOT_GIVEN,

min_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

max_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

) -> None:

tools = tools or []

self._instructions = instructions

self._tools = tools.copy() + find_function_tools(self)

self._chat_ctx = chat_ctx.copy(tools=self._tools) if chat_ctx else ChatContext.empty()

self._turn_detection = turn_detection

if isinstance(stt, str):

stt = inference.STT.from_model_string(stt)

if isinstance(llm, str):

llm = inference.LLM.from_model_string(llm)

if isinstance(tts, str):

tts = inference.TTS.from_model_string(tts)

self._stt = stt

self._llm = llm

self._tts = tts

self._vad = vad

self._allow_interruptions = allow_interruptions

self._min_consecutive_speech_delay = min_consecutive_speech_delay

self._use_tts_aligned_transcript = use_tts_aligned_transcript

self._min_endpointing_delay = min_endpointing_delay

self._max_endpointing_delay = max_endpointing_delay

if isinstance(mcp_servers, list) and len(mcp_servers) == 0:

mcp_servers = None  # treat empty list as None (but keep NOT_GIVEN)

self._mcp_servers = mcp_servers

self._activity: AgentActivity | None = None

@property

def label(self) -> str:

"""

Returns:

str: The label of the agent.

"""

return f"{type(self).__module__}.{type(self).__name__}"

@property

def instructions(self) -> str:

"""

Returns:

str: The core instructions that guide the agent's behavior.

"""

return self._instructions

@property

def tools(self) -> list[llm.FunctionTool | llm.RawFunctionTool]:

"""

Returns:

list[llm.FunctionTool | llm.RawFunctionTool]:

A list of function tools available to the agent.

"""

return self._tools.copy()

@property

def chat_ctx(self) -> llm.ChatContext:

"""

Provides a read-only view of the agent's current chat context.

Returns:

llm.ChatContext: A read-only version of the agent's conversation history.

See Also:

update_chat_ctx: Method to update the internal chat context.

"""

return _ReadOnlyChatContext(self._chat_ctx.items)

async def update_instructions(self, instructions: str) -> None:

"""

Updates the agent's instructions.

If the agent is running in realtime mode, this method also updates

the instructions for the ongoing realtime session.

Args:

instructions (str):

The new instructions to set for the agent.

Raises:

llm.RealtimeError: If updating the realtime session instructions fails.

"""

if self._activity is None:

self._instructions = instructions

return

await self._activity.update_instructions(instructions)

async def update_tools(self, tools: list[llm.FunctionTool | llm.RawFunctionTool]) -> None:

"""

Updates the agent's available function tools.

If the agent is running in realtime mode, this method also updates

the tools for the ongoing realtime session.

Args:

tools (list[llm.FunctionTool]):

The new list of function tools available to the agent.

Raises:

llm.RealtimeError: If updating the realtime session tools fails.

"""

if self._activity is None:

self._tools = list(set(tools))

self._chat_ctx = self._chat_ctx.copy(tools=self._tools)

return

await self._activity.update_tools(tools)

async def update_chat_ctx(

self, chat_ctx: llm.ChatContext, *, exclude_invalid_function_calls: bool = True

) -> None:

"""

Updates the agent's chat context.

If the agent is running in realtime mode, this method also updates

the chat context for the ongoing realtime session.

Args:

chat_ctx (llm.ChatContext):

The new or updated chat context for the agent.

exclude_invalid_function_calls (bool): Whether to exclude function calls

and outputs not from the agent's tools.

Raises:

llm.RealtimeError: If updating the realtime session chat context fails.

"""

if self._activity is None:

self._chat_ctx = chat_ctx.copy(

tools=self._tools if exclude_invalid_function_calls else NOT_GIVEN

)

return

await self._activity.update_chat_ctx(

chat_ctx, exclude_invalid_function_calls=exclude_invalid_function_calls

)

# -- Pipeline nodes --

# They can all be overriden by subclasses, by default they use the STT/LLM/TTS specified in the

# constructor of the VoiceAgent

async def on_enter(self) -> None:

"""Called when the task is entered"""

pass

async def on_exit(self) -> None:

"""Called when the task is exited"""

pass

async def on_user_turn_completed(

self, turn_ctx: llm.ChatContext, new_message: llm.ChatMessage

) -> None:

"""Called when the user has finished speaking, and the LLM is about to respond

This is a good opportunity to update the chat context or edit the new message before it is

sent to the LLM.

"""

pass

def stt_node(

self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings

) -> (

AsyncIterable[stt.SpeechEvent | str]

| Coroutine[Any, Any, AsyncIterable[stt.SpeechEvent | str]]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that transcribes audio frames into speech events.

By default, this node uses a Speech-To-Text (STT) capability from the current agent.

If the STT implementation does not support streaming natively, a VAD (Voice Activity

Detection) mechanism is required to wrap the STT.

You can override this node with your own implementation for more flexibility (e.g.,

custom pre-processing of audio, additional buffering, or alternative STT strategies).

Args:

audio (AsyncIterable[rtc.AudioFrame]): An asynchronous stream of audio frames.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields:

stt.SpeechEvent: An event containing transcribed text or other STT-related data.

"""

return Agent.default.stt_node(self, audio, model_settings)

def llm_node(

self,

chat_ctx: llm.ChatContext,

tools: list[FunctionTool | RawFunctionTool],

model_settings: ModelSettings,

) -> (

AsyncIterable[llm.ChatChunk | str]

| Coroutine[Any, Any, AsyncIterable[llm.ChatChunk | str]]

| Coroutine[Any, Any, str]

| Coroutine[Any, Any, llm.ChatChunk]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that processes text generation with an LLM.

By default, this node uses the agent's LLM to process the provided context. It may yield

plain text (as `str`) for straightforward text generation, or `llm.ChatChunk` objects that

can include text and optional tool calls. `ChatChunk` is helpful for capturing more complex

outputs such as function calls, usage statistics, or other metadata.

You can override this node to customize how the LLM is used or how tool invocations

and responses are handled.

Args:

chat_ctx (llm.ChatContext): The context for the LLM (the conversation history).

tools (list[FunctionTool]): A list of callable tools that the LLM may invoke.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields/Returns:

str: Plain text output from the LLM.

llm.ChatChunk: An object that can contain both text and optional tool calls.

"""

return Agent.default.llm_node(self, chat_ctx, tools, model_settings)

def transcription_node(

self, text: AsyncIterable[str | TimedString], model_settings: ModelSettings

) -> (

AsyncIterable[str | TimedString]

| Coroutine[Any, Any, AsyncIterable[str | TimedString]]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that finalizes transcriptions from text segments.

This node can be used to adjust or post-process text coming from an LLM (or any other

source) into a final transcribed form. For instance, you might clean up formatting, fix

punctuation, or perform any other text transformations here.

You can override this node to customize post-processing logic according to your needs.

Args:

text (AsyncIterable[str | TimedString]): An asynchronous stream of text segments.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields:

str: Finalized or post-processed text segments.

"""

return Agent.default.transcription_node(self, text, model_settings)

def tts_node(

self, text: AsyncIterable[str], model_settings: ModelSettings

) -> (

AsyncIterable[rtc.AudioFrame]

| Coroutine[Any, Any, AsyncIterable[rtc.AudioFrame]]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that synthesizes audio from text segments.

By default, this node converts incoming text into audio frames using the Text-To-Speech

from the agent.

If the TTS implementation does not support streaming natively, it uses a sentence tokenizer

to split text for incremental synthesis.

You can override this node to provide different text chunking behavior, a custom TTS engine,

or any other specialized processing.

Args:

text (AsyncIterable[str]): An asynchronous stream of text segments to be synthesized.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields:

rtc.AudioFrame: Audio frames synthesized from the provided text.

"""

return Agent.default.tts_node(self, text, model_settings)

def realtime_audio_output_node(

self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings

) -> (

AsyncIterable[rtc.AudioFrame]

| Coroutine[Any, Any, AsyncIterable[rtc.AudioFrame]]

| Coroutine[Any, Any, None]

):

"""A node processing the audio from the realtime LLM session before it is played out."""

return Agent.default.realtime_audio_output_node(self, audio, model_settings)

def _get_activity_or_raise(self) -> AgentActivity:

"""Get the current activity context for this task (internal)"""

if self._activity is None:

raise RuntimeError("no activity context found, the agent is not running")

return self._activity

class default:

@staticmethod

async def stt_node(

agent: Agent, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings

) -> AsyncGenerator[stt.SpeechEvent, None]:

"""Default implementation for `Agent.stt_node`"""

activity = agent._get_activity_or_raise()

assert activity.stt is not None, "stt_node called but no STT node is available"

wrapped_stt = activity.stt

if not activity.stt.capabilities.streaming:

if not activity.vad:

raise RuntimeError(

f"The STT ({activity.stt.label}) does not support streaming, add a VAD to the AgentTask/VoiceAgent to enable streaming"  # noqa: E501

"Or manually wrap your STT in a stt.StreamAdapter"

)

wrapped_stt = stt.StreamAdapter(stt=wrapped_stt, vad=activity.vad)

conn_options = activity.session.conn_options.stt_conn_options

async with wrapped_stt.stream(conn_options=conn_options) as stream:

@utils.log_exceptions(logger=logger)

async def _forward_input() -> None:

async for frame in audio:

stream.push_frame(frame)

forward_task = asyncio.create_task(_forward_input())

try:

async for event in stream:

yield event

finally:

await utils.aio.cancel_and_wait(forward_task)

@staticmethod

async def llm_node(

agent: Agent,

chat_ctx: llm.ChatContext,

tools: list[FunctionTool | RawFunctionTool],

model_settings: ModelSettings,

) -> AsyncGenerator[llm.ChatChunk | str, None]:

"""Default implementation for `Agent.llm_node`"""

activity = agent._get_activity_or_raise()

assert activity.llm is not None, "llm_node called but no LLM node is available"

assert isinstance(activity.llm, llm.LLM), (

"llm_node should only be used with LLM (non-multimodal/realtime APIs) nodes"

)

tool_choice = model_settings.tool_choice if model_settings else NOT_GIVEN

activity_llm = activity.llm

conn_options = activity.session.conn_options.llm_conn_options

async with activity_llm.chat(

chat_ctx=chat_ctx, tools=tools, tool_choice=tool_choice, conn_options=conn_options

) as stream:

async for chunk in stream:

yield chunk

@staticmethod

async def tts_node(

agent: Agent, text: AsyncIterable[str], model_settings: ModelSettings

) -> AsyncGenerator[rtc.AudioFrame, None]:

"""Default implementation for `Agent.tts_node`"""

activity = agent._get_activity_or_raise()

assert activity.tts is not None, "tts_node called but no TTS node is available"

wrapped_tts = activity.tts

if not activity.tts.capabilities.streaming:

wrapped_tts = tts.StreamAdapter(

tts=wrapped_tts,

sentence_tokenizer=tokenize.blingfire.SentenceTokenizer(retain_format=True),

)

conn_options = activity.session.conn_options.tts_conn_options

async with wrapped_tts.stream(conn_options=conn_options) as stream:

async def _forward_input() -> None:

async for chunk in text:

stream.push_text(chunk)

stream.end_input()

forward_task = asyncio.create_task(_forward_input())

try:

async for ev in stream:

yield ev.frame

finally:

await utils.aio.cancel_and_wait(forward_task)

@staticmethod

async def transcription_node(

agent: Agent, text: AsyncIterable[str | TimedString], model_settings: ModelSettings

) -> AsyncGenerator[str | TimedString, None]:

"""Default implementation for `Agent.transcription_node`"""

async for delta in text:

yield delta

@staticmethod

async def realtime_audio_output_node(

agent: Agent, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings

) -> AsyncGenerator[rtc.AudioFrame, None]:

"""Default implementation for `Agent.realtime_audio_output_node`"""

activity = agent._get_activity_or_raise()

assert activity.realtime_llm_session is not None, (

"realtime_audio_output_node called but no realtime LLM session is available"

)

async for frame in audio:

yield frame

@property

def realtime_llm_session(self) -> llm.RealtimeSession:

"""

Retrieve the realtime LLM session associated with the current agent.

Raises:

RuntimeError: If the agent is not running or the realtime LLM session is not available

"""

if (rt_session := self._get_activity_or_raise().realtime_llm_session) is None:

raise RuntimeError("no realtime LLM session")

return rt_session

@property

def turn_detection(self) -> NotGivenOr[TurnDetectionMode | None]:

"""

Retrieves the turn detection mode for identifying conversational turns.

If this property was not set at Agent creation, but an ``AgentSession`` provides a turn detection,

the session's turn detection mode will be used at runtime instead.

Returns:

NotGivenOr[TurnDetectionMode | None]: An optional turn detection mode for managing conversation flow.

"""  # noqa: E501

return self._turn_detection

@property

def stt(self) -> NotGivenOr[stt.STT | None]:

"""

Retrieves the Speech-To-Text component for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides an STT component,

the session's STT will be used at runtime instead.

Returns:

NotGivenOr[stt.STT | None]: An optional STT component.

"""  # noqa: E501

return self._stt

@property

def llm(self) -> NotGivenOr[llm.LLM | llm.RealtimeModel | None]:

"""

Retrieves the Language Model or RealtimeModel used for text generation.

If this property was not set at Agent creation, but an ``AgentSession`` provides an LLM or RealtimeModel,

the session's model will be used at runtime instead.

Returns:

NotGivenOr[llm.LLM | llm.RealtimeModel | None]: The language model for text generation.

"""  # noqa: E501

return self._llm

@property

def tts(self) -> NotGivenOr[tts.TTS | None]:

"""

Retrieves the Text-To-Speech component for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides a TTS component,

the session's TTS will be used at runtime instead.

Returns:

NotGivenOr[tts.TTS | None]: An optional TTS component for generating audio output.

"""  # noqa: E501

return self._tts

@property

def mcp_servers(self) -> NotGivenOr[list[mcp.MCPServer] | None]:

"""

Retrieves the list of Model Context Protocol (MCP) servers providing external tools.

If this property was not set at Agent creation, but an ``AgentSession`` provides MCP servers,

the session's MCP servers will be used at runtime instead.

Returns:

NotGivenOr[list[mcp.MCPServer]]: An optional list of MCP servers.

"""  # noqa: E501

return self._mcp_servers

@property

def vad(self) -> NotGivenOr[vad.VAD | None]:

"""

Retrieves the Voice Activity Detection component for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides a VAD component,

the session's VAD will be used at runtime instead.

Returns:

NotGivenOr[vad.VAD | None]: An optional VAD component for detecting voice activity.

"""  # noqa: E501

return self._vad

@property

def allow_interruptions(self) -> NotGivenOr[bool]:

"""

Indicates whether interruptions (e.g., stopping TTS playback) are allowed.

If this property was not set at Agent creation, but an ``AgentSession`` provides a value for

allowing interruptions, the session's value will be used at runtime instead.

Returns:

NotGivenOr[bool]: Whether interruptions are permitted.

"""

return self._allow_interruptions

@property

def min_endpointing_delay(self) -> NotGivenOr[float]:

"""

Minimum time-in-seconds the agent must wait after a potential end-of-utterance signal

before it declares the user’s turn complete.

If this property was set at Agent creation, it will be used at runtime instead of the session's value.

"""

return self._min_endpointing_delay

@property

def max_endpointing_delay(self) -> NotGivenOr[float]:

"""

Maximum time-in-seconds the agent will wait before terminating the turn.

If this property was set at Agent creation, it will be used at runtime instead of the session's value.

"""

return self._max_endpointing_delay

@property

def min_consecutive_speech_delay(self) -> NotGivenOr[float]:

"""

Retrieves the minimum consecutive speech delay for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides a value for

the minimum consecutive speech delay, the session's value will be used at runtime instead.

Returns:

NotGivenOr[float]: The minimum consecutive speech delay.

"""

return self._min_consecutive_speech_delay

@property

def use_tts_aligned_transcript(self) -> NotGivenOr[bool]:

"""

Indicates whether to use TTS-aligned transcript as the input of

the ``transcription_node``.

If this property was not set at Agent creation, but an ``AgentSession`` provides a value for

the use of TTS-aligned transcript, the session's value will be used at runtime instead.

Returns:

NotGivenOr[bool]: Whether to use TTS-aligned transcript.

"""

return self._use_tts_aligned_transcript

@property

def session(self) -> AgentSession:

"""

Retrieve the VoiceAgent associated with the current agent.

Raises:

RuntimeError: If the agent is not running

"""

return self._get_activity_or_raise().session

Subclasses

livekit.agents.voice.agent.AgentTask

Class variables

var

default

Instance variables

prop

allow_interruptions

: NotGivenOr[bool]

Expand source code

@property

def allow_interruptions(self) -> NotGivenOr[bool]:

"""

Indicates whether interruptions (e.g., stopping TTS playback) are allowed.

If this property was not set at Agent creation, but an ``AgentSession`` provides a value for

allowing interruptions, the session's value will be used at runtime instead.

Returns:

NotGivenOr[bool]: Whether interruptions are permitted.

"""

return self._allow_interruptions

Indicates whether interruptions (e.g., stopping TTS playback) are allowed.

If this property was not set at Agent creation, but an

AgentSession

provides a value for

allowing interruptions, the session's value will be used at runtime instead.

Returns

NotGivenOr[bool]

Whether interruptions are permitted.

prop

chat_ctx

:

ChatContext

Expand source code

@property

def chat_ctx(self) -> llm.ChatContext:

"""

Provides a read-only view of the agent's current chat context.

Returns:

llm.ChatContext: A read-only version of the agent's conversation history.

See Also:

update_chat_ctx: Method to update the internal chat context.

"""

return _ReadOnlyChatContext(self._chat_ctx.items)

Provides a read-only view of the agent's current chat context.

Returns

ChatContext

A read-only version of the agent's conversation history.

See Also:

update_chat_ctx: Method to update the internal chat context.

prop

instructions

: str

Expand source code

@property

def instructions(self) -> str:

"""

Returns:

str: The core instructions that guide the agent's behavior.

"""

return self._instructions

Returns

str

The core instructions that guide the agent's behavior.

prop

label

: str

Expand source code

@property

def label(self) -> str:

"""

Returns:

str: The label of the agent.

"""

return f"{type(self).__module__}.{type(self).__name__}"

Returns

str

The label of the agent.

prop

llm

: NotGivenOr[

LLM

|

RealtimeModel

| None]

Expand source code

@property

def llm(self) -> NotGivenOr[llm.LLM | llm.RealtimeModel | None]:

"""

Retrieves the Language Model or RealtimeModel used for text generation.

If this property was not set at Agent creation, but an ``AgentSession`` provides an LLM or RealtimeModel,

the session's model will be used at runtime instead.

Returns:

NotGivenOr[llm.LLM | llm.RealtimeModel | None]: The language model for text generation.

"""  # noqa: E501

return self._llm

Retrieves the Language Model or RealtimeModel used for text generation.

If this property was not set at Agent creation, but an

AgentSession

provides an LLM or RealtimeModel,

the session's model will be used at runtime instead.

Returns

NotGivenOr[llm.LLM | llm.RealtimeModel | None]

The language model for text generation.

prop

max_endpointing_delay

: NotGivenOr[float]

Expand source code

@property

def max_endpointing_delay(self) -> NotGivenOr[float]:

"""

Maximum time-in-seconds the agent will wait before terminating the turn.

If this property was set at Agent creation, it will be used at runtime instead of the session's value.

"""

return self._max_endpointing_delay

Maximum time-in-seconds the agent will wait before terminating the turn.

If this property was set at Agent creation, it will be used at runtime instead of the session's value.

prop

mcp_servers

: NotGivenOr[list[mcp.MCPServer] | None]

Expand source code

@property

def mcp_servers(self) -> NotGivenOr[list[mcp.MCPServer] | None]:

"""

Retrieves the list of Model Context Protocol (MCP) servers providing external tools.

If this property was not set at Agent creation, but an ``AgentSession`` provides MCP servers,

the session's MCP servers will be used at runtime instead.

Returns:

NotGivenOr[list[mcp.MCPServer]]: An optional list of MCP servers.

"""  # noqa: E501

return self._mcp_servers

Retrieves the list of Model Context Protocol (MCP) servers providing external tools.

If this property was not set at Agent creation, but an

AgentSession

provides MCP servers,

the session's MCP servers will be used at runtime instead.

Returns

NotGivenOr[list[mcp.MCPServer]]

An optional list of MCP servers.

prop

min_consecutive_speech_delay

: NotGivenOr[float]

Expand source code

@property

def min_consecutive_speech_delay(self) -> NotGivenOr[float]:

"""

Retrieves the minimum consecutive speech delay for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides a value for

the minimum consecutive speech delay, the session's value will be used at runtime instead.

Returns:

NotGivenOr[float]: The minimum consecutive speech delay.

"""

return self._min_consecutive_speech_delay

Retrieves the minimum consecutive speech delay for the agent.

If this property was not set at Agent creation, but an

AgentSession

provides a value for

the minimum consecutive speech delay, the session's value will be used at runtime instead.

Returns

NotGivenOr[float]

The minimum consecutive speech delay.

prop

min_endpointing_delay

: NotGivenOr[float]

Expand source code

@property

def min_endpointing_delay(self) -> NotGivenOr[float]:

"""

Minimum time-in-seconds the agent must wait after a potential end-of-utterance signal

before it declares the user’s turn complete.

If this property was set at Agent creation, it will be used at runtime instead of the session's value.

"""

return self._min_endpointing_delay

Minimum time-in-seconds the agent must wait after a potential end-of-utterance signal

before it declares the user’s turn complete.

If this property was set at Agent creation, it will be used at runtime instead of the session's value.

prop

realtime_llm_session

:

RealtimeSession

Expand source code

@property

def realtime_llm_session(self) -> llm.RealtimeSession:

"""

Retrieve the realtime LLM session associated with the current agent.

Raises:

RuntimeError: If the agent is not running or the realtime LLM session is not available

"""

if (rt_session := self._get_activity_or_raise().realtime_llm_session) is None:

raise RuntimeError("no realtime LLM session")

return rt_session

Retrieve the realtime LLM session associated with the current agent.

Raises

RuntimeError

If the agent is not running or the realtime LLM session is not available

prop

session

:

AgentSession

Expand source code

@property

def session(self) -> AgentSession:

"""

Retrieve the VoiceAgent associated with the current agent.

Raises:

RuntimeError: If the agent is not running

"""

return self._get_activity_or_raise().session

Retrieve the VoiceAgent associated with the current agent.

Raises

RuntimeError

If the agent is not running

prop

stt

: NotGivenOr[

STT

| None]

Expand source code

@property

def stt(self) -> NotGivenOr[stt.STT | None]:

"""

Retrieves the Speech-To-Text component for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides an STT component,

the session's STT will be used at runtime instead.

Returns:

NotGivenOr[stt.STT | None]: An optional STT component.

"""  # noqa: E501

return self._stt

Retrieves the Speech-To-Text component for the agent.

If this property was not set at Agent creation, but an

AgentSession

provides an STT component,

the session's STT will be used at runtime instead.

Returns

NotGivenOr[stt.STT | None]

An optional STT component.

prop

tools

: list[

FunctionTool

|

RawFunctionTool

]

Expand source code

@property

def tools(self) -> list[llm.FunctionTool | llm.RawFunctionTool]:

"""

Returns:

list[llm.FunctionTool | llm.RawFunctionTool]:

A list of function tools available to the agent.

"""

return self._tools.copy()

Returns

list[llm.FunctionTool | llm.RawFunctionTool]:

A list of function tools available to the agent.

prop

tts

: NotGivenOr[

TTS

| None]

Expand source code

@property

def tts(self) -> NotGivenOr[tts.TTS | None]:

"""

Retrieves the Text-To-Speech component for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides a TTS component,

the session's TTS will be used at runtime instead.

Returns:

NotGivenOr[tts.TTS | None]: An optional TTS component for generating audio output.

"""  # noqa: E501

return self._tts

Retrieves the Text-To-Speech component for the agent.

If this property was not set at Agent creation, but an

AgentSession

provides a TTS component,

the session's TTS will be used at runtime instead.

Returns

NotGivenOr[tts.TTS | None]

An optional TTS component for generating audio output.

prop

turn_detection

: NotGivenOr[TurnDetectionMode | None]

Expand source code

@property

def turn_detection(self) -> NotGivenOr[TurnDetectionMode | None]:

"""

Retrieves the turn detection mode for identifying conversational turns.

If this property was not set at Agent creation, but an ``AgentSession`` provides a turn detection,

the session's turn detection mode will be used at runtime instead.

Returns:

NotGivenOr[TurnDetectionMode | None]: An optional turn detection mode for managing conversation flow.

"""  # noqa: E501

return self._turn_detection

Retrieves the turn detection mode for identifying conversational turns.

If this property was not set at Agent creation, but an

AgentSession

provides a turn detection,

the session's turn detection mode will be used at runtime instead.

Returns

NotGivenOr[TurnDetectionMode | None]

An optional turn detection mode for managing conversation flow.

prop

use_tts_aligned_transcript

: NotGivenOr[bool]

Expand source code

@property

def use_tts_aligned_transcript(self) -> NotGivenOr[bool]:

"""

Indicates whether to use TTS-aligned transcript as the input of

the ``transcription_node``.

If this property was not set at Agent creation, but an ``AgentSession`` provides a value for

the use of TTS-aligned transcript, the session's value will be used at runtime instead.

Returns:

NotGivenOr[bool]: Whether to use TTS-aligned transcript.

"""

return self._use_tts_aligned_transcript

Indicates whether to use TTS-aligned transcript as the input of

the

transcription_node

.

If this property was not set at Agent creation, but an

AgentSession

provides a value for

the use of TTS-aligned transcript, the session's value will be used at runtime instead.

Returns

NotGivenOr[bool]

Whether to use TTS-aligned transcript.

prop

vad

: NotGivenOr[

VAD

| None]

Expand source code

@property

def vad(self) -> NotGivenOr[vad.VAD | None]:

"""

Retrieves the Voice Activity Detection component for the agent.

If this property was not set at Agent creation, but an ``AgentSession`` provides a VAD component,

the session's VAD will be used at runtime instead.

Returns:

NotGivenOr[vad.VAD | None]: An optional VAD component for detecting voice activity.

"""  # noqa: E501

return self._vad

Retrieves the Voice Activity Detection component for the agent.

If this property was not set at Agent creation, but an

AgentSession

provides a VAD component,

the session's VAD will be used at runtime instead.

Returns

NotGivenOr[vad.VAD | None]

An optional VAD component for detecting voice activity.

Methods

def

llm_node

(

self,

chat_ctx:

ChatContext

,

tools: list[

FunctionTool

| RawFunctionTool],

model_settings:

ModelSettings

) ‑> collections.abc.AsyncIterable[livekit.agents.llm.llm.ChatChunk | str] | collections.abc.Coroutine[typing.Any, typing.Any, collections.abc.AsyncIterable[livekit.agents.llm.llm.ChatChunk | str]] | collections.abc.Coroutine[typing.Any, typing.Any, str] | collections.abc.Coroutine[typing.Any, typing.Any, livekit.agents.llm.llm.ChatChunk] | collections.abc.Coroutine[typing.Any, typing.Any, None]

Expand source code

def llm_node(

self,

chat_ctx: llm.ChatContext,

tools: list[FunctionTool | RawFunctionTool],

model_settings: ModelSettings,

) -> (

AsyncIterable[llm.ChatChunk | str]

| Coroutine[Any, Any, AsyncIterable[llm.ChatChunk | str]]

| Coroutine[Any, Any, str]

| Coroutine[Any, Any, llm.ChatChunk]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that processes text generation with an LLM.

By default, this node uses the agent's LLM to process the provided context. It may yield

plain text (as `str`) for straightforward text generation, or `llm.ChatChunk` objects that

can include text and optional tool calls. `ChatChunk` is helpful for capturing more complex

outputs such as function calls, usage statistics, or other metadata.

You can override this node to customize how the LLM is used or how tool invocations

and responses are handled.

Args:

chat_ctx (llm.ChatContext): The context for the LLM (the conversation history).

tools (list[FunctionTool]): A list of callable tools that the LLM may invoke.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields/Returns:

str: Plain text output from the LLM.

llm.ChatChunk: An object that can contain both text and optional tool calls.

"""

return Agent.default.llm_node(self, chat_ctx, tools, model_settings)

A node in the processing pipeline that processes text generation with an LLM.

By default, this node uses the agent's LLM to process the provided context. It may yield

plain text (as

str

) for straightforward text generation, or

ChatChunk

objects that

can include text and optional tool calls.

ChatChunk

is helpful for capturing more complex

outputs such as function calls, usage statistics, or other metadata.

You can override this node to customize how the LLM is used or how tool invocations

and responses are handled.

Args

chat_ctx

:

ChatContext

The context for the LLM (the conversation history).

tools

:

list[

FunctionTool

]

A list of callable tools that the LLM may invoke.

model_settings

:

ModelSettings

Configuration and parameters for model execution.

Yields/Returns:

str: Plain text output from the LLM.

llm.ChatChunk: An object that can contain both text and optional tool calls.

async def

on_enter

(

self) ‑> None

Expand source code

async def on_enter(self) -> None:

"""Called when the task is entered"""

pass

Called when the task is entered

async def

on_exit

(

self) ‑> None

Expand source code

async def on_exit(self) -> None:

"""Called when the task is exited"""

pass

Called when the task is exited

async def

on_user_turn_completed

(

self,

turn_ctx:

ChatContext

,

new_message:

ChatMessage

) ‑> None

Expand source code

async def on_user_turn_completed(

self, turn_ctx: llm.ChatContext, new_message: llm.ChatMessage

) -> None:

"""Called when the user has finished speaking, and the LLM is about to respond

This is a good opportunity to update the chat context or edit the new message before it is

sent to the LLM.

"""

pass

Called when the user has finished speaking, and the LLM is about to respond

This is a good opportunity to update the chat context or edit the new message before it is

sent to the LLM.

def

realtime_audio_output_node

(

self,

audio: AsyncIterable[rtc.AudioFrame],

model_settings:

ModelSettings

) ‑> collections.abc.AsyncIterable[

AudioFrame

] | collections.abc.Coroutine[typing.Any, typing.Any, collections.abc.AsyncIterable[

AudioFrame

]] | collections.abc.Coroutine[typing.Any, typing.Any, None]

Expand source code

def realtime_audio_output_node(

self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings

) -> (

AsyncIterable[rtc.AudioFrame]

| Coroutine[Any, Any, AsyncIterable[rtc.AudioFrame]]

| Coroutine[Any, Any, None]

):

"""A node processing the audio from the realtime LLM session before it is played out."""

return Agent.default.realtime_audio_output_node(self, audio, model_settings)

A node processing the audio from the realtime LLM session before it is played out.

def

stt_node

(

self,

audio: AsyncIterable[rtc.AudioFrame],

model_settings:

ModelSettings

) ‑> collections.abc.AsyncIterable[livekit.agents.stt.stt.SpeechEvent | str] | collections.abc.Coroutine[typing.Any, typing.Any, collections.abc.AsyncIterable[livekit.agents.stt.stt.SpeechEvent | str]] | collections.abc.Coroutine[typing.Any, typing.Any, None]

Expand source code

def stt_node(

self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings

) -> (

AsyncIterable[stt.SpeechEvent | str]

| Coroutine[Any, Any, AsyncIterable[stt.SpeechEvent | str]]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that transcribes audio frames into speech events.

By default, this node uses a Speech-To-Text (STT) capability from the current agent.

If the STT implementation does not support streaming natively, a VAD (Voice Activity

Detection) mechanism is required to wrap the STT.

You can override this node with your own implementation for more flexibility (e.g.,

custom pre-processing of audio, additional buffering, or alternative STT strategies).

Args:

audio (AsyncIterable[rtc.AudioFrame]): An asynchronous stream of audio frames.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields:

stt.SpeechEvent: An event containing transcribed text or other STT-related data.

"""

return Agent.default.stt_node(self, audio, model_settings)

A node in the processing pipeline that transcribes audio frames into speech events.

By default, this node uses a Speech-To-Text (STT) capability from the current agent.

If the STT implementation does not support streaming natively, a VAD (Voice Activity

Detection) mechanism is required to wrap the STT.

You can override this node with your own implementation for more flexibility (e.g.,

custom pre-processing of audio, additional buffering, or alternative STT strategies).

Args

audio

:

AsyncIterable[rtc.AudioFrame]

An asynchronous stream of audio frames.

model_settings

:

ModelSettings

Configuration and parameters for model execution.

Yields

SpeechEvent

An event containing transcribed text or other STT-related data.

def

transcription_node

(

self,

text: AsyncIterable[str | TimedString],

model_settings:

ModelSettings

) ‑> AsyncIterable[str | TimedString] | Coroutine[Any, Any, AsyncIterable[str | TimedString]] | Coroutine[Any, Any, None]

Expand source code

def transcription_node(

self, text: AsyncIterable[str | TimedString], model_settings: ModelSettings

) -> (

AsyncIterable[str | TimedString]

| Coroutine[Any, Any, AsyncIterable[str | TimedString]]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that finalizes transcriptions from text segments.

This node can be used to adjust or post-process text coming from an LLM (or any other

source) into a final transcribed form. For instance, you might clean up formatting, fix

punctuation, or perform any other text transformations here.

You can override this node to customize post-processing logic according to your needs.

Args:

text (AsyncIterable[str | TimedString]): An asynchronous stream of text segments.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields:

str: Finalized or post-processed text segments.

"""

return Agent.default.transcription_node(self, text, model_settings)

A node in the processing pipeline that finalizes transcriptions from text segments.

This node can be used to adjust or post-process text coming from an LLM (or any other

source) into a final transcribed form. For instance, you might clean up formatting, fix

punctuation, or perform any other text transformations here.

You can override this node to customize post-processing logic according to your needs.

Args

text

:

AsyncIterable[str | TimedString]

An asynchronous stream of text segments.

model_settings

:

ModelSettings

Configuration and parameters for model execution.

Yields

str

Finalized or post-processed text segments.

def

tts_node

(

self,

text: AsyncIterable[str],

model_settings:

ModelSettings

) ‑> collections.abc.AsyncIterable[

AudioFrame

] | collections.abc.Coroutine[typing.Any, typing.Any, collections.abc.AsyncIterable[

AudioFrame

]] | collections.abc.Coroutine[typing.Any, typing.Any, None]

Expand source code

def tts_node(

self, text: AsyncIterable[str], model_settings: ModelSettings

) -> (

AsyncIterable[rtc.AudioFrame]

| Coroutine[Any, Any, AsyncIterable[rtc.AudioFrame]]

| Coroutine[Any, Any, None]

):

"""

A node in the processing pipeline that synthesizes audio from text segments.

By default, this node converts incoming text into audio frames using the Text-To-Speech

from the agent.

If the TTS implementation does not support streaming natively, it uses a sentence tokenizer

to split text for incremental synthesis.

You can override this node to provide different text chunking behavior, a custom TTS engine,

or any other specialized processing.

Args:

text (AsyncIterable[str]): An asynchronous stream of text segments to be synthesized.

model_settings (ModelSettings): Configuration and parameters for model execution.

Yields:

rtc.AudioFrame: Audio frames synthesized from the provided text.

"""

return Agent.default.tts_node(self, text, model_settings)

A node in the processing pipeline that synthesizes audio from text segments.

By default, this node converts incoming text into audio frames using the Text-To-Speech

from the agent.

If the TTS implementation does not support streaming natively, it uses a sentence tokenizer

to split text for incremental synthesis.

You can override this node to provide different text chunking behavior, a custom TTS engine,

or any other specialized processing.

Args

text

:

AsyncIterable[str]

An asynchronous stream of text segments to be synthesized.

model_settings

:

ModelSettings

Configuration and parameters for model execution.

Yields

rtc.AudioFrame

Audio frames synthesized from the provided text.

async def

update_chat_ctx

(

self,

chat_ctx:

ChatContext

,

*,

exclude_invalid_function_calls: bool = True) ‑> None

Expand source code

async def update_chat_ctx(

self, chat_ctx: llm.ChatContext, *, exclude_invalid_function_calls: bool = True

) -> None:

"""

Updates the agent's chat context.

If the agent is running in realtime mode, this method also updates

the chat context for the ongoing realtime session.

Args:

chat_ctx (llm.ChatContext):

The new or updated chat context for the agent.

exclude_invalid_function_calls (bool): Whether to exclude function calls

and outputs not from the agent's tools.

Raises:

llm.RealtimeError: If updating the realtime session chat context fails.

"""

if self._activity is None:

self._chat_ctx = chat_ctx.copy(

tools=self._tools if exclude_invalid_function_calls else NOT_GIVEN

)

return

await self._activity.update_chat_ctx(

chat_ctx, exclude_invalid_function_calls=exclude_invalid_function_calls

)

Updates the agent's chat context.

If the agent is running in realtime mode, this method also updates

the chat context for the ongoing realtime session.

Args

chat_ctx (llm.ChatContext):

The new or updated chat context for the agent.

exclude_invalid_function_calls

:

bool

Whether to exclude function calls

and outputs not from the agent's tools.

Raises

RealtimeError

If updating the realtime session chat context fails.

async def

update_instructions

(

self, instructions: str) ‑> None

Expand source code

async def update_instructions(self, instructions: str) -> None:

"""

Updates the agent's instructions.

If the agent is running in realtime mode, this method also updates

the instructions for the ongoing realtime session.

Args:

instructions (str):

The new instructions to set for the agent.

Raises:

llm.RealtimeError: If updating the realtime session instructions fails.

"""

if self._activity is None:

self._instructions = instructions

return

await self._activity.update_instructions(instructions)

Updates the agent's instructions.

If the agent is running in realtime mode, this method also updates

the instructions for the ongoing realtime session.

Args

instructions (str):

The new instructions to set for the agent.

Raises

RealtimeError

If updating the realtime session instructions fails.

async def

update_tools

(

self,

tools: list[

FunctionTool

|

RawFunctionTool

]) ‑> None

Expand source code

async def update_tools(self, tools: list[llm.FunctionTool | llm.RawFunctionTool]) -> None:

"""

Updates the agent's available function tools.

If the agent is running in realtime mode, this method also updates

the tools for the ongoing realtime session.

Args:

tools (list[llm.FunctionTool]):

The new list of function tools available to the agent.

Raises:

llm.RealtimeError: If updating the realtime session tools fails.

"""

if self._activity is None:

self._tools = list(set(tools))

self._chat_ctx = self._chat_ctx.copy(tools=self._tools)

return

await self._activity.update_tools(tools)

Updates the agent's available function tools.

If the agent is running in realtime mode, this method also updates

the tools for the ongoing realtime session.

Args

tools (list[llm.FunctionTool]):

The new list of function tools available to the agent.

Raises

RealtimeError

If updating the realtime session tools fails.

class

AgentFalseInterruptionEvent

(

**data: Any)

Expand source code

class AgentFalseInterruptionEvent(BaseModel):

type: Literal["agent_false_interruption"] = "agent_false_interruption"

resumed: bool

"""Whether the false interruption was resumed automatically."""

created_at: float = Field(default_factory=time.time)

# deprecated

message: ChatMessage | None = None

extra_instructions: str | None = None

def __getattribute__(self, name: str) -> Any:

if name in ["message", "extra_instructions"]:

logger.warning(

f"AgentFalseInterruptionEvent.{name} is deprecated, automatic resume is now supported"

)

return super().__getattribute__(name)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

extra_instructions

: str | None

var

message

: livekit.agents.llm.chat_context.ChatMessage | None

var

model_config

var

resumed

: bool

Whether the false interruption was resumed automatically.

var

type

: Literal['agent_false_interruption']

class

AgentHandoffEvent

(

old_agent:

Agent

| None,

new_agent:

Agent

,

type: "Literal['agent_handoff']" = 'agent_handoff')

Expand source code

@dataclass

class AgentHandoffEvent:

old_agent: Agent | None

new_agent: Agent

type: Literal["agent_handoff"] = "agent_handoff"

AgentHandoffEvent(old_agent: 'Agent | None', new_agent: 'Agent', type: "Literal['agent_handoff']" = 'agent_handoff')

Instance variables

var

new_agent

:

Agent

var

old_agent

:

Agent

| None

var

type

: Literal['agent_handoff']

class

AgentSession

(

*,

turn_detection: NotGivenOr[TurnDetectionMode] = NOT_GIVEN,

stt: NotGivenOr[

STT

| STTModels | str] = NOT_GIVEN,

vad: NotGivenOr[

VAD

] = NOT_GIVEN,

llm: NotGivenOr[

LLM

|

RealtimeModel

| LLMModels | str] = NOT_GIVEN,

tts: NotGivenOr[

TTS

| TTSModels | str] = NOT_GIVEN,

mcp_servers: NotGivenOr[list[mcp.MCPServer]] = NOT_GIVEN,

userdata: NotGivenOr[Userdata_T] = NOT_GIVEN,

allow_interruptions: bool = True,

discard_audio_if_uninterruptible: bool = True,

min_interruption_duration: float = 0.5,

min_interruption_words: int = 0,

min_endpointing_delay: float = 0.5,

max_endpointing_delay: float = 3.0,

max_tool_steps: int = 3,

video_sampler: NotGivenOr[_VideoSampler | None] = NOT_GIVEN,

user_away_timeout: float | None = 15.0,

false_interruption_timeout: float | None = 2.0,

resume_false_interruption: bool = True,

min_consecutive_speech_delay: float = 0.0,

use_tts_aligned_transcript: NotGivenOr[bool] = NOT_GIVEN,

tts_text_transforms: NotGivenOr[Sequence[TextTransforms] | None] = NOT_GIVEN,

preemptive_generation: bool = False,

conn_options: NotGivenOr[SessionConnectOptions] = NOT_GIVEN,

loop: asyncio.AbstractEventLoop | None = None,

agent_false_interruption_timeout: NotGivenOr[float | None] = NOT_GIVEN)

Expand source code

class AgentSession(rtc.EventEmitter[EventTypes], Generic[Userdata_T]):

def __init__(

self,

*,

turn_detection: NotGivenOr[TurnDetectionMode] = NOT_GIVEN,

stt: NotGivenOr[stt.STT | STTModels | str] = NOT_GIVEN,

vad: NotGivenOr[vad.VAD] = NOT_GIVEN,

llm: NotGivenOr[llm.LLM | llm.RealtimeModel | LLMModels | str] = NOT_GIVEN,

tts: NotGivenOr[tts.TTS | TTSModels | str] = NOT_GIVEN,

mcp_servers: NotGivenOr[list[mcp.MCPServer]] = NOT_GIVEN,

userdata: NotGivenOr[Userdata_T] = NOT_GIVEN,

allow_interruptions: bool = True,

discard_audio_if_uninterruptible: bool = True,

min_interruption_duration: float = 0.5,

min_interruption_words: int = 0,

min_endpointing_delay: float = 0.5,

max_endpointing_delay: float = 3.0,

max_tool_steps: int = 3,

video_sampler: NotGivenOr[_VideoSampler | None] = NOT_GIVEN,

user_away_timeout: float | None = 15.0,

false_interruption_timeout: float | None = 2.0,

resume_false_interruption: bool = True,

min_consecutive_speech_delay: float = 0.0,

use_tts_aligned_transcript: NotGivenOr[bool] = NOT_GIVEN,

tts_text_transforms: NotGivenOr[Sequence[TextTransforms] | None] = NOT_GIVEN,

preemptive_generation: bool = False,

conn_options: NotGivenOr[SessionConnectOptions] = NOT_GIVEN,

loop: asyncio.AbstractEventLoop | None = None,

# deprecated

agent_false_interruption_timeout: NotGivenOr[float | None] = NOT_GIVEN,

) -> None:

"""`AgentSession` is the LiveKit Agents runtime that glues together

media streams, speech/LLM components, and tool orchestration into a

single real-time voice agent.

It links audio, video, and text I/O with STT, VAD, TTS, and the LLM;

handles turn detection, endpointing, interruptions, and multi-step

tool calls; and exposes everything through event callbacks so you can

focus on writing function tools and simple hand-offs rather than

low-level streaming logic.

Args:

turn_detection (TurnDetectionMode, optional): Strategy for deciding

when the user has finished speaking.

* ``"stt"`` – rely on speech-to-text end-of-utterance cues

* ``"vad"`` – rely on Voice Activity Detection start/stop cues

* ``"realtime_llm"`` – use server-side detection from a

realtime LLM

* ``"manual"`` – caller controls turn boundaries explicitly

* ``_TurnDetector`` instance – plug-in custom detector

If *NOT_GIVEN*, the session chooses the best available mode in

priority order ``realtime_llm → vad → stt → manual``; it

automatically falls back if the necessary model is missing.

stt (stt.STT | str, optional): Speech-to-text backend.

vad (vad.VAD, optional): Voice-activity detector

llm (llm.LLM | llm.RealtimeModel | str, optional): LLM or RealtimeModel

tts (tts.TTS | str, optional): Text-to-speech engine.

mcp_servers (list[mcp.MCPServer], optional): List of MCP servers

providing external tools for the agent to use.

userdata (Userdata_T, optional): Arbitrary per-session user data.

allow_interruptions (bool): Whether the user can interrupt the

agent mid-utterance. Default ``True``.

discard_audio_if_uninterruptible (bool): When ``True``, buffered

audio is dropped while the agent is speaking and cannot be

interrupted. Default ``True``.

min_interruption_duration (float): Minimum speech length (s) to

register as an interruption. Default ``0.5`` s.

min_interruption_words (int): Minimum number of words to consider

an interruption, only used if stt enabled. Default ``0``.

min_endpointing_delay (float): Minimum time-in-seconds the agent

must wait after a potential end-of-utterance signal (from VAD

or an EOU model) before it declares the user’s turn complete.

Default ``0.5`` s.

max_endpointing_delay (float): Maximum time-in-seconds the agent

will wait before terminating the turn. Default ``3.0`` s.

max_tool_steps (int): Maximum consecutive tool calls per LLM turn.

Default ``3``.

video_sampler (_VideoSampler, optional): Uses

:class:`VoiceActivityVideoSampler` when *NOT_GIVEN*; that sampler

captures video at ~1 fps while the user is speaking and ~0.3 fps

when silent by default.

user_away_timeout (float, optional): If set, set the user state as

"away" after this amount of time after user and agent are silent.

Default ``15.0`` s, set to ``None`` to disable.

false_interruption_timeout (float, optional): If set, emit an

`agent_false_interruption` event after this amount of time if

the user is silent and no user transcript is detected after

the interruption. Set to ``None`` to disable. Default ``2.0`` s.

resume_false_interruption (bool): Whether to resume the false interruption

after the false_interruption_timeout. Default ``True``.

min_consecutive_speech_delay (float, optional): The minimum delay between

consecutive speech. Default ``0.0`` s.

use_tts_aligned_transcript (bool, optional): Whether to use TTS-aligned

transcript as the input of the ``transcription_node``. Only applies

if ``TTS.capabilities.aligned_transcript`` is ``True`` or ``streaming``

is ``False``. When NOT_GIVEN, it's disabled.

tts_text_transforms (Sequence[TextTransforms], optional): The transforms to apply

to the tts input text, available built-in transforms: ``"filter_markdown"``, ``"filter_emoji"``.

Set to ``None`` to disable. When NOT_GIVEN, all filters will be applied.

preemptive_generation (bool):

Whether to speculatively begin LLM and TTS requests before an end-of-turn is

detected. When True, the agent sends inference calls as soon as a user

transcript is received rather than waiting for a definitive turn boundary. This

can reduce response latency by overlapping model inference with user audio,

but may incur extra compute if the user interrupts or revises mid-utterance.

Defaults to ``False``.

conn_options (SessionConnectOptions, optional): Connection options for

stt, llm, and tts.

loop (asyncio.AbstractEventLoop, optional): Event loop to bind the

session to. Falls back to :pyfunc:`asyncio.get_event_loop()`.

"""

super().__init__()

self._loop = loop or asyncio.get_event_loop()

if is_given(agent_false_interruption_timeout):

logger.warning(

"`agent_false_interruption_timeout` is deprecated, use `false_interruption_timeout` instead"  # noqa: E501

)

false_interruption_timeout = agent_false_interruption_timeout

if not is_given(video_sampler):

video_sampler = VoiceActivityVideoSampler(speaking_fps=1.0, silent_fps=0.3)

self._video_sampler = video_sampler

# This is the "global" chat_context, it holds the entire conversation history

self._chat_ctx = ChatContext.empty()

self._opts = VoiceOptions(

allow_interruptions=allow_interruptions,

discard_audio_if_uninterruptible=discard_audio_if_uninterruptible,

min_interruption_duration=min_interruption_duration,

min_interruption_words=min_interruption_words,

min_endpointing_delay=min_endpointing_delay,

max_endpointing_delay=max_endpointing_delay,

max_tool_steps=max_tool_steps,

user_away_timeout=user_away_timeout,

false_interruption_timeout=false_interruption_timeout,

resume_false_interruption=resume_false_interruption,

min_consecutive_speech_delay=min_consecutive_speech_delay,

tts_text_transforms=(

tts_text_transforms

if is_given(tts_text_transforms)

else DEFAULT_TTS_TEXT_TRANSFORMS

),

preemptive_generation=preemptive_generation,

use_tts_aligned_transcript=use_tts_aligned_transcript,

)

self._conn_options = conn_options or SessionConnectOptions()

self._started = False

self._turn_detection = turn_detection or None

if isinstance(stt, str):

stt = inference.STT.from_model_string(stt)

if isinstance(llm, str):

llm = inference.LLM.from_model_string(llm)

if isinstance(tts, str):

tts = inference.TTS.from_model_string(tts)

self._stt = stt or None

self._vad = vad or None

self._llm = llm or None

self._tts = tts or None

self._mcp_servers = mcp_servers or None

# unrecoverable error counts, reset after agent speaking

self._llm_error_counts = 0

self._tts_error_counts = 0

# configurable IO

self._input = io.AgentInput(self._on_video_input_changed, self._on_audio_input_changed)

self._output = io.AgentOutput(

self._on_video_output_changed,

self._on_audio_output_changed,

self._on_text_output_changed,

)

self._forward_audio_atask: asyncio.Task[None] | None = None

self._forward_video_atask: asyncio.Task[None] | None = None

self._update_activity_atask: asyncio.Task[None] | None = None

self._activity_lock = asyncio.Lock()

self._lock = asyncio.Lock()

# used to keep a reference to the room io

# this is not exposed, if users want access to it, they can create their own RoomIO

self._room_io: room_io.RoomIO | None = None

self._agent: Agent | None = None

self._activity: AgentActivity | None = None

self._next_activity: AgentActivity | None = None

self._user_state: UserState = "listening"

self._agent_state: AgentState = "initializing"

self._user_away_timer: asyncio.TimerHandle | None = None

self._userdata: Userdata_T | None = userdata if is_given(userdata) else None

self._closing_task: asyncio.Task[None] | None = None

self._closing: bool = False

self._job_context_cb_registered: bool = False

self._global_run_state: RunResult | None = None

# trace

self._user_speaking_span: trace.Span | None = None

self._agent_speaking_span: trace.Span | None = None

self._session_span: trace.Span | None = None

self._root_span_context: otel_context.Context | None = None

@property

def userdata(self) -> Userdata_T:

if self._userdata is None:

raise ValueError("VoiceAgent userdata is not set")

return self._userdata

@userdata.setter

def userdata(self, value: Userdata_T) -> None:

self._userdata = value

@property

def turn_detection(self) -> TurnDetectionMode | None:

return self._turn_detection

@property

def mcp_servers(self) -> list[mcp.MCPServer] | None:

return self._mcp_servers

@property

def input(self) -> io.AgentInput:

return self._input

@property

def output(self) -> io.AgentOutput:

return self._output

@property

def options(self) -> VoiceOptions:

return self._opts

@property

def conn_options(self) -> SessionConnectOptions:

return self._conn_options

@property

def history(self) -> llm.ChatContext:

return self._chat_ctx

@property

def current_speech(self) -> SpeechHandle | None:

return self._activity.current_speech if self._activity is not None else None

@property

def user_state(self) -> UserState:

return self._user_state

@property

def agent_state(self) -> AgentState:

return self._agent_state

@property

def current_agent(self) -> Agent:

if self._agent is None:

raise RuntimeError("VoiceAgent isn't running")

return self._agent

def run(self, *, user_input: str, output_type: type[Run_T] | None = None) -> RunResult[Run_T]:

if self._global_run_state is not None and not self._global_run_state.done():

raise RuntimeError("nested runs are not supported")

run_state = RunResult(user_input=user_input, output_type=output_type)

self._global_run_state = run_state

self.generate_reply(user_input=user_input)

return run_state

@overload

async def start(

self,

agent: Agent,

*,

capture_run: Literal[True],

room: NotGivenOr[rtc.Room] = NOT_GIVEN,

room_input_options: NotGivenOr[room_io.RoomInputOptions] = NOT_GIVEN,

room_output_options: NotGivenOr[room_io.RoomOutputOptions] = NOT_GIVEN,

) -> RunResult: ...

@overload

async def start(

self,

agent: Agent,

*,

capture_run: Literal[False] = False,

room: NotGivenOr[rtc.Room] = NOT_GIVEN,

room_input_options: NotGivenOr[room_io.RoomInputOptions] = NOT_GIVEN,

room_output_options: NotGivenOr[room_io.RoomOutputOptions] = NOT_GIVEN,

) -> None: ...

@tracer.start_as_current_span("agent_session", end_on_exit=False)

async def start(

self,

agent: Agent,

*,

capture_run: bool = False,

room: NotGivenOr[rtc.Room] = NOT_GIVEN,

room_input_options: NotGivenOr[room_io.RoomInputOptions] = NOT_GIVEN,

room_output_options: NotGivenOr[room_io.RoomOutputOptions] = NOT_GIVEN,

) -> RunResult | None:

"""Start the voice agent.

Create a default RoomIO if the input or output audio is not already set.

If the console flag is provided, start a ChatCLI.

Args:

capture_run: Whether to return a RunResult and capture the run result during session start.

room: The room to use for input and output

room_input_options: Options for the room input

room_output_options: Options for the room output

"""

async with self._lock:

if self._started:

return None

self._closing = False

self._root_span_context = otel_context.get_current()

self._session_span = current_span = trace.get_current_span()

current_span = trace.get_current_span()

current_span.set_attribute(trace_types.ATTR_AGENT_LABEL, agent.label)

current_span.set_attribute(

trace_types.ATTR_SESSION_OPTIONS,

json.dumps({k: v for k, v in asdict(self._opts).items() if is_given(v)}),

)

self._agent = agent

self._update_agent_state("initializing")

tasks: list[asyncio.Task[None]] = []

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

from .chat_cli import ChatCLI

if (

self.input.audio is not None

or self.output.audio is not None

or self.output.transcription is not None

):

logger.warning(

"agent started with the console subcommand, but input.audio or output.audio "  # noqa: E501

"or output.transcription is already set, overriding.."

)

chat_cli = ChatCLI(self)

tasks.append(asyncio.create_task(chat_cli.start(), name="_chat_cli_start"))

elif is_given(room) and not self._room_io:

room_input_options = copy.copy(

room_input_options or room_io.DEFAULT_ROOM_INPUT_OPTIONS

)

room_output_options = copy.copy(

room_output_options or room_io.DEFAULT_ROOM_OUTPUT_OPTIONS

)

if self.input.audio is not None:

if room_input_options.audio_enabled:

logger.warning(

"RoomIO audio input is enabled but input.audio is already set, ignoring.."  # noqa: E501

)

room_input_options.audio_enabled = False

if self.output.audio is not None:

if room_output_options.audio_enabled:

logger.warning(

"RoomIO audio output is enabled but output.audio is already set, ignoring.."  # noqa: E501

)

room_output_options.audio_enabled = False

if self.output.transcription is not None:

if room_output_options.transcription_enabled:

logger.warning(

"RoomIO transcription output is enabled but output.transcription is already set, ignoring.."  # noqa: E501

)

room_output_options.transcription_enabled = False

self._room_io = room_io.RoomIO(

room=room,

agent_session=self,

input_options=room_input_options,

output_options=room_output_options,

)

tasks.append(asyncio.create_task(self._room_io.start(), name="_room_io_start"))

# session can be restarted, register the callbacks only once

try:

job_ctx = get_job_context()

current_span.set_attribute(trace_types.ATTR_ROOM_NAME, job_ctx.room.name)

current_span.set_attribute(trace_types.ATTR_JOB_ID, job_ctx.job.id)

current_span.set_attribute(trace_types.ATTR_AGENT_NAME, job_ctx.job.agent_name)

if self._room_io:

# automatically connect to the room when room io is used

tasks.append(asyncio.create_task(job_ctx.connect(), name="_job_ctx_connect"))

if not self._job_context_cb_registered:

job_ctx.add_shutdown_callback(

lambda: self._aclose_impl(reason=CloseReason.JOB_SHUTDOWN)

)

self._job_context_cb_registered = True

except RuntimeError:

pass  # ignore

run_state: RunResult | None = None

if capture_run:

if self._global_run_state is not None and not self._global_run_state.done():

raise RuntimeError("nested runs are not supported")

run_state = RunResult(output_type=None)

self._global_run_state = run_state

# it is ok to await it directly, there is no previous task to drain

tasks.append(

asyncio.create_task(self._update_activity(self._agent, wait_on_enter=False))

)

try:

await asyncio.gather(*tasks)

finally:

await utils.aio.cancel_and_wait(*tasks)

# important: no await should be done after this!

if self.input.audio is not None:

self._forward_audio_atask = asyncio.create_task(

self._forward_audio_task(), name="_forward_audio_task"

)

if self.input.video is not None:

self._forward_video_atask = asyncio.create_task(

self._forward_video_task(), name="_forward_video_task"

)

self._started = True

self._update_agent_state("listening")

if self._room_io and self._room_io.subscribed_fut:

def on_room_io_subscribed(_: asyncio.Future[None]) -> None:

if self._user_state == "listening" and self._agent_state == "listening":

self._set_user_away_timer()

self._room_io.subscribed_fut.add_done_callback(on_room_io_subscribed)

# log used IO

def _collect_source(

inp: io.AudioInput | io.VideoInput | None,

) -> list[io.AudioInput | io.VideoInput]:

return [] if inp is None else [inp] + _collect_source(inp.source)

def _collect_chain(

out: io.TextOutput | io.VideoOutput | io.AudioOutput | None,

) -> list[io.VideoOutput | io.AudioOutput | io.TextOutput]:

return [] if out is None else [out] + _collect_chain(out.next_in_chain)

audio_input = _collect_source(self.input.audio)[::-1]

video_input = _collect_source(self.input.video)[::-1]

audio_output = _collect_chain(self.output.audio)

video_output = _collect_chain(self.output.video)

transcript_output = _collect_chain(self.output.transcription)

logger.debug(

"using audio io: %s -> `AgentSession` -> %s",

" -> ".join([f"`{out.label}`" for out in audio_input]) or "(none)",

" -> ".join([f"`{out.label}`" for out in audio_output]) or "(none)",

)

if (

self._opts.resume_false_interruption

and self.output.audio

and not self.output.audio.can_pause

):

logger.warning(

"resume_false_interruption is enabled but audio output does not support pause, it will be ignored",

extra={"audio_output": self.output.audio.label},

)

logger.debug(

"using transcript io: `AgentSession` -> %s",

" -> ".join([f"`{out.label}`" for out in transcript_output]) or "(none)",

)

if video_input or video_output:

logger.debug(

"using video io: %s > `AgentSession` > %s",

" -> ".join([f"`{out.label}`" for out in video_input]) or "(none)",

" -> ".join([f"`{out.label}`" for out in video_output]) or "(none)",

)

if run_state:

await run_state

return run_state

async def drain(self) -> None:

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

await self._activity.drain()

def _close_soon(

self,

*,

reason: CloseReason,

drain: bool = False,

error: llm.LLMError | stt.STTError | tts.TTSError | llm.RealtimeModelError | None = None,

) -> None:

if self._closing_task:

return

self._closing_task = asyncio.create_task(

self._aclose_impl(error=error, drain=drain, reason=reason)

)

def shutdown(self, *, drain: bool = True) -> None:

self._close_soon(error=None, drain=drain, reason=CloseReason.USER_INITIATED)

@utils.log_exceptions(logger=logger)

async def _aclose_impl(

self,

*,

reason: CloseReason,

drain: bool = False,

error: llm.LLMError | stt.STTError | tts.TTSError | llm.RealtimeModelError | None = None,

) -> None:

if self._root_span_context:

# make `activity.drain` and `on_exit` under the root span

otel_context.attach(self._root_span_context)

async with self._lock:

if not self._started:

return

self._closing = True

self._cancel_user_away_timer()

if self._activity is not None:

if not drain:

try:

await self._activity.interrupt()

except RuntimeError:

# uninterruptible speech

# TODO(long): force interrupt or wait for it to finish?

# it might be an audio played from the error callback

pass

await self._activity.drain()

# wait any uninterruptible speech to finish

if self._activity.current_speech:

await self._activity.current_speech

# detach the inputs and outputs

self.input.audio = None

self.input.video = None

self.output.audio = None

self.output.transcription = None

if (

reason != CloseReason.ERROR

and (audio_recognition := self._activity._audio_recognition) is not None

):

# wait for the user transcript to be committed

audio_recognition.commit_user_turn(audio_detached=True, transcript_timeout=2.0)

await self._activity.aclose()

self._activity = None

if self._agent_speaking_span:

self._agent_speaking_span.end()

self._agent_speaking_span = None

if self._user_speaking_span:

self._user_speaking_span.end()

self._user_speaking_span = None

if self._forward_audio_atask is not None:

await utils.aio.cancel_and_wait(self._forward_audio_atask)

self._started = False

if self._session_span:

self._session_span.end()

self._session_span = None

self.emit("close", CloseEvent(error=error, reason=reason))

self._user_state = "listening"

self._agent_state = "initializing"

self._llm_error_counts = 0

self._tts_error_counts = 0

self._root_span_context = None

# close room io after close event is emitted

if self._room_io:

await self._room_io.aclose()

self._room_io = None

logger.debug("session closed", extra={"reason": reason.value, "error": error})

async def aclose(self) -> None:

await self._aclose_impl(reason=CloseReason.USER_INITIATED)

def update_options(

self,

*,

min_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

max_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

) -> None:

"""

Update the options for the agent session.

Args:

min_endpointing_delay (NotGivenOr[float], optional): The minimum endpointing delay.

max_endpointing_delay (NotGivenOr[float], optional): The maximum endpointing delay.

"""

if is_given(min_endpointing_delay):

self._opts.min_endpointing_delay = min_endpointing_delay

if is_given(max_endpointing_delay):

self._opts.max_endpointing_delay = max_endpointing_delay

if self._activity is not None:

self._activity.update_options(

min_endpointing_delay=min_endpointing_delay,

max_endpointing_delay=max_endpointing_delay,

)

def say(

self,

text: str | AsyncIterable[str],

*,

audio: NotGivenOr[AsyncIterable[rtc.AudioFrame]] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

add_to_chat_ctx: bool = True,

) -> SpeechHandle:

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

run_state = self._global_run_state

activity = self._next_activity if self._activity.scheduling_paused else self._activity

if activity is None:

raise RuntimeError("AgentSession is closing, cannot use say()")

handle = activity.say(

text,

audio=audio,

allow_interruptions=allow_interruptions,

add_to_chat_ctx=add_to_chat_ctx,

)

if run_state:

run_state._watch_handle(handle)

return handle

def generate_reply(

self,

*,

user_input: NotGivenOr[str] = NOT_GIVEN,

instructions: NotGivenOr[str] = NOT_GIVEN,

tool_choice: NotGivenOr[llm.ToolChoice] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

) -> SpeechHandle:

"""Generate a reply for the agent to speak to the user.

Args:

user_input (NotGivenOr[str], optional): The user's input that may influence the reply,

such as answering a question.

instructions (NotGivenOr[str], optional): Additional instructions for generating the reply.

tool_choice (NotGivenOr[llm.ToolChoice], optional): Specifies the external tool to use when

generating the reply. If generate_reply is invoked within a function_tool, defaults to "none".

allow_interruptions (NotGivenOr[bool], optional): Indicates whether the user can interrupt this speech.

Returns:

SpeechHandle: A handle to the generated reply.

"""  # noqa: E501

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

user_message = (

llm.ChatMessage(role="user", content=[user_input])

if is_given(user_input)

else NOT_GIVEN

)

run_state = self._global_run_state

activity = self._next_activity if self._activity.scheduling_paused else self._activity

if activity is None:

raise RuntimeError("AgentSession is closing, cannot use generate_reply()")

handle = activity._generate_reply(

user_message=user_message,

instructions=instructions,

tool_choice=tool_choice,

allow_interruptions=allow_interruptions,

)

if run_state:

run_state._watch_handle(handle)

return handle

def interrupt(self, *, force: bool = False) -> asyncio.Future[None]:

"""Interrupt the current speech generation.

Returns:

An asyncio.Future that completes when the interruption is fully processed

and chat context has been updated.

"""

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

return self._activity.interrupt(force=force)

def clear_user_turn(self) -> None:

# clear the transcription or input audio buffer of the user turn

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

self._activity.clear_user_turn()

def commit_user_turn(

self, *, transcript_timeout: float = 2.0, stt_flush_duration: float = 2.0

) -> None:

"""Commit the user turn and generate a reply.

Args:

transcript_timeout (float, optional): The timeout for the final transcript

to be received after committing the user turn.

Increase this value if the STT is slow to respond.

stt_flush_duration (float, optional): The duration of the silence to be appended to the STT

to flush the buffer and generate the final transcript.

Raises:

RuntimeError: If the AgentSession isn't running.

"""

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

self._activity.commit_user_turn(

transcript_timeout=transcript_timeout, stt_flush_duration=stt_flush_duration

)

def update_agent(self, agent: Agent) -> None:

self._agent = agent

if self._started:

self._update_activity_atask = task = asyncio.create_task(

self._update_activity_task(self._update_activity_atask, self._agent),

name="_update_activity_task",

)

run_state = self._global_run_state

if run_state:

# don't mark the RunResult as done, if there is currently an agent transition happening.  # noqa: E501

# (used to make sure we're correctly adding the AgentHandoffResult before completion)  # noqa: E501

run_state._watch_handle(task)

async def _update_activity(

self,

agent: Agent,

*,

previous_activity: Literal["close", "pause"] = "close",

new_activity: Literal["start", "resume"] = "start",

blocked_tasks: list[asyncio.Task] | None = None,

wait_on_enter: bool = True,

) -> None:

async with self._activity_lock:

# _update_activity is called directly sometimes, update for redundancy

self._agent = agent

if new_activity == "start":

if agent._activity is not None:

raise RuntimeError("cannot start agent: an activity is already running")

self._next_activity = AgentActivity(agent, self)

elif new_activity == "resume":

if agent._activity is None:

raise RuntimeError("cannot resume agent: no existing active activity to resume")

self._next_activity = agent._activity

previous_activity_v = self._activity

if self._activity is not None:

if previous_activity == "close":

await self._activity.drain()

await self._activity.aclose()

elif previous_activity == "pause":

await self._activity.pause(blocked_tasks=blocked_tasks or [])

self._activity = self._next_activity

self._next_activity = None

run_state = self._global_run_state

if run_state:

run_state._agent_handoff(

old_agent=previous_activity_v.agent if previous_activity_v else None,

new_agent=self._activity.agent,

)

if new_activity == "start":

await self._activity.start()

elif new_activity == "resume":

await self._activity.resume()

# move it outside the lock to allow calling _update_activity in on_enter of a new agent

if wait_on_enter:

assert self._activity._on_enter_task is not None

await asyncio.shield(self._activity._on_enter_task)

@utils.log_exceptions(logger=logger)

async def _update_activity_task(

self, old_task: asyncio.Task[None] | None, agent: Agent

) -> None:

if old_task is not None:

await old_task

if self._root_span_context is not None:

# restore the root span context so on_exit, on_enter, and future turns

# are direct children of the root span, not nested under a tool call.

otel_context.attach(self._root_span_context)

await self._update_activity(agent)

def _on_error(

self,

error: llm.LLMError | stt.STTError | tts.TTSError | llm.RealtimeModelError,

) -> None:

if self._closing_task or error.recoverable:

return

if error.type == "llm_error":

self._llm_error_counts += 1

if self._llm_error_counts <= self.conn_options.max_unrecoverable_errors:

return

elif error.type == "tts_error":

self._tts_error_counts += 1

if self._tts_error_counts <= self.conn_options.max_unrecoverable_errors:

return

logger.error("AgentSession is closing due to unrecoverable error", exc_info=error.error)

def on_close_done(_: asyncio.Task[None]) -> None:

self._closing_task = None

self._closing_task = asyncio.create_task(

self._aclose_impl(error=error, reason=CloseReason.ERROR)

)

self._closing_task.add_done_callback(on_close_done)

@utils.log_exceptions(logger=logger)

async def _forward_audio_task(self) -> None:

audio_input = self.input.audio

if audio_input is None:

return

async for frame in audio_input:

if self._activity is not None:

self._activity.push_audio(frame)

@utils.log_exceptions(logger=logger)

async def _forward_video_task(self) -> None:

video_input = self.input.video

if video_input is None:

return

async for frame in video_input:

if self._activity is not None:

if self._video_sampler is not None and not self._video_sampler(frame, self):

continue  # ignore this frame

self._activity.push_video(frame)

def _set_user_away_timer(self) -> None:

self._cancel_user_away_timer()

if self._opts.user_away_timeout is None:

return

if (

(room_io := self._room_io)

and room_io.subscribed_fut

and not room_io.subscribed_fut.done()

):

# skip the timer before user join the room

return

self._user_away_timer = self._loop.call_later(

self._opts.user_away_timeout, self._update_user_state, "away"

)

def _cancel_user_away_timer(self) -> None:

if self._user_away_timer is not None:

self._user_away_timer.cancel()

self._user_away_timer = None

def _update_agent_state(self, state: AgentState) -> None:

if self._agent_state == state:

return

if state == "speaking":

self._llm_error_counts = 0

self._tts_error_counts = 0

if self._agent_speaking_span is None:

self._agent_speaking_span = tracer.start_span("agent_speaking")

self._agent_speaking_span.set_attribute(trace_types.ATTR_START_TIME, time.time())

elif self._agent_speaking_span is not None:

self._agent_speaking_span.set_attribute(trace_types.ATTR_END_TIME, time.time())

self._agent_speaking_span.end()

self._agent_speaking_span = None

if state == "listening" and self._user_state == "listening":

self._set_user_away_timer()

else:

self._cancel_user_away_timer()

old_state = self._agent_state

self._agent_state = state

self.emit(

"agent_state_changed",

AgentStateChangedEvent(old_state=old_state, new_state=state),

)

def _update_user_state(

self, state: UserState, *, last_speaking_time: float | None = None

) -> None:

if self._user_state == state:

return

if state == "speaking" and self._user_speaking_span is None:

self._user_speaking_span = tracer.start_span("user_speaking")

self._user_speaking_span.set_attribute(trace_types.ATTR_START_TIME, time.time())

elif self._user_speaking_span is not None:

end_time = last_speaking_time or time.time()

self._user_speaking_span.set_attribute(trace_types.ATTR_END_TIME, end_time)

self._user_speaking_span.end()

self._user_speaking_span = None

if state == "listening" and self._agent_state == "listening":

self._set_user_away_timer()

else:

self._cancel_user_away_timer()

old_state = self._user_state

self._user_state = state

self.emit(

"user_state_changed",

UserStateChangedEvent(old_state=old_state, new_state=state),

)

def _user_input_transcribed(self, ev: UserInputTranscribedEvent) -> None:

if self.user_state == "away" and ev.is_final:

# reset user state from away to listening in case VAD has a miss detection

self._update_user_state("listening")

self.emit("user_input_transcribed", ev)

def _conversation_item_added(self, message: llm.ChatMessage) -> None:

self._chat_ctx.insert(message)

self.emit("conversation_item_added", ConversationItemAddedEvent(item=message))

def _tool_items_added(self, items: Sequence[llm.FunctionCall | llm.FunctionCallOutput]) -> None:

self._chat_ctx.insert(items)

# move them to the end to avoid shadowing the same named modules for mypy

@property

def stt(self) -> stt.STT | None:

return self._stt

@property

def llm(self) -> llm.LLM | llm.RealtimeModel | None:

return self._llm

@property

def tts(self) -> tts.TTS | None:

return self._tts

@property

def vad(self) -> vad.VAD | None:

return self._vad

# -- User changed input/output streams/sinks --

def _on_video_input_changed(self) -> None:

if not self._started:

return

if self._forward_video_atask is not None:

self._forward_video_atask.cancel()

self._forward_video_atask = asyncio.create_task(

self._forward_video_task(), name="_forward_video_task"

)

def _on_audio_input_changed(self) -> None:

if not self._started:

return

if self._forward_audio_atask is not None:

self._forward_audio_atask.cancel()

self._forward_audio_atask = asyncio.create_task(

self._forward_audio_task(), name="_forward_audio_task"

)

def _on_video_output_changed(self) -> None:

pass

def _on_audio_output_changed(self) -> None:

if (

self._started

and self._opts.resume_false_interruption

and (audio_output := self.output.audio)

and not audio_output.can_pause

):

logger.warning(

"resume_false_interruption is enabled, but the audio output does not support pause, ignored",

extra={"audio_output": audio_output.label},

)

def _on_text_output_changed(self) -> None:

pass

# ---

async def __aenter__(self) -> AgentSession:

return self

async def __aexit__(

self,

exc_type: type[BaseException] | None,

exc: BaseException | None,

exc_tb: TracebackType | None,

) -> None:

await self.aclose()

Abstract base class for generic types.

On Python 3.12 and newer, generic classes implicitly inherit from

Generic when they declare a parameter list after the class's name::

class Mapping[KT, VT]:

def __getitem__(self, key: KT) -> VT:

...

# Etc.

On older versions of Python, however, generic classes have to

explicitly inherit from Generic.

After a class has been declared to be generic, it can then be used as

follows::

def lookup_name[KT, VT](mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:

try:

return mapping[key]

except KeyError:

return default

AgentSession

is the LiveKit Agents runtime that glues together

media streams, speech/LLM components, and tool orchestration into a

single real-time voice agent.

It links audio, video, and text I/O with STT, VAD, TTS, and the LLM;

handles turn detection, endpointing, interruptions, and multi-step

tool calls; and exposes everything through event callbacks so you can

focus on writing function tools and simple hand-offs rather than

low-level streaming logic.

Args

turn_detection

:

TurnDetectionMode

, optional

Strategy for deciding

when the user has finished speaking.

"stt"

– rely on speech-to-text end-of-utterance cues

"vad"

– rely on Voice Activity Detection start/stop cues

"realtime_llm"

– use server-side detection from a

realtime LLM

"manual"

– caller controls turn boundaries explicitly

_TurnDetector

instance – plug-in custom detector

If

NOT_GIVEN

, the session chooses the best available mode in

priority order

realtime_llm → vad → stt → manual

; it

automatically falls back if the necessary model is missing.

stt

:

stt.STT | str

, optional

Speech-to-text backend.

vad

:

VAD

, optional

Voice-activity detector

llm

:

llm.LLM | llm.RealtimeModel | str

, optional

LLM or RealtimeModel

tts

:

tts.TTS | str

, optional

Text-to-speech engine.

mcp_servers

:

list[mcp.MCPServer]

, optional

List of MCP servers

providing external tools for the agent to use.

userdata

:

Userdata_T

, optional

Arbitrary per-session user data.

allow_interruptions

:

bool

Whether the user can interrupt the

agent mid-utterance. Default

True

.

discard_audio_if_uninterruptible

:

bool

When

True

, buffered

audio is dropped while the agent is speaking and cannot be

interrupted. Default

True

.

min_interruption_duration

:

float

Minimum speech length (s) to

register as an interruption. Default

0.5

s.

min_interruption_words

:

int

Minimum number of words to consider

an interruption, only used if stt enabled. Default

0

.

min_endpointing_delay

:

float

Minimum time-in-seconds the agent

must wait after a potential end-of-utterance signal (from VAD

or an EOU model) before it declares the user’s turn complete.

Default

0.5

s.

max_endpointing_delay

:

float

Maximum time-in-seconds the agent

will wait before terminating the turn. Default

3.0

s.

max_tool_steps

:

int

Maximum consecutive tool calls per LLM turn.

Default

3

.

video_sampler

:

_VideoSampler

, optional

Uses

:class:

VoiceActivityVideoSampler

when

NOT_GIVEN

; that sampler

captures video at ~1 fps while the user is speaking and ~0.3 fps

when silent by default.

user_away_timeout

:

float

, optional

If set, set the user state as

"away" after this amount of time after user and agent are silent.

Default

15.0

s, set to

None

to disable.

false_interruption_timeout

:

float

, optional

If set, emit an

agent_false_interruption

event after this amount of time if

the user is silent and no user transcript is detected after

the interruption. Set to

None

to disable. Default

2.0

s.

resume_false_interruption

:

bool

Whether to resume the false interruption

after the false_interruption_timeout. Default

True

.

min_consecutive_speech_delay

:

float

, optional

The minimum delay between

consecutive speech. Default

0.0

s.

use_tts_aligned_transcript

:

bool

, optional

Whether to use TTS-aligned

transcript as the input of the

transcription_node

. Only applies

if

TTS.capabilities.aligned_transcript

is

True

or

streaming

is

False

. When NOT_GIVEN, it's disabled.

tts_text_transforms

:

Sequence[TextTransforms]

, optional

The transforms to apply

to the tts input text, available built-in transforms:

"filter_markdown"

,

"filter_emoji"

.

Set to

None

to disable. When NOT_GIVEN, all filters will be applied.

preemptive_generation (bool):

Whether to speculatively begin LLM and TTS requests before an end-of-turn is

detected. When True, the agent sends inference calls as soon as a user

transcript is received rather than waiting for a definitive turn boundary. This

can reduce response latency by overlapping model inference with user audio,

but may incur extra compute if the user interrupts or revises mid-utterance.

Defaults to

False

.

conn_options

:

SessionConnectOptions

, optional

Connection options for

stt, llm, and tts.

loop

:

asyncio.AbstractEventLoop

, optional

Event loop to bind the

session to. Falls back to :pyfunc:

asyncio.get_event_loop()

.

Ancestors

EventEmitter

typing.Generic

Instance variables

prop

agent_state

: AgentState

Expand source code

@property

def agent_state(self) -> AgentState:

return self._agent_state

prop

conn_options

: SessionConnectOptions

Expand source code

@property

def conn_options(self) -> SessionConnectOptions:

return self._conn_options

prop

current_agent

:

Agent

Expand source code

@property

def current_agent(self) -> Agent:

if self._agent is None:

raise RuntimeError("VoiceAgent isn't running")

return self._agent

prop

current_speech

: SpeechHandle | None

Expand source code

@property

def current_speech(self) -> SpeechHandle | None:

return self._activity.current_speech if self._activity is not None else None

prop

history

:

ChatContext

Expand source code

@property

def history(self) -> llm.ChatContext:

return self._chat_ctx

prop

input

: io.AgentInput

Expand source code

@property

def input(self) -> io.AgentInput:

return self._input

prop

llm

:

LLM

|

RealtimeModel

| None

Expand source code

@property

def llm(self) -> llm.LLM | llm.RealtimeModel | None:

return self._llm

prop

mcp_servers

: list[mcp.MCPServer] | None

Expand source code

@property

def mcp_servers(self) -> list[mcp.MCPServer] | None:

return self._mcp_servers

prop

options

: VoiceOptions

Expand source code

@property

def options(self) -> VoiceOptions:

return self._opts

prop

output

: io.AgentOutput

Expand source code

@property

def output(self) -> io.AgentOutput:

return self._output

prop

stt

:

STT

| None

Expand source code

@property

def stt(self) -> stt.STT | None:

return self._stt

prop

tts

:

TTS

| None

Expand source code

@property

def tts(self) -> tts.TTS | None:

return self._tts

prop

turn_detection

: TurnDetectionMode | None

Expand source code

@property

def turn_detection(self) -> TurnDetectionMode | None:

return self._turn_detection

prop

user_state

: UserState

Expand source code

@property

def user_state(self) -> UserState:

return self._user_state

prop

userdata

: Userdata_T

Expand source code

@property

def userdata(self) -> Userdata_T:

if self._userdata is None:

raise ValueError("VoiceAgent userdata is not set")

return self._userdata

prop

vad

:

VAD

| None

Expand source code

@property

def vad(self) -> vad.VAD | None:

return self._vad

Methods

async def

aclose

(

self) ‑> None

Expand source code

async def aclose(self) -> None:

await self._aclose_impl(reason=CloseReason.USER_INITIATED)

def

clear_user_turn

(

self) ‑> None

Expand source code

def clear_user_turn(self) -> None:

# clear the transcription or input audio buffer of the user turn

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

self._activity.clear_user_turn()

def

commit_user_turn

(

self, *, transcript_timeout: float = 2.0, stt_flush_duration: float = 2.0) ‑> None

Expand source code

def commit_user_turn(

self, *, transcript_timeout: float = 2.0, stt_flush_duration: float = 2.0

) -> None:

"""Commit the user turn and generate a reply.

Args:

transcript_timeout (float, optional): The timeout for the final transcript

to be received after committing the user turn.

Increase this value if the STT is slow to respond.

stt_flush_duration (float, optional): The duration of the silence to be appended to the STT

to flush the buffer and generate the final transcript.

Raises:

RuntimeError: If the AgentSession isn't running.

"""

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

self._activity.commit_user_turn(

transcript_timeout=transcript_timeout, stt_flush_duration=stt_flush_duration

)

Commit the user turn and generate a reply.

Args

transcript_timeout

:

float

, optional

The timeout for the final transcript

to be received after committing the user turn.

Increase this value if the STT is slow to respond.

stt_flush_duration

:

float

, optional

The duration of the silence to be appended to the STT

to flush the buffer and generate the final transcript.

Raises

RuntimeError

If the AgentSession isn't running.

async def

drain

(

self) ‑> None

Expand source code

async def drain(self) -> None:

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

await self._activity.drain()

def

generate_reply

(

self,

*,

user_input: NotGivenOr[str] = NOT_GIVEN,

instructions: NotGivenOr[str] = NOT_GIVEN,

tool_choice: NotGivenOr[llm.ToolChoice] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN) ‑> livekit.agents.voice.speech_handle.SpeechHandle

Expand source code

def generate_reply(

self,

*,

user_input: NotGivenOr[str] = NOT_GIVEN,

instructions: NotGivenOr[str] = NOT_GIVEN,

tool_choice: NotGivenOr[llm.ToolChoice] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

) -> SpeechHandle:

"""Generate a reply for the agent to speak to the user.

Args:

user_input (NotGivenOr[str], optional): The user's input that may influence the reply,

such as answering a question.

instructions (NotGivenOr[str], optional): Additional instructions for generating the reply.

tool_choice (NotGivenOr[llm.ToolChoice], optional): Specifies the external tool to use when

generating the reply. If generate_reply is invoked within a function_tool, defaults to "none".

allow_interruptions (NotGivenOr[bool], optional): Indicates whether the user can interrupt this speech.

Returns:

SpeechHandle: A handle to the generated reply.

"""  # noqa: E501

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

user_message = (

llm.ChatMessage(role="user", content=[user_input])

if is_given(user_input)

else NOT_GIVEN

)

run_state = self._global_run_state

activity = self._next_activity if self._activity.scheduling_paused else self._activity

if activity is None:

raise RuntimeError("AgentSession is closing, cannot use generate_reply()")

handle = activity._generate_reply(

user_message=user_message,

instructions=instructions,

tool_choice=tool_choice,

allow_interruptions=allow_interruptions,

)

if run_state:

run_state._watch_handle(handle)

return handle

Generate a reply for the agent to speak to the user.

Args

user_input

:

NotGivenOr[str]

, optional

The user's input that may influence the reply,

such as answering a question.

instructions

:

NotGivenOr[str]

, optional

Additional instructions for generating the reply.

tool_choice

:

NotGivenOr[llm.ToolChoice]

, optional

Specifies the external tool to use when

generating the reply. If generate_reply is invoked within a function_tool, defaults to "none".

allow_interruptions

:

NotGivenOr[bool]

, optional

Indicates whether the user can interrupt this speech.

Returns

SpeechHandle

A handle to the generated reply.

def

interrupt

(

self, *, force: bool = False) ‑> _asyncio.Future[None]

Expand source code

def interrupt(self, *, force: bool = False) -> asyncio.Future[None]:

"""Interrupt the current speech generation.

Returns:

An asyncio.Future that completes when the interruption is fully processed

and chat context has been updated.

"""

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

return self._activity.interrupt(force=force)

Interrupt the current speech generation.

Returns

An asyncio.Future that completes when the interruption is fully processed

and chat context has been updated.

def

run

(

self, *, user_input: str, output_type: type[Run_T] | None = None) ‑>

RunResult

[~Run_T]

Expand source code

def run(self, *, user_input: str, output_type: type[Run_T] | None = None) -> RunResult[Run_T]:

if self._global_run_state is not None and not self._global_run_state.done():

raise RuntimeError("nested runs are not supported")

run_state = RunResult(user_input=user_input, output_type=output_type)

self._global_run_state = run_state

self.generate_reply(user_input=user_input)

return run_state

def

say

(

self,

text: str | AsyncIterable[str],

*,

audio: NotGivenOr[AsyncIterable[rtc.AudioFrame]] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

add_to_chat_ctx: bool = True) ‑> livekit.agents.voice.speech_handle.SpeechHandle

Expand source code

def say(

self,

text: str | AsyncIterable[str],

*,

audio: NotGivenOr[AsyncIterable[rtc.AudioFrame]] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

add_to_chat_ctx: bool = True,

) -> SpeechHandle:

if self._activity is None:

raise RuntimeError("AgentSession isn't running")

run_state = self._global_run_state

activity = self._next_activity if self._activity.scheduling_paused else self._activity

if activity is None:

raise RuntimeError("AgentSession is closing, cannot use say()")

handle = activity.say(

text,

audio=audio,

allow_interruptions=allow_interruptions,

add_to_chat_ctx=add_to_chat_ctx,

)

if run_state:

run_state._watch_handle(handle)

return handle

def

shutdown

(

self, *, drain: bool = True) ‑> None

Expand source code

def shutdown(self, *, drain: bool = True) -> None:

self._close_soon(error=None, drain=drain, reason=CloseReason.USER_INITIATED)

async def

start

(

self,

agent:

Agent

,

*,

capture_run: bool = False,

room: NotGivenOr[rtc.Room] = NOT_GIVEN,

room_input_options: NotGivenOr[room_io.RoomInputOptions] = NOT_GIVEN,

room_output_options: NotGivenOr[room_io.RoomOutputOptions] = NOT_GIVEN) ‑>

RunResult

| None

Expand source code

@tracer.start_as_current_span("agent_session", end_on_exit=False)

async def start(

self,

agent: Agent,

*,

capture_run: bool = False,

room: NotGivenOr[rtc.Room] = NOT_GIVEN,

room_input_options: NotGivenOr[room_io.RoomInputOptions] = NOT_GIVEN,

room_output_options: NotGivenOr[room_io.RoomOutputOptions] = NOT_GIVEN,

) -> RunResult | None:

"""Start the voice agent.

Create a default RoomIO if the input or output audio is not already set.

If the console flag is provided, start a ChatCLI.

Args:

capture_run: Whether to return a RunResult and capture the run result during session start.

room: The room to use for input and output

room_input_options: Options for the room input

room_output_options: Options for the room output

"""

async with self._lock:

if self._started:

return None

self._closing = False

self._root_span_context = otel_context.get_current()

self._session_span = current_span = trace.get_current_span()

current_span = trace.get_current_span()

current_span.set_attribute(trace_types.ATTR_AGENT_LABEL, agent.label)

current_span.set_attribute(

trace_types.ATTR_SESSION_OPTIONS,

json.dumps({k: v for k, v in asdict(self._opts).items() if is_given(v)}),

)

self._agent = agent

self._update_agent_state("initializing")

tasks: list[asyncio.Task[None]] = []

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

from .chat_cli import ChatCLI

if (

self.input.audio is not None

or self.output.audio is not None

or self.output.transcription is not None

):

logger.warning(

"agent started with the console subcommand, but input.audio or output.audio "  # noqa: E501

"or output.transcription is already set, overriding.."

)

chat_cli = ChatCLI(self)

tasks.append(asyncio.create_task(chat_cli.start(), name="_chat_cli_start"))

elif is_given(room) and not self._room_io:

room_input_options = copy.copy(

room_input_options or room_io.DEFAULT_ROOM_INPUT_OPTIONS

)

room_output_options = copy.copy(

room_output_options or room_io.DEFAULT_ROOM_OUTPUT_OPTIONS

)

if self.input.audio is not None:

if room_input_options.audio_enabled:

logger.warning(

"RoomIO audio input is enabled but input.audio is already set, ignoring.."  # noqa: E501

)

room_input_options.audio_enabled = False

if self.output.audio is not None:

if room_output_options.audio_enabled:

logger.warning(

"RoomIO audio output is enabled but output.audio is already set, ignoring.."  # noqa: E501

)

room_output_options.audio_enabled = False

if self.output.transcription is not None:

if room_output_options.transcription_enabled:

logger.warning(

"RoomIO transcription output is enabled but output.transcription is already set, ignoring.."  # noqa: E501

)

room_output_options.transcription_enabled = False

self._room_io = room_io.RoomIO(

room=room,

agent_session=self,

input_options=room_input_options,

output_options=room_output_options,

)

tasks.append(asyncio.create_task(self._room_io.start(), name="_room_io_start"))

# session can be restarted, register the callbacks only once

try:

job_ctx = get_job_context()

current_span.set_attribute(trace_types.ATTR_ROOM_NAME, job_ctx.room.name)

current_span.set_attribute(trace_types.ATTR_JOB_ID, job_ctx.job.id)

current_span.set_attribute(trace_types.ATTR_AGENT_NAME, job_ctx.job.agent_name)

if self._room_io:

# automatically connect to the room when room io is used

tasks.append(asyncio.create_task(job_ctx.connect(), name="_job_ctx_connect"))

if not self._job_context_cb_registered:

job_ctx.add_shutdown_callback(

lambda: self._aclose_impl(reason=CloseReason.JOB_SHUTDOWN)

)

self._job_context_cb_registered = True

except RuntimeError:

pass  # ignore

run_state: RunResult | None = None

if capture_run:

if self._global_run_state is not None and not self._global_run_state.done():

raise RuntimeError("nested runs are not supported")

run_state = RunResult(output_type=None)

self._global_run_state = run_state

# it is ok to await it directly, there is no previous task to drain

tasks.append(

asyncio.create_task(self._update_activity(self._agent, wait_on_enter=False))

)

try:

await asyncio.gather(*tasks)

finally:

await utils.aio.cancel_and_wait(*tasks)

# important: no await should be done after this!

if self.input.audio is not None:

self._forward_audio_atask = asyncio.create_task(

self._forward_audio_task(), name="_forward_audio_task"

)

if self.input.video is not None:

self._forward_video_atask = asyncio.create_task(

self._forward_video_task(), name="_forward_video_task"

)

self._started = True

self._update_agent_state("listening")

if self._room_io and self._room_io.subscribed_fut:

def on_room_io_subscribed(_: asyncio.Future[None]) -> None:

if self._user_state == "listening" and self._agent_state == "listening":

self._set_user_away_timer()

self._room_io.subscribed_fut.add_done_callback(on_room_io_subscribed)

# log used IO

def _collect_source(

inp: io.AudioInput | io.VideoInput | None,

) -> list[io.AudioInput | io.VideoInput]:

return [] if inp is None else [inp] + _collect_source(inp.source)

def _collect_chain(

out: io.TextOutput | io.VideoOutput | io.AudioOutput | None,

) -> list[io.VideoOutput | io.AudioOutput | io.TextOutput]:

return [] if out is None else [out] + _collect_chain(out.next_in_chain)

audio_input = _collect_source(self.input.audio)[::-1]

video_input = _collect_source(self.input.video)[::-1]

audio_output = _collect_chain(self.output.audio)

video_output = _collect_chain(self.output.video)

transcript_output = _collect_chain(self.output.transcription)

logger.debug(

"using audio io: %s -> `AgentSession` -> %s",

" -> ".join([f"`{out.label}`" for out in audio_input]) or "(none)",

" -> ".join([f"`{out.label}`" for out in audio_output]) or "(none)",

)

if (

self._opts.resume_false_interruption

and self.output.audio

and not self.output.audio.can_pause

):

logger.warning(

"resume_false_interruption is enabled but audio output does not support pause, it will be ignored",

extra={"audio_output": self.output.audio.label},

)

logger.debug(

"using transcript io: `AgentSession` -> %s",

" -> ".join([f"`{out.label}`" for out in transcript_output]) or "(none)",

)

if video_input or video_output:

logger.debug(

"using video io: %s > `AgentSession` > %s",

" -> ".join([f"`{out.label}`" for out in video_input]) or "(none)",

" -> ".join([f"`{out.label}`" for out in video_output]) or "(none)",

)

if run_state:

await run_state

return run_state

Start the voice agent.

Create a default RoomIO if the input or output audio is not already set.

If the console flag is provided, start a ChatCLI.

Args

capture_run

Whether to return a RunResult and capture the run result during session start.

room

The room to use for input and output

room_input_options

Options for the room input

room_output_options

Options for the room output

def

update_agent

(

self,

agent:

Agent

) ‑> None

Expand source code

def update_agent(self, agent: Agent) -> None:

self._agent = agent

if self._started:

self._update_activity_atask = task = asyncio.create_task(

self._update_activity_task(self._update_activity_atask, self._agent),

name="_update_activity_task",

)

run_state = self._global_run_state

if run_state:

# don't mark the RunResult as done, if there is currently an agent transition happening.  # noqa: E501

# (used to make sure we're correctly adding the AgentHandoffResult before completion)  # noqa: E501

run_state._watch_handle(task)

def

update_options

(

self,

*,

min_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

max_endpointing_delay: NotGivenOr[float] = NOT_GIVEN) ‑> None

Expand source code

def update_options(

self,

*,

min_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

max_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

) -> None:

"""

Update the options for the agent session.

Args:

min_endpointing_delay (NotGivenOr[float], optional): The minimum endpointing delay.

max_endpointing_delay (NotGivenOr[float], optional): The maximum endpointing delay.

"""

if is_given(min_endpointing_delay):

self._opts.min_endpointing_delay = min_endpointing_delay

if is_given(max_endpointing_delay):

self._opts.max_endpointing_delay = max_endpointing_delay

if self._activity is not None:

self._activity.update_options(

min_endpointing_delay=min_endpointing_delay,

max_endpointing_delay=max_endpointing_delay,

)

Update the options for the agent session.

Args

min_endpointing_delay

:

NotGivenOr[float]

, optional

The minimum endpointing delay.

max_endpointing_delay

:

NotGivenOr[float]

, optional

The maximum endpointing delay.

Inherited members

EventEmitter

:

emit

off

on

once

class

AgentStateChangedEvent

(

**data: Any)

Expand source code

class AgentStateChangedEvent(BaseModel):

type: Literal["agent_state_changed"] = "agent_state_changed"

old_state: AgentState

new_state: AgentState

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

model_config

var

new_state

: Literal['initializing', 'idle', 'listening', 'thinking', 'speaking']

var

old_state

: Literal['initializing', 'idle', 'listening', 'thinking', 'speaking']

var

type

: Literal['agent_state_changed']

class

AgentTask

(

*,

instructions: str,

chat_ctx: NotGivenOr[

ChatContext

] = NOT_GIVEN,

tools: list[

FunctionTool

|

RawFunctionTool

] | None = None,

turn_detection: NotGivenOr[TurnDetectionMode | None] = NOT_GIVEN,

stt: NotGivenOr[

STT

| None] = NOT_GIVEN,

vad: NotGivenOr[

VAD

| None] = NOT_GIVEN,

llm: NotGivenOr[

LLM

|

RealtimeModel

| None] = NOT_GIVEN,

tts: NotGivenOr[

TTS

| None] = NOT_GIVEN,

mcp_servers: NotGivenOr[list[mcp.MCPServer] | None] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

min_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

max_endpointing_delay: NotGivenOr[float] = NOT_GIVEN)

Expand source code

class AgentTask(Agent, Generic[TaskResult_T]):

def __init__(

self,

*,

instructions: str,

chat_ctx: NotGivenOr[llm.ChatContext] = NOT_GIVEN,

tools: list[llm.FunctionTool | llm.RawFunctionTool] | None = None,

turn_detection: NotGivenOr[TurnDetectionMode | None] = NOT_GIVEN,

stt: NotGivenOr[stt.STT | None] = NOT_GIVEN,

vad: NotGivenOr[vad.VAD | None] = NOT_GIVEN,

llm: NotGivenOr[llm.LLM | llm.RealtimeModel | None] = NOT_GIVEN,

tts: NotGivenOr[tts.TTS | None] = NOT_GIVEN,

mcp_servers: NotGivenOr[list[mcp.MCPServer] | None] = NOT_GIVEN,

allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,

min_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

max_endpointing_delay: NotGivenOr[float] = NOT_GIVEN,

) -> None:

tools = tools or []

super().__init__(

instructions=instructions,

chat_ctx=chat_ctx,

tools=tools,

turn_detection=turn_detection,

stt=stt,

vad=vad,

llm=llm,

tts=tts,

mcp_servers=mcp_servers,

allow_interruptions=allow_interruptions,

min_endpointing_delay=min_endpointing_delay,

max_endpointing_delay=max_endpointing_delay,

)

self.__started = False

self.__fut = asyncio.Future[TaskResult_T]()

def done(self) -> bool:

return self.__fut.done()

def complete(self, result: TaskResult_T | Exception) -> None:

if self.__fut.done():

raise RuntimeError(f"{self.__class__.__name__} is already done")

if isinstance(result, Exception):

self.__fut.set_exception(result)

else:

self.__fut.set_result(result)

self.__fut.exception()  # silence exc not retrieved warnings

from .agent_activity import _SpeechHandleContextVar

speech_handle = _SpeechHandleContextVar.get(None)

if speech_handle:

speech_handle._maybe_run_final_output = result

# if not self.__inline_mode:

#    session._close_soon(reason=CloseReason.TASK_COMPLETED, drain=True)

async def __await_impl(self) -> TaskResult_T:

if self.__started:

raise RuntimeError(f"{self.__class__.__name__} is not re-entrant, await only once")

self.__started = True

current_task = asyncio.current_task()

if current_task is None:

raise RuntimeError(

f"{self.__class__.__name__} must be executed inside an async context"

)

task_info = _get_activity_task_info(current_task)

if not task_info or not task_info.inline_task:

raise RuntimeError(

f"{self.__class__.__name__} should only be awaited inside tool_functions or the on_enter/on_exit methods of an Agent"  # noqa: E501

)

def _handle_task_done(_: asyncio.Task[Any]) -> None:

if self.__fut.done():

return

# if the asyncio.Task running the InlineTask completes before the InlineTask itself, log

# an error and attempt to recover by terminating the InlineTask.

logger.error(

f"The asyncio.Task finished before {self.__class__.__name__} was completed."

)

self.complete(

RuntimeError(

f"The asyncio.Task finished before {self.__class__.__name__} was completed."

)

)

current_task.add_done_callback(_handle_task_done)

from .agent_activity import _AgentActivityContextVar, _SpeechHandleContextVar

# TODO(theomonnom): add a global lock for inline tasks

# This may currently break in the case we use parallel tool calls.

speech_handle = _SpeechHandleContextVar.get(None)

old_activity = _AgentActivityContextVar.get()

old_agent = old_activity.agent

session = old_activity.session

if (

task_info.function_call

and isinstance(old_activity.llm, RealtimeModel)

and not old_activity.llm.capabilities.manual_function_calls

):

logger.error(

f"Realtime model '{old_activity.llm.label}' does not support resuming function calls from chat context, "

"using AgentTask inside a function tool may have unexpected behavior."

)

# TODO(theomonnom): could the RunResult watcher & the blocked_tasks share the same logic?

await session._update_activity(

self, previous_activity="pause", blocked_tasks=[current_task]

)

# NOTE: _update_activity is calling the on_enter method, so the RunResult can capture all speeches

run_state = session._global_run_state

if speech_handle and run_state and not run_state.done():

# make sure to not deadlock on the current speech handle

run_state._unwatch_handle(speech_handle)

# it is OK to call _mark_done_if_needed here, the above _update_activity will call on_enter

# so handles added inside the on_enter will make sure we're not completing the run_state too early.

run_state._mark_done_if_needed(None)

try:

return await asyncio.shield(self.__fut)

finally:

# run_state could have changed after self.__fut

run_state = session._global_run_state

if session.current_agent != self:

logger.warning(

f"{self.__class__.__name__} completed, but the agent has changed in the meantime. "

"Ignoring handoff to the previous agent, likely due to `AgentSession.update_agent` being invoked."

)

await old_activity.aclose()

else:

if speech_handle and run_state and not run_state.done():

run_state._watch_handle(speech_handle)

merged_chat_ctx = old_agent.chat_ctx.merge(

self.chat_ctx, exclude_function_call=True, exclude_instructions=True

)

# set the chat_ctx directly, `session._update_activity` will sync it to the rt_session if needed

old_agent._chat_ctx.items[:] = merged_chat_ctx.items

# await old_agent.update_chat_ctx(merged_chat_ctx)

await session._update_activity(

old_agent, new_activity="resume", wait_on_enter=False

)

def __await__(self) -> Generator[None, None, TaskResult_T]:

return self.__await_impl().__await__()

Abstract base class for generic types.

On Python 3.12 and newer, generic classes implicitly inherit from

Generic when they declare a parameter list after the class's name::

class Mapping[KT, VT]:

def __getitem__(self, key: KT) -> VT:

...

# Etc.

On older versions of Python, however, generic classes have to

explicitly inherit from Generic.

After a class has been declared to be generic, it can then be used as

follows::

def lookup_name[KT, VT](mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:

try:

return mapping[key]

except KeyError:

return default

Ancestors

livekit.agents.voice.agent.Agent

typing.Generic

Subclasses

GetEmailTask

Methods

def

complete

(

self, result: TaskResult_T | Exception) ‑> None

Expand source code

def complete(self, result: TaskResult_T | Exception) -> None:

if self.__fut.done():

raise RuntimeError(f"{self.__class__.__name__} is already done")

if isinstance(result, Exception):

self.__fut.set_exception(result)

else:

self.__fut.set_result(result)

self.__fut.exception()  # silence exc not retrieved warnings

from .agent_activity import _SpeechHandleContextVar

speech_handle = _SpeechHandleContextVar.get(None)

if speech_handle:

speech_handle._maybe_run_final_output = result

# if not self.__inline_mode:

#    session._close_soon(reason=CloseReason.TASK_COMPLETED, drain=True)

def

done

(

self) ‑> bool

Expand source code

def done(self) -> bool:

return self.__fut.done()

class

AssignmentTimeoutError

(

*args, **kwargs)

Expand source code

class AssignmentTimeoutError(Exception):

"""Raised when accepting a job but not receiving an assignment within the specified timeout.

The server may have chosen another worker to handle this job."""

pass

Raised when accepting a job but not receiving an assignment within the specified timeout.

The server may have chosen another worker to handle this job.

Ancestors

builtins.Exception

builtins.BaseException

class

AudioConfig

(

source: ForwardRef('AudioSource'),

volume: ForwardRef('float') = 1.0,

probability: ForwardRef('float') = 1.0)

Expand source code

class AudioConfig(NamedTuple):

"""

Definition for the audio to be played in the background

Args:

volume: The volume of the audio (0.0-1.0)

probability: The probability of the audio being played, when multiple

AudioConfigs are provided (0.0-1.0)

"""

source: AudioSource

volume: float = 1.0

probability: float = 1.0

Definition for the audio to be played in the background

Args

volume

The volume of the audio (0.0-1.0)

probability

The probability of the audio being played, when multiple

AudioConfigs are provided (0.0-1.0)

Ancestors

builtins.tuple

Instance variables

var

probability

: float

Expand source code

class AudioConfig(NamedTuple):

"""

Definition for the audio to be played in the background

Args:

volume: The volume of the audio (0.0-1.0)

probability: The probability of the audio being played, when multiple

AudioConfigs are provided (0.0-1.0)

"""

source: AudioSource

volume: float = 1.0

probability: float = 1.0

Alias for field number 2

var

source

: AsyncIterator[

AudioFrame

] | str |

BuiltinAudioClip

Expand source code

class AudioConfig(NamedTuple):

"""

Definition for the audio to be played in the background

Args:

volume: The volume of the audio (0.0-1.0)

probability: The probability of the audio being played, when multiple

AudioConfigs are provided (0.0-1.0)

"""

source: AudioSource

volume: float = 1.0

probability: float = 1.0

Alias for field number 0

var

volume

: float

Expand source code

class AudioConfig(NamedTuple):

"""

Definition for the audio to be played in the background

Args:

volume: The volume of the audio (0.0-1.0)

probability: The probability of the audio being played, when multiple

AudioConfigs are provided (0.0-1.0)

"""

source: AudioSource

volume: float = 1.0

probability: float = 1.0

Alias for field number 1

class

AutoSubscribe

(

*args, **kwds)

Expand source code

class AutoSubscribe(str, Enum):

SUBSCRIBE_ALL = "subscribe_all"

SUBSCRIBE_NONE = "subscribe_none"

AUDIO_ONLY = "audio_only"

VIDEO_ONLY = "video_only"

str(object='') -> str

str(bytes_or_buffer[, encoding[, errors]]) -> str

Create a new string object from the given object. If encoding or

errors is specified, then the object must expose a data buffer

that will be decoded using the given encoding and error handler.

Otherwise, returns the result of object.

str

() (if defined)

or repr(object).

encoding defaults to sys.getdefaultencoding().

errors defaults to 'strict'.

Ancestors

builtins.str

enum.Enum

Class variables

var

AUDIO_ONLY

var

SUBSCRIBE_ALL

var

SUBSCRIBE_NONE

var

VIDEO_ONLY

class

BackgroundAudioPlayer

(

*,

ambient_sound: NotGivenOr[AudioSource |

AudioConfig

| list[

AudioConfig

] | None] = NOT_GIVEN,

thinking_sound: NotGivenOr[AudioSource |

AudioConfig

| list[

AudioConfig

] | None] = NOT_GIVEN,

stream_timeout_ms: int = 200)

Expand source code

class BackgroundAudioPlayer:

def __init__(

self,

*,

ambient_sound: NotGivenOr[AudioSource | AudioConfig | list[AudioConfig] | None] = NOT_GIVEN,

thinking_sound: NotGivenOr[

AudioSource | AudioConfig | list[AudioConfig] | None

] = NOT_GIVEN,

stream_timeout_ms: int = 200,

) -> None:

"""

Initializes the BackgroundAudio component with optional ambient and thinking sounds.

This component creates and publishes a continuous audio track to a LiveKit room while managing

the playback of ambient and agent “thinking” sounds. It supports three types of audio sources:

- A BuiltinAudioClip enum value, which will use a pre-defined sound from the package resources

- A file path (string) pointing to an audio file, which can be looped.

- An AsyncIterator that yields rtc.AudioFrame

When a list (or AudioConfig) is supplied, the component considers each sound’s volume and probability:

- The probability value determines the chance that a particular sound is selected for playback.

- A total probability below 1.0 means there is a chance no sound will be selected (resulting in silence).

Args:

ambient_sound (NotGivenOr[Union[AudioSource, AudioConfig, List[AudioConfig], None]], optional):

The ambient sound to be played continuously. For file paths, the sound will be looped.

For AsyncIterator sources, ensure the iterator is infinite or looped.

thinking_sound (NotGivenOr[Union[AudioSource, AudioConfig, List[AudioConfig], None]], optional):

The sound to be played when the associated agent enters a “thinking” state. This can be a single

sound source or a list of AudioConfig objects (with volume and probability settings).

"""  # noqa: E501

self._ambient_sound = ambient_sound if is_given(ambient_sound) else None

self._thinking_sound = thinking_sound if is_given(thinking_sound) else None

self._audio_source = rtc.AudioSource(48000, 1, queue_size_ms=_AUDIO_SOURCE_BUFFER_MS)

self._audio_mixer = rtc.AudioMixer(

48000, 1, blocksize=4800, capacity=1, stream_timeout_ms=stream_timeout_ms

)

self.publication: rtc.LocalTrackPublication | None = None

self._lock = asyncio.Lock()

self._republish_task: asyncio.Task[None] | None = None  # republish the task on reconnect

self._mixer_atask: asyncio.Task[None] | None = None

self._play_tasks: list[asyncio.Task[None]] = []

self._ambient_handle: PlayHandle | None = None

self._thinking_handle: PlayHandle | None = None

def _select_sound_from_list(self, sounds: list[AudioConfig]) -> AudioConfig | None:

"""

Selects a sound from a list of BackgroundSound based on their probabilities.

Returns None if no sound is selected (when sum of probabilities < 1.0).

"""

total_probability = sum(sound.probability for sound in sounds)

if total_probability <= 0:

return None

if total_probability < 1.0 and random.random() > total_probability:

return None

normalize_factor = 1.0 if total_probability <= 1.0 else total_probability

r = random.random() * min(total_probability, 1.0)

cumulative = 0.0

for sound in sounds:

if sound.probability <= 0:

continue

norm_prob = sound.probability / normalize_factor

cumulative += norm_prob

if r <= cumulative:

return sound

return sounds[-1]

def _normalize_sound_source(

self, source: AudioSource | AudioConfig | list[AudioConfig] | None

) -> tuple[AudioSource, float] | None:

if source is None:

return None

if isinstance(source, BuiltinAudioClip):

return self._normalize_builtin_audio(source), 1.0

elif isinstance(source, list):

selected = self._select_sound_from_list(cast(list[AudioConfig], source))

if selected is None:

return None

return selected.source, selected.volume

elif isinstance(source, AudioConfig):

return self._normalize_builtin_audio(source.source), source.volume

return source, 1.0

def _normalize_builtin_audio(self, source: AudioSource) -> AsyncIterator[rtc.AudioFrame] | str:

if isinstance(source, BuiltinAudioClip):

return source.path()

else:

return source

def play(

self,

audio: AudioSource | AudioConfig | list[AudioConfig],

*,

loop: bool = False,

) -> PlayHandle:

"""

Plays an audio once or in a loop.

Args:

audio (Union[AudioSource, AudioConfig, List[AudioConfig]]):

The audio to play. Can be:

- A string pointing to a file path

- An AsyncIterator that yields `rtc.AudioFrame`

- An AudioConfig object with volume and probability

- A list of AudioConfig objects, where one will be selected based on probability

If a string is provided and `loop` is True, the sound will be looped.

If an AsyncIterator is provided, it is played until exhaustion (and cannot be looped

automatically).

loop (bool, optional):

Whether to loop the audio. Only applicable if `audio` is a string or contains strings.

Defaults to False.

Returns:

PlayHandle: An object representing the playback handle. This can be

awaited or stopped manually.

"""  # noqa: E501

if not self._mixer_atask:

raise RuntimeError("BackgroundAudio is not started")

normalized = self._normalize_sound_source(audio)

if normalized is None:

play_handle = PlayHandle()

play_handle._mark_playout_done()

return play_handle

sound_source, volume = normalized

if loop and isinstance(sound_source, AsyncIterator):

raise ValueError(

"Looping sound via AsyncIterator is not supported. Use a string file path or your own 'infinite' AsyncIterator with loop=False"  # noqa: E501

)

play_handle = PlayHandle()

task = asyncio.create_task(self._play_task(play_handle, sound_source, volume, loop))

task.add_done_callback(lambda _: self._play_tasks.remove(task))

task.add_done_callback(lambda _: play_handle._mark_playout_done())

self._play_tasks.append(task)

return play_handle

async def start(

self,

*,

room: rtc.Room,

agent_session: NotGivenOr[AgentSession] = NOT_GIVEN,

track_publish_options: NotGivenOr[rtc.TrackPublishOptions] = NOT_GIVEN,

) -> None:

"""

Starts the background audio system, publishing the audio track

and beginning playback of any configured ambient sound.

If `ambient_sound` is provided (and contains file paths), they will loop

automatically. If `ambient_sound` contains AsyncIterators, they are assumed

to be already infinite or looped.

Args:

room (rtc.Room):

The LiveKit Room object where the audio track will be published.

agent_session (NotGivenOr[AgentSession], optional):

The session object used to track the agent's state (e.g., "thinking").

Required if `thinking_sound` is provided.

track_publish_options (NotGivenOr[rtc.TrackPublishOptions], optional):

Options used when publishing the audio track. If not given, defaults will

be used.

"""

async with self._lock:

self._room = room

self._agent_session = agent_session or None

self._track_publish_options = track_publish_options or None

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning(

"Background audio is not supported in console mode. Audio will not be played."

)

await self._publish_track()

self._mixer_atask = asyncio.create_task(self._run_mixer_task())

self._room.on("reconnected", self._on_reconnected)

if self._agent_session:

self._agent_session.on("agent_state_changed", self._agent_state_changed)

if self._ambient_sound:

normalized = self._normalize_sound_source(

cast(Union[AudioSource, AudioConfig, list[AudioConfig]], self._ambient_sound)

)

if normalized:

sound_source, volume = normalized

selected_sound = AudioConfig(sound_source, volume)

if isinstance(sound_source, str):

self._ambient_handle = self.play(selected_sound, loop=True)

else:

self._ambient_handle = self.play(selected_sound)

async def aclose(self) -> None:

"""

Gracefully closes the background audio system, canceling all ongoing

playback tasks and unpublishing the audio track.

"""

async with self._lock:

if not self._mixer_atask:

return  # not started

await cancel_and_wait(*self._play_tasks)

if self._republish_task:

await cancel_and_wait(self._republish_task)

await cancel_and_wait(self._mixer_atask)

self._mixer_atask = None

await self._audio_mixer.aclose()

await self._audio_source.aclose()

if self._agent_session:

self._agent_session.off("agent_state_changed", self._agent_state_changed)

self._room.off("reconnected", self._on_reconnected)

with contextlib.suppress(Exception):

if self.publication is not None:

await self._room.local_participant.unpublish_track(self.publication.sid)

def _on_reconnected(self) -> None:

if self._republish_task:

self._republish_task.cancel()

self.publication = None

self._republish_task = asyncio.create_task(self._republish_track_task())

def _agent_state_changed(self, ev: AgentStateChangedEvent) -> None:

if not self._thinking_sound:

return

if ev.new_state == "thinking":

if self._thinking_handle and not self._thinking_handle.done():

return

assert self._thinking_sound is not None

self._thinking_handle = self.play(

cast(Union[AudioSource, AudioConfig, list[AudioConfig]], self._thinking_sound)

)

elif self._thinking_handle:

self._thinking_handle.stop()

@log_exceptions(logger=logger)

async def _play_task(

self, play_handle: PlayHandle, sound: AudioSource, volume: float, loop: bool

) -> None:

if isinstance(sound, BuiltinAudioClip):

sound = sound.path()

if isinstance(sound, str):

if loop:

sound = _loop_audio_frames(sound)

else:

sound = audio_frames_from_file(sound)

async def _gen_wrapper() -> AsyncGenerator[rtc.AudioFrame, None]:

async for frame in sound:

if volume != 1.0:

data = np.frombuffer(frame.data, dtype=np.int16).astype(np.float32)

data *= 10 ** (np.log10(volume))

np.clip(data, -32768, 32767, out=data)

yield rtc.AudioFrame(

data=data.astype(np.int16).tobytes(),

sample_rate=frame.sample_rate,

num_channels=frame.num_channels,

samples_per_channel=frame.samples_per_channel,

)

else:

yield frame

# TODO(theomonnom): the wait_for_playout() may be innaccurate by 400ms

play_handle._mark_playout_done()

gen = _gen_wrapper()

try:

self._audio_mixer.add_stream(gen)

await play_handle.wait_for_playout()  # wait for playout or interruption

finally:

self._audio_mixer.remove_stream(gen)

play_handle._mark_playout_done()

await asyncio.sleep(0)

if play_handle._stop_fut.done():

await gen.aclose()

@log_exceptions(logger=logger)

async def _run_mixer_task(self) -> None:

async for frame in self._audio_mixer:

await self._audio_source.capture_frame(frame)

async def _publish_track(self) -> None:

if self.publication is not None:

return

track = rtc.LocalAudioTrack.create_audio_track("background_audio", self._audio_source)

self.publication = await self._room.local_participant.publish_track(

track, self._track_publish_options or rtc.TrackPublishOptions()

)

@log_exceptions(logger=logger)

async def _republish_track_task(self) -> None:

# used to republish the track on agent reconnect

async with self._lock:

await self._publish_track()

Initializes the BackgroundAudio component with optional ambient and thinking sounds.

This component creates and publishes a continuous audio track to a LiveKit room while managing

the playback of ambient and agent “thinking” sounds. It supports three types of audio sources:

- A BuiltinAudioClip enum value, which will use a pre-defined sound from the package resources

- A file path (string) pointing to an audio file, which can be looped.

- An AsyncIterator that yields rtc.AudioFrame

When a list (or AudioConfig) is supplied, the component considers each sound’s volume and probability:

- The probability value determines the chance that a particular sound is selected for playback.

- A total probability below 1.0 means there is a chance no sound will be selected (resulting in silence).

Args

ambient_sound (NotGivenOr[Union[AudioSource, AudioConfig, List[AudioConfig], None]], optional):

The ambient sound to be played continuously. For file paths, the sound will be looped.

For AsyncIterator sources, ensure the iterator is infinite or looped.

thinking_sound (NotGivenOr[Union[AudioSource, AudioConfig, List[AudioConfig], None]], optional):

The sound to be played when the associated agent enters a “thinking” state. This can be a single

sound source or a list of AudioConfig objects (with volume and probability settings).

Methods

async def

aclose

(

self) ‑> None

Expand source code

async def aclose(self) -> None:

"""

Gracefully closes the background audio system, canceling all ongoing

playback tasks and unpublishing the audio track.

"""

async with self._lock:

if not self._mixer_atask:

return  # not started

await cancel_and_wait(*self._play_tasks)

if self._republish_task:

await cancel_and_wait(self._republish_task)

await cancel_and_wait(self._mixer_atask)

self._mixer_atask = None

await self._audio_mixer.aclose()

await self._audio_source.aclose()

if self._agent_session:

self._agent_session.off("agent_state_changed", self._agent_state_changed)

self._room.off("reconnected", self._on_reconnected)

with contextlib.suppress(Exception):

if self.publication is not None:

await self._room.local_participant.unpublish_track(self.publication.sid)

Gracefully closes the background audio system, canceling all ongoing

playback tasks and unpublishing the audio track.

def

play

(

self,

audio: AudioSource |

AudioConfig

| list[

AudioConfig

],

*,

loop: bool = False) ‑>

PlayHandle

Expand source code

def play(

self,

audio: AudioSource | AudioConfig | list[AudioConfig],

*,

loop: bool = False,

) -> PlayHandle:

"""

Plays an audio once or in a loop.

Args:

audio (Union[AudioSource, AudioConfig, List[AudioConfig]]):

The audio to play. Can be:

- A string pointing to a file path

- An AsyncIterator that yields `rtc.AudioFrame`

- An AudioConfig object with volume and probability

- A list of AudioConfig objects, where one will be selected based on probability

If a string is provided and `loop` is True, the sound will be looped.

If an AsyncIterator is provided, it is played until exhaustion (and cannot be looped

automatically).

loop (bool, optional):

Whether to loop the audio. Only applicable if `audio` is a string or contains strings.

Defaults to False.

Returns:

PlayHandle: An object representing the playback handle. This can be

awaited or stopped manually.

"""  # noqa: E501

if not self._mixer_atask:

raise RuntimeError("BackgroundAudio is not started")

normalized = self._normalize_sound_source(audio)

if normalized is None:

play_handle = PlayHandle()

play_handle._mark_playout_done()

return play_handle

sound_source, volume = normalized

if loop and isinstance(sound_source, AsyncIterator):

raise ValueError(

"Looping sound via AsyncIterator is not supported. Use a string file path or your own 'infinite' AsyncIterator with loop=False"  # noqa: E501

)

play_handle = PlayHandle()

task = asyncio.create_task(self._play_task(play_handle, sound_source, volume, loop))

task.add_done_callback(lambda _: self._play_tasks.remove(task))

task.add_done_callback(lambda _: play_handle._mark_playout_done())

self._play_tasks.append(task)

return play_handle

Plays an audio once or in a loop.

Args

audio (Union[AudioSource, AudioConfig, List[AudioConfig]]):

The audio to play. Can be:

- A string pointing to a file path

- An AsyncIterator that yields

rtc.AudioFrame

- An AudioConfig object with volume and probability

- A list of AudioConfig objects, where one will be selected based on probability

If a string is provided and <code>loop</code> is True, the sound will be looped.

If an AsyncIterator is provided, it is played until exhaustion (and cannot be looped

automatically).

loop (bool, optional):

Whether to loop the audio. Only applicable if

audio

is a string or contains strings.

Defaults to False.

Returns

PlayHandle

An object representing the playback handle. This can be

awaited or stopped manually.

async def

start

(

self,

*,

room: rtc.Room,

agent_session: NotGivenOr[

AgentSession

] = NOT_GIVEN,

track_publish_options: NotGivenOr[rtc.TrackPublishOptions] = NOT_GIVEN) ‑> None

Expand source code

async def start(

self,

*,

room: rtc.Room,

agent_session: NotGivenOr[AgentSession] = NOT_GIVEN,

track_publish_options: NotGivenOr[rtc.TrackPublishOptions] = NOT_GIVEN,

) -> None:

"""

Starts the background audio system, publishing the audio track

and beginning playback of any configured ambient sound.

If `ambient_sound` is provided (and contains file paths), they will loop

automatically. If `ambient_sound` contains AsyncIterators, they are assumed

to be already infinite or looped.

Args:

room (rtc.Room):

The LiveKit Room object where the audio track will be published.

agent_session (NotGivenOr[AgentSession], optional):

The session object used to track the agent's state (e.g., "thinking").

Required if `thinking_sound` is provided.

track_publish_options (NotGivenOr[rtc.TrackPublishOptions], optional):

Options used when publishing the audio track. If not given, defaults will

be used.

"""

async with self._lock:

self._room = room

self._agent_session = agent_session or None

self._track_publish_options = track_publish_options or None

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning(

"Background audio is not supported in console mode. Audio will not be played."

)

await self._publish_track()

self._mixer_atask = asyncio.create_task(self._run_mixer_task())

self._room.on("reconnected", self._on_reconnected)

if self._agent_session:

self._agent_session.on("agent_state_changed", self._agent_state_changed)

if self._ambient_sound:

normalized = self._normalize_sound_source(

cast(Union[AudioSource, AudioConfig, list[AudioConfig]], self._ambient_sound)

)

if normalized:

sound_source, volume = normalized

selected_sound = AudioConfig(sound_source, volume)

if isinstance(sound_source, str):

self._ambient_handle = self.play(selected_sound, loop=True)

else:

self._ambient_handle = self.play(selected_sound)

Starts the background audio system, publishing the audio track

and beginning playback of any configured ambient sound.

If

ambient_sound

is provided (and contains file paths), they will loop

automatically. If

ambient_sound

contains AsyncIterators, they are assumed

to be already infinite or looped.

Args

room (rtc.Room):

The LiveKit Room object where the audio track will be published.

agent_session (NotGivenOr[AgentSession], optional):

The session object used to track the agent's state (e.g., "thinking").

Required if

thinking_sound

is provided.

track_publish_options (NotGivenOr[rtc.TrackPublishOptions], optional):

Options used when publishing the audio track. If not given, defaults will

be used.

class

BuiltinAudioClip

(

*args, **kwds)

Expand source code

class BuiltinAudioClip(enum.Enum):

OFFICE_AMBIENCE = "office-ambience.ogg"

KEYBOARD_TYPING = "keyboard-typing.ogg"

KEYBOARD_TYPING2 = "keyboard-typing2.ogg"

def path(self) -> str:

file_path = files("livekit.agents.resources") / self.value

return str(_resource_stack.enter_context(as_file(file_path)))

Create a collection of name/value pairs.

Example enumeration:

>>> class Color(Enum):

...     RED = 1

...     BLUE = 2

...     GREEN = 3

Access them by:

attribute access:

Color.RED

value lookup:

Color(1)

name lookup:

Color['RED']

Enumerations can be iterated over, and know how many members they have:

>>> len(Color)

3

>>> list(Color)

[<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]

Methods can be added to enumerations, and members can have their own

attributes – see the documentation for details.

Ancestors

enum.Enum

Class variables

var

KEYBOARD_TYPING

var

KEYBOARD_TYPING2

var

OFFICE_AMBIENCE

Methods

def

path

(

self) ‑> str

Expand source code

def path(self) -> str:

file_path = files("livekit.agents.resources") / self.value

return str(_resource_stack.enter_context(as_file(file_path)))

class

ChatContext

(

items: NotGivenOr[list[ChatItem]] = NOT_GIVEN)

Expand source code

class ChatContext:

def __init__(self, items: NotGivenOr[list[ChatItem]] = NOT_GIVEN):

self._items: list[ChatItem] = items if is_given(items) else []

@classmethod

def empty(cls) -> ChatContext:

return cls([])

@property

def items(self) -> list[ChatItem]:

return self._items

@items.setter

def items(self, items: list[ChatItem]) -> None:

self._items = items

def add_message(

self,

*,

role: ChatRole,

content: list[ChatContent] | str,

id: NotGivenOr[str] = NOT_GIVEN,

interrupted: NotGivenOr[bool] = NOT_GIVEN,

created_at: NotGivenOr[float] = NOT_GIVEN,

) -> ChatMessage:

kwargs: dict[str, Any] = {}

if is_given(id):

kwargs["id"] = id

if is_given(interrupted):

kwargs["interrupted"] = interrupted

if is_given(created_at):

kwargs["created_at"] = created_at

if isinstance(content, str):

message = ChatMessage(role=role, content=[content], **kwargs)

else:

message = ChatMessage(role=role, content=content, **kwargs)

if is_given(created_at):

idx = self.find_insertion_index(created_at=created_at)

self._items.insert(idx, message)

else:

self._items.append(message)

return message

def insert(self, item: ChatItem | Sequence[ChatItem]) -> None:

"""Insert an item or list of items into the chat context by creation time."""

items = list(item) if isinstance(item, Sequence) else [item]

for _item in items:

idx = self.find_insertion_index(created_at=_item.created_at)

self._items.insert(idx, _item)

def get_by_id(self, item_id: str) -> ChatItem | None:

return next((item for item in self.items if item.id == item_id), None)

def index_by_id(self, item_id: str) -> int | None:

return next((i for i, item in enumerate(self.items) if item.id == item_id), None)

def copy(

self,

*,

exclude_function_call: bool = False,

exclude_instructions: bool = False,

exclude_empty_message: bool = False,

tools: NotGivenOr[Sequence[FunctionTool | RawFunctionTool | str | Any]] = NOT_GIVEN,

) -> ChatContext:

items = []

from .tool_context import (

get_function_info,

get_raw_function_info,

is_function_tool,

is_raw_function_tool,

)

valid_tools = set[str]()

if is_given(tools):

for tool in tools:

if isinstance(tool, str):

valid_tools.add(tool)

elif is_function_tool(tool):

valid_tools.add(get_function_info(tool).name)

elif is_raw_function_tool(tool):

valid_tools.add(get_raw_function_info(tool).name)

# TODO(theomonnom): other tools

for item in self.items:

if exclude_function_call and item.type in [

"function_call",

"function_call_output",

]:

continue

if (

exclude_instructions

and item.type == "message"

and item.role in ["system", "developer"]

):

continue

if exclude_empty_message and item.type == "message" and not item.content:

continue

if (

is_given(tools)

and (item.type == "function_call" or item.type == "function_call_output")

and item.name not in valid_tools

):

continue

items.append(item)

return ChatContext(items)

def truncate(self, *, max_items: int) -> ChatContext:

"""Truncate the chat context to the last N items in place.

Removes leading function calls to avoid partial function outputs.

Preserves the first system message by adding it back to the beginning.

"""

if len(self._items) <= max_items:

return self

instructions = next(

(item for item in self._items if item.type == "message" and item.role == "system"),

None,

)

new_items = self._items[-max_items:]

# chat ctx shouldn't start with function_call or function_call_output

while new_items and new_items[0].type in [

"function_call",

"function_call_output",

]:

new_items.pop(0)

if instructions:

new_items.insert(0, instructions)

self._items[:] = new_items

return self

def merge(

self,

other_chat_ctx: ChatContext,

*,

exclude_function_call: bool = False,

exclude_instructions: bool = False,

) -> ChatContext:

"""Add messages from `other_chat_ctx` into this one, avoiding duplicates, and keep items sorted by created_at."""

existing_ids = {item.id for item in self._items}

for item in other_chat_ctx.items:

if exclude_function_call and item.type in [

"function_call",

"function_call_output",

]:

continue

if (

exclude_instructions

and item.type == "message"

and item.role in ["system", "developer"]

):

continue

if item.id not in existing_ids:

idx = self.find_insertion_index(created_at=item.created_at)

self._items.insert(idx, item)

existing_ids.add(item.id)

return self

def to_dict(

self,

*,

exclude_image: bool = True,

exclude_audio: bool = True,

exclude_timestamp: bool = True,

exclude_function_call: bool = False,

) -> dict[str, Any]:

items: list[ChatItem] = []

for item in self.items:

if exclude_function_call and item.type in [

"function_call",

"function_call_output",

]:

continue

if item.type == "message":

item = item.model_copy()

if exclude_image:

item.content = [c for c in item.content if not isinstance(c, ImageContent)]

if exclude_audio:

item.content = [c for c in item.content if not isinstance(c, AudioContent)]

items.append(item)

exclude_fields = set()

if exclude_timestamp:

exclude_fields.add("created_at")

return {

"items": [

item.model_dump(

mode="json",

exclude_none=True,

exclude_defaults=False,

exclude=exclude_fields,

)

for item in items

],

}

@overload

def to_provider_format(

self, format: Literal["openai"], *, inject_dummy_user_message: bool = True

) -> tuple[list[dict], Literal[None]]: ...

@overload

def to_provider_format(

self, format: Literal["google"], *, inject_dummy_user_message: bool = True

) -> tuple[list[dict], _provider_format.google.GoogleFormatData]: ...

@overload

def to_provider_format(

self, format: Literal["aws"], *, inject_dummy_user_message: bool = True

) -> tuple[list[dict], _provider_format.aws.BedrockFormatData]: ...

@overload

def to_provider_format(

self, format: Literal["anthropic"], *, inject_dummy_user_message: bool = True

) -> tuple[list[dict], _provider_format.anthropic.AnthropicFormatData]: ...

@overload

def to_provider_format(

self, format: Literal["mistralai"], *, inject_dummy_user_message: bool = True

) -> tuple[list[dict], Literal[None]]: ...

@overload

def to_provider_format(self, format: str, **kwargs: Any) -> tuple[list[dict], Any]: ...

def to_provider_format(

self,

format: Literal["openai", "google", "aws", "anthropic", "mistralai"] | str,

*,

inject_dummy_user_message: bool = True,

**kwargs: Any,

) -> tuple[list[dict], Any]:

"""Convert the chat context to a provider-specific format.

If ``inject_dummy_user_message`` is ``True``, a dummy user message will be added

to the beginning or end of the chat context depending on the provider.

This is necessary because some providers expect a user message to be present for

generating a response.

"""

kwargs["inject_dummy_user_message"] = inject_dummy_user_message

if format == "openai":

return _provider_format.openai.to_chat_ctx(self, **kwargs)

elif format == "google":

return _provider_format.google.to_chat_ctx(self, **kwargs)

elif format == "aws":

return _provider_format.aws.to_chat_ctx(self, **kwargs)

elif format == "anthropic":

return _provider_format.anthropic.to_chat_ctx(self, **kwargs)

elif format == "mistralai":

return _provider_format.mistralai.to_chat_ctx(self, **kwargs)

else:

raise ValueError(f"Unsupported provider format: {format}")

def find_insertion_index(self, *, created_at: float) -> int:

"""

Returns the index to insert an item by creation time.

Iterates in reverse, assuming items are sorted by `created_at`.

Finds the position after the last item with `created_at <=` the given timestamp.

"""

for i in reversed(range(len(self._items))):

if self._items[i].created_at <= created_at:

return i + 1

return 0

@classmethod

def from_dict(cls, data: dict[str, Any]) -> ChatContext:

item_adapter = TypeAdapter(list[ChatItem])

items = item_adapter.validate_python(data["items"])

return cls(items)

@property

def readonly(self) -> bool:

return False

def is_equivalent(self, other: ChatContext) -> bool:

"""

Return True if `other` has the same sequence of items with matching

essential fields (IDs, types, and payload) as this context.

Comparison rules:

- Messages: compares the full `content` list, `role` and `interrupted`.

- Function calls: compares `name`, `call_id`, and `arguments`.

- Function call outputs: compares `name`, `call_id`, `output`, and `is_error`.

Does not consider timestamps or other metadata.

"""

if self is other:

return True

if len(self.items) != len(other.items):

return False

for a, b in zip(self.items, other.items):

if a.id != b.id or a.type != b.type:

return False

if a.type == "message" and b.type == "message":

if a.role != b.role or a.interrupted != b.interrupted or a.content != b.content:

return False

elif a.type == "function_call" and b.type == "function_call":

if a.name != b.name or a.call_id != b.call_id or a.arguments != b.arguments:

return False

elif a.type == "function_call_output" and b.type == "function_call_output":

if (

a.name != b.name

or a.call_id != b.call_id

or a.output != b.output

or a.is_error != b.is_error

):

return False

return True

Subclasses

livekit.agents.llm.chat_context._ReadOnlyChatContext

Static methods

def

empty

(

) ‑> livekit.agents.llm.chat_context.ChatContext

def

from_dict

(

data: dict[str, Any]) ‑> livekit.agents.llm.chat_context.ChatContext

Instance variables

prop

items

: list[ChatItem]

Expand source code

@property

def items(self) -> list[ChatItem]:

return self._items

prop

readonly

: bool

Expand source code

@property

def readonly(self) -> bool:

return False

Methods

def

add_message

(

self,

*,

role: ChatRole,

content: list[ChatContent] | str,

id: NotGivenOr[str] = NOT_GIVEN,

interrupted: NotGivenOr[bool] = NOT_GIVEN,

created_at: NotGivenOr[float] = NOT_GIVEN) ‑> livekit.agents.llm.chat_context.ChatMessage

Expand source code

def add_message(

self,

*,

role: ChatRole,

content: list[ChatContent] | str,

id: NotGivenOr[str] = NOT_GIVEN,

interrupted: NotGivenOr[bool] = NOT_GIVEN,

created_at: NotGivenOr[float] = NOT_GIVEN,

) -> ChatMessage:

kwargs: dict[str, Any] = {}

if is_given(id):

kwargs["id"] = id

if is_given(interrupted):

kwargs["interrupted"] = interrupted

if is_given(created_at):

kwargs["created_at"] = created_at

if isinstance(content, str):

message = ChatMessage(role=role, content=[content], **kwargs)

else:

message = ChatMessage(role=role, content=content, **kwargs)

if is_given(created_at):

idx = self.find_insertion_index(created_at=created_at)

self._items.insert(idx, message)

else:

self._items.append(message)

return message

def

copy

(

self,

*,

exclude_function_call: bool = False,

exclude_instructions: bool = False,

exclude_empty_message: bool = False,

tools: NotGivenOr[Sequence[

FunctionTool

| RawFunctionTool | str | Any]] = NOT_GIVEN) ‑>

ChatContext

Expand source code

def copy(

self,

*,

exclude_function_call: bool = False,

exclude_instructions: bool = False,

exclude_empty_message: bool = False,

tools: NotGivenOr[Sequence[FunctionTool | RawFunctionTool | str | Any]] = NOT_GIVEN,

) -> ChatContext:

items = []

from .tool_context import (

get_function_info,

get_raw_function_info,

is_function_tool,

is_raw_function_tool,

)

valid_tools = set[str]()

if is_given(tools):

for tool in tools:

if isinstance(tool, str):

valid_tools.add(tool)

elif is_function_tool(tool):

valid_tools.add(get_function_info(tool).name)

elif is_raw_function_tool(tool):

valid_tools.add(get_raw_function_info(tool).name)

# TODO(theomonnom): other tools

for item in self.items:

if exclude_function_call and item.type in [

"function_call",

"function_call_output",

]:

continue

if (

exclude_instructions

and item.type == "message"

and item.role in ["system", "developer"]

):

continue

if exclude_empty_message and item.type == "message" and not item.content:

continue

if (

is_given(tools)

and (item.type == "function_call" or item.type == "function_call_output")

and item.name not in valid_tools

):

continue

items.append(item)

return ChatContext(items)

def

find_insertion_index

(

self, *, created_at: float) ‑> int

Expand source code

def find_insertion_index(self, *, created_at: float) -> int:

"""

Returns the index to insert an item by creation time.

Iterates in reverse, assuming items are sorted by `created_at`.

Finds the position after the last item with `created_at <=` the given timestamp.

"""

for i in reversed(range(len(self._items))):

if self._items[i].created_at <= created_at:

return i + 1

return 0

Returns the index to insert an item by creation time.

Iterates in reverse, assuming items are sorted by

created_at

.

Finds the position after the last item with

created_at <=

the given timestamp.

def

get_by_id

(

self, item_id: str) ‑> livekit.agents.llm.chat_context.ChatMessage | livekit.agents.llm.chat_context.FunctionCall | livekit.agents.llm.chat_context.FunctionCallOutput | None

Expand source code

def get_by_id(self, item_id: str) -> ChatItem | None:

return next((item for item in self.items if item.id == item_id), None)

def

index_by_id

(

self, item_id: str) ‑> int | None

Expand source code

def index_by_id(self, item_id: str) -> int | None:

return next((i for i, item in enumerate(self.items) if item.id == item_id), None)

def

insert

(

self, item: ChatItem | Sequence[ChatItem]) ‑> None

Expand source code

def insert(self, item: ChatItem | Sequence[ChatItem]) -> None:

"""Insert an item or list of items into the chat context by creation time."""

items = list(item) if isinstance(item, Sequence) else [item]

for _item in items:

idx = self.find_insertion_index(created_at=_item.created_at)

self._items.insert(idx, _item)

Insert an item or list of items into the chat context by creation time.

def

is_equivalent

(

self,

other:

ChatContext

) ‑> bool

Expand source code

def is_equivalent(self, other: ChatContext) -> bool:

"""

Return True if `other` has the same sequence of items with matching

essential fields (IDs, types, and payload) as this context.

Comparison rules:

- Messages: compares the full `content` list, `role` and `interrupted`.

- Function calls: compares `name`, `call_id`, and `arguments`.

- Function call outputs: compares `name`, `call_id`, `output`, and `is_error`.

Does not consider timestamps or other metadata.

"""

if self is other:

return True

if len(self.items) != len(other.items):

return False

for a, b in zip(self.items, other.items):

if a.id != b.id or a.type != b.type:

return False

if a.type == "message" and b.type == "message":

if a.role != b.role or a.interrupted != b.interrupted or a.content != b.content:

return False

elif a.type == "function_call" and b.type == "function_call":

if a.name != b.name or a.call_id != b.call_id or a.arguments != b.arguments:

return False

elif a.type == "function_call_output" and b.type == "function_call_output":

if (

a.name != b.name

or a.call_id != b.call_id

or a.output != b.output

or a.is_error != b.is_error

):

return False

return True

Return True if

other

has the same sequence of items with matching

essential fields (IDs, types, and payload) as this context.

Comparison rules:

- Messages: compares the full

content

list,

role

and

interrupted

.

- Function calls: compares

name

,

call_id

, and

arguments

.

- Function call outputs: compares

name

,

call_id

,

output

, and

is_error

.

Does not consider timestamps or other metadata.

def

merge

(

self,

other_chat_ctx:

ChatContext

,

*,

exclude_function_call: bool = False,

exclude_instructions: bool = False) ‑> livekit.agents.llm.chat_context.ChatContext

Expand source code

def merge(

self,

other_chat_ctx: ChatContext,

*,

exclude_function_call: bool = False,

exclude_instructions: bool = False,

) -> ChatContext:

"""Add messages from `other_chat_ctx` into this one, avoiding duplicates, and keep items sorted by created_at."""

existing_ids = {item.id for item in self._items}

for item in other_chat_ctx.items:

if exclude_function_call and item.type in [

"function_call",

"function_call_output",

]:

continue

if (

exclude_instructions

and item.type == "message"

and item.role in ["system", "developer"]

):

continue

if item.id not in existing_ids:

idx = self.find_insertion_index(created_at=item.created_at)

self._items.insert(idx, item)

existing_ids.add(item.id)

return self

Add messages from

other_chat_ctx

into this one, avoiding duplicates, and keep items sorted by created_at.

def

to_dict

(

self,

*,

exclude_image: bool = True,

exclude_audio: bool = True,

exclude_timestamp: bool = True,

exclude_function_call: bool = False) ‑> dict[str, typing.Any]

Expand source code

def to_dict(

self,

*,

exclude_image: bool = True,

exclude_audio: bool = True,

exclude_timestamp: bool = True,

exclude_function_call: bool = False,

) -> dict[str, Any]:

items: list[ChatItem] = []

for item in self.items:

if exclude_function_call and item.type in [

"function_call",

"function_call_output",

]:

continue

if item.type == "message":

item = item.model_copy()

if exclude_image:

item.content = [c for c in item.content if not isinstance(c, ImageContent)]

if exclude_audio:

item.content = [c for c in item.content if not isinstance(c, AudioContent)]

items.append(item)

exclude_fields = set()

if exclude_timestamp:

exclude_fields.add("created_at")

return {

"items": [

item.model_dump(

mode="json",

exclude_none=True,

exclude_defaults=False,

exclude=exclude_fields,

)

for item in items

],

}

def

to_provider_format

(

self,

format: "Literal['openai', 'google', 'aws', 'anthropic', 'mistralai'] | str",

*,

inject_dummy_user_message: bool = True,

**kwargs: Any) ‑> tuple[list[dict], typing.Any]

Expand source code

def to_provider_format(

self,

format: Literal["openai", "google", "aws", "anthropic", "mistralai"] | str,

*,

inject_dummy_user_message: bool = True,

**kwargs: Any,

) -> tuple[list[dict], Any]:

"""Convert the chat context to a provider-specific format.

If ``inject_dummy_user_message`` is ``True``, a dummy user message will be added

to the beginning or end of the chat context depending on the provider.

This is necessary because some providers expect a user message to be present for

generating a response.

"""

kwargs["inject_dummy_user_message"] = inject_dummy_user_message

if format == "openai":

return _provider_format.openai.to_chat_ctx(self, **kwargs)

elif format == "google":

return _provider_format.google.to_chat_ctx(self, **kwargs)

elif format == "aws":

return _provider_format.aws.to_chat_ctx(self, **kwargs)

elif format == "anthropic":

return _provider_format.anthropic.to_chat_ctx(self, **kwargs)

elif format == "mistralai":

return _provider_format.mistralai.to_chat_ctx(self, **kwargs)

else:

raise ValueError(f"Unsupported provider format: {format}")

Convert the chat context to a provider-specific format.

If

inject_dummy_user_message

is

True

, a dummy user message will be added

to the beginning or end of the chat context depending on the provider.

This is necessary because some providers expect a user message to be present for

generating a response.

def

truncate

(

self, *, max_items: int) ‑> livekit.agents.llm.chat_context.ChatContext

Expand source code

def truncate(self, *, max_items: int) -> ChatContext:

"""Truncate the chat context to the last N items in place.

Removes leading function calls to avoid partial function outputs.

Preserves the first system message by adding it back to the beginning.

"""

if len(self._items) <= max_items:

return self

instructions = next(

(item for item in self._items if item.type == "message" and item.role == "system"),

None,

)

new_items = self._items[-max_items:]

# chat ctx shouldn't start with function_call or function_call_output

while new_items and new_items[0].type in [

"function_call",

"function_call_output",

]:

new_items.pop(0)

if instructions:

new_items.insert(0, instructions)

self._items[:] = new_items

return self

Truncate the chat context to the last N items in place.

Removes leading function calls to avoid partial function outputs.

Preserves the first system message by adding it back to the beginning.

class

ChatMessage

(

**data: Any)

Expand source code

class ChatMessage(BaseModel):

id: str = Field(default_factory=lambda: utils.shortuuid("item_"))

type: Literal["message"] = "message"

role: ChatRole

content: list[ChatContent]

interrupted: bool = False

transcript_confidence: float | None = None

hash: bytes | None = None

created_at: float = Field(default_factory=time.time)

@property

def text_content(self) -> str | None:

"""

Returns a string of all text content in the message.

Multiple text content items will be joined by a newline.

"""

text_parts = [c for c in self.content if isinstance(c, str)]

if not text_parts:

return None

return "\n".join(text_parts)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

content

: list[livekit.agents.llm.chat_context.ImageContent | livekit.agents.llm.chat_context.AudioContent | str]

var

created_at

: float

var

hash

: bytes | None

var

id

: str

var

interrupted

: bool

var

model_config

var

role

: Literal['developer', 'system', 'user', 'assistant']

var

transcript_confidence

: float | None

var

type

: Literal['message']

Instance variables

prop

text_content

: str | None

Expand source code

@property

def text_content(self) -> str | None:

"""

Returns a string of all text content in the message.

Multiple text content items will be joined by a newline.

"""

text_parts = [c for c in self.content if isinstance(c, str)]

if not text_parts:

return None

return "\n".join(text_parts)

Returns a string of all text content in the message.

Multiple text content items will be joined by a newline.

class

ChatMessageEvent

(

item:

ChatMessage

,

type: "Literal['message']" = 'message')

Expand source code

@dataclass

class ChatMessageEvent:

item: llm.ChatMessage

type: Literal["message"] = "message"

ChatMessageEvent(item: 'llm.ChatMessage', type: "Literal['message']" = 'message')

Instance variables

var

item

: livekit.agents.llm.chat_context.ChatMessage

var

type

: Literal['message']

class

CloseEvent

(

**data: Any)

Expand source code

class CloseEvent(BaseModel):

type: Literal["close"] = "close"

error: LLMError | STTError | TTSError | RealtimeModelError | None = None

reason: CloseReason

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

error

: livekit.agents.llm.llm.LLMError | livekit.agents.stt.stt.STTError | livekit.agents.tts.tts.TTSError | livekit.agents.llm.realtime.RealtimeModelError | None

var

model_config

var

reason

: livekit.agents.voice.events.CloseReason

var

type

: Literal['close']

class

CloseReason

(

*args, **kwds)

Expand source code

@unique

class CloseReason(str, Enum):

ERROR = "error"

JOB_SHUTDOWN = "job_shutdown"

PARTICIPANT_DISCONNECTED = "participant_disconnected"

USER_INITIATED = "user_initiated"

TASK_COMPLETED = "task_completed"

str(object='') -> str

str(bytes_or_buffer[, encoding[, errors]]) -> str

Create a new string object from the given object. If encoding or

errors is specified, then the object must expose a data buffer

that will be decoded using the given encoding and error handler.

Otherwise, returns the result of object.

str

() (if defined)

or repr(object).

encoding defaults to sys.getdefaultencoding().

errors defaults to 'strict'.

Ancestors

builtins.str

enum.Enum

Class variables

var

ERROR

var

JOB_SHUTDOWN

var

PARTICIPANT_DISCONNECTED

var

TASK_COMPLETED

var

USER_INITIATED

class

ConversationItemAddedEvent

(

**data: Any)

Expand source code

class ConversationItemAddedEvent(BaseModel):

type: Literal["conversation_item_added"] = "conversation_item_added"

item: ChatMessage | _TypeDiscriminator

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

item

: livekit.agents.llm.chat_context.ChatMessage | livekit.agents.voice.events._TypeDiscriminator

var

model_config

var

type

: Literal['conversation_item_added']

class

ErrorEvent

(

**data: Any)

Expand source code

class ErrorEvent(BaseModel):

model_config = ConfigDict(arbitrary_types_allowed=True)

type: Literal["error"] = "error"

error: LLMError | STTError | TTSError | RealtimeModelError | Any

source: LLM | STT | TTS | RealtimeModel | Any

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

error

: livekit.agents.llm.llm.LLMError | livekit.agents.stt.stt.STTError | livekit.agents.tts.tts.TTSError | livekit.agents.llm.realtime.RealtimeModelError | typing.Any

var

model_config

var

source

: livekit.agents.llm.llm.LLM | livekit.agents.stt.stt.STT | livekit.agents.tts.tts.TTS | livekit.agents.llm.realtime.RealtimeModel | typing.Any

var

type

: Literal['error']

class

EventAssert

(

event: RunEvent,

parent:

RunAssert

,

index: int = -1)

Expand source code

class EventAssert:

def __init__(self, event: RunEvent, parent: RunAssert, index: int = -1):

self._event = event

self._parent = parent

self._index = index

def _raise(self, message: str) -> None:

__tracebackhide__ = True

self._parent._raise_with_debug_info(message, index=self._index)

def event(self) -> RunEvent:

return self._event

def is_function_call(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

) -> FunctionCallAssert:

"""

Verify this event is a function call with matching details.

Args:

name (str, optional): Expected function name.

arguments (dict, optional): Expected call arguments.

Returns:

FunctionCallAssert: Assertion for the function call.

Raises:

AssertionError: If the event is not a function call or details mismatch.

Example:

>>> ev_assert.is_function_call(name="foo", arguments={"x": 1})

"""

__tracebackhide__ = True

if not isinstance(self._event, FunctionCallEvent):

self._raise("Expected FunctionCallEvent")

assert isinstance(self._event, FunctionCallEvent)  # type check

if is_given(name) and self._event.item.name != name:

self._raise(f"Expected call name '{name}', got '{self._event.item.name}'")

if is_given(arguments):

actual = json.loads(self._event.item.arguments)

for key, value in arguments.items():

if key not in actual or actual[key] != value:

self._raise(f"For key '{key}', expected {value}, got {actual.get(key)}")

return FunctionCallAssert(self._event, self._parent, self._index)

def is_function_call_output(

self, *, output: NotGivenOr[str] = NOT_GIVEN, is_error: NotGivenOr[bool] = NOT_GIVEN

) -> FunctionCallOutputAssert:

"""

Verify this event is a function call output with matching details.

Args:

output (str, optional): Expected output text.

is_error (bool, optional): Expected error flag.

Returns:

FunctionCallOutputAssert: Assertion for the output.

Raises:

AssertionError: If the event is not function output or details mismatch.

Example:

>>> ev_assert.is_function_call_output(output="OK", is_error=False)

"""

__tracebackhide__ = True

if not isinstance(self._event, FunctionCallOutputEvent):

self._raise("Expected FunctionCallOutputEvent")

assert isinstance(self._event, FunctionCallOutputEvent)  # type check

if is_given(output) and self._event.item.output != output:

self._raise(f"Expected output '{output}', got '{self._event.item.output}'")

if is_given(is_error) and self._event.item.is_error != is_error:

self._raise(f"Expected is_error={is_error}, got {self._event.item.is_error}")

return FunctionCallOutputAssert(self._event, self._parent, self._index)

def is_message(self, *, role: NotGivenOr[llm.ChatRole] = NOT_GIVEN) -> ChatMessageAssert:

"""

Verify this event is a message from the given role.

Args:

role (ChatRole, optional): Expected sender role.

Returns:

ChatMessageAssert: Assertion for the message.

Raises:

AssertionError: If the event is not a message or role mismatch.

Example:

>>> ev_assert.is_message(role="assistant")

"""

__tracebackhide__ = True

if not isinstance(self._event, ChatMessageEvent):

self._raise("Expected ChatMessageEvent")

assert isinstance(self._event, ChatMessageEvent)  # type check

if is_given(role) and self._event.item.role != role:

self._raise(f"Expected role '{role}', got '{self._event.item.role}'")

return ChatMessageAssert(self._event, self._parent, self._index)

def is_agent_handoff(

self, *, new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN

) -> AgentHandoffAssert:

"""

Verify this event is an agent handoff.

Args:

new_agent_type (type, optional): Expected new agent class.

Returns:

AgentHandoffAssert: Assertion for the handoff.

Raises:

AssertionError: If the event is not an agent handoff or type mismatch.

Example:

>>> ev_assert.is_agent_handoff(new_agent_type=MyAgent)

"""

__tracebackhide__ = True

if not isinstance(self._event, AgentHandoffEvent):

self._raise("Expected AgentHandoffEvent")

assert isinstance(self._event, AgentHandoffEvent)  # type check

if is_given(new_agent_type) and not isinstance(self._event.new_agent, new_agent_type):

self._raise(

f"Expected new_agent '{new_agent_type.__name__}', got '{type(self._event.new_agent).__name__}'"

)

return AgentHandoffAssert(self._event, self._parent, self._index)

Methods

def

event

(

self) ‑>

ChatMessageEvent

|

FunctionCallEvent

|

FunctionCallOutputEvent

|

AgentHandoffEvent

Expand source code

def event(self) -> RunEvent:

return self._event

def

is_agent_handoff

(

self,

*,

new_agent_type: NotGivenOr[type[

Agent

]] = NOT_GIVEN) ‑> AgentHandoffAssert

Expand source code

def is_agent_handoff(

self, *, new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN

) -> AgentHandoffAssert:

"""

Verify this event is an agent handoff.

Args:

new_agent_type (type, optional): Expected new agent class.

Returns:

AgentHandoffAssert: Assertion for the handoff.

Raises:

AssertionError: If the event is not an agent handoff or type mismatch.

Example:

>>> ev_assert.is_agent_handoff(new_agent_type=MyAgent)

"""

__tracebackhide__ = True

if not isinstance(self._event, AgentHandoffEvent):

self._raise("Expected AgentHandoffEvent")

assert isinstance(self._event, AgentHandoffEvent)  # type check

if is_given(new_agent_type) and not isinstance(self._event.new_agent, new_agent_type):

self._raise(

f"Expected new_agent '{new_agent_type.__name__}', got '{type(self._event.new_agent).__name__}'"

)

return AgentHandoffAssert(self._event, self._parent, self._index)

Verify this event is an agent handoff.

Args

new_agent_type

:

type

, optional

Expected new agent class.

Returns

AgentHandoffAssert

Assertion for the handoff.

Raises

AssertionError

If the event is not an agent handoff or type mismatch.

Example

>>> ev_assert.is_agent_handoff(new_agent_type=MyAgent)

def

is_function_call

(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN) ‑>

FunctionCallAssert

Expand source code

def is_function_call(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

) -> FunctionCallAssert:

"""

Verify this event is a function call with matching details.

Args:

name (str, optional): Expected function name.

arguments (dict, optional): Expected call arguments.

Returns:

FunctionCallAssert: Assertion for the function call.

Raises:

AssertionError: If the event is not a function call or details mismatch.

Example:

>>> ev_assert.is_function_call(name="foo", arguments={"x": 1})

"""

__tracebackhide__ = True

if not isinstance(self._event, FunctionCallEvent):

self._raise("Expected FunctionCallEvent")

assert isinstance(self._event, FunctionCallEvent)  # type check

if is_given(name) and self._event.item.name != name:

self._raise(f"Expected call name '{name}', got '{self._event.item.name}'")

if is_given(arguments):

actual = json.loads(self._event.item.arguments)

for key, value in arguments.items():

if key not in actual or actual[key] != value:

self._raise(f"For key '{key}', expected {value}, got {actual.get(key)}")

return FunctionCallAssert(self._event, self._parent, self._index)

Verify this event is a function call with matching details.

Args

name

:

str

, optional

Expected function name.

arguments

:

dict

, optional

Expected call arguments.

Returns

FunctionCallAssert

Assertion for the function call.

Raises

AssertionError

If the event is not a function call or details mismatch.

Example

>>> ev_assert.is_function_call(name="foo", arguments={"x": 1})

def

is_function_call_output

(

self,

*,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN) ‑>

FunctionCallOutputAssert

Expand source code

def is_function_call_output(

self, *, output: NotGivenOr[str] = NOT_GIVEN, is_error: NotGivenOr[bool] = NOT_GIVEN

) -> FunctionCallOutputAssert:

"""

Verify this event is a function call output with matching details.

Args:

output (str, optional): Expected output text.

is_error (bool, optional): Expected error flag.

Returns:

FunctionCallOutputAssert: Assertion for the output.

Raises:

AssertionError: If the event is not function output or details mismatch.

Example:

>>> ev_assert.is_function_call_output(output="OK", is_error=False)

"""

__tracebackhide__ = True

if not isinstance(self._event, FunctionCallOutputEvent):

self._raise("Expected FunctionCallOutputEvent")

assert isinstance(self._event, FunctionCallOutputEvent)  # type check

if is_given(output) and self._event.item.output != output:

self._raise(f"Expected output '{output}', got '{self._event.item.output}'")

if is_given(is_error) and self._event.item.is_error != is_error:

self._raise(f"Expected is_error={is_error}, got {self._event.item.is_error}")

return FunctionCallOutputAssert(self._event, self._parent, self._index)

Verify this event is a function call output with matching details.

Args

output

:

str

, optional

Expected output text.

is_error

:

bool

, optional

Expected error flag.

Returns

FunctionCallOutputAssert

Assertion for the output.

Raises

AssertionError

If the event is not function output or details mismatch.

Example

>>> ev_assert.is_function_call_output(output="OK", is_error=False)

def

is_message

(

self, *, role: NotGivenOr[llm.ChatRole] = NOT_GIVEN) ‑>

ChatMessageAssert

Expand source code

def is_message(self, *, role: NotGivenOr[llm.ChatRole] = NOT_GIVEN) -> ChatMessageAssert:

"""

Verify this event is a message from the given role.

Args:

role (ChatRole, optional): Expected sender role.

Returns:

ChatMessageAssert: Assertion for the message.

Raises:

AssertionError: If the event is not a message or role mismatch.

Example:

>>> ev_assert.is_message(role="assistant")

"""

__tracebackhide__ = True

if not isinstance(self._event, ChatMessageEvent):

self._raise("Expected ChatMessageEvent")

assert isinstance(self._event, ChatMessageEvent)  # type check

if is_given(role) and self._event.item.role != role:

self._raise(f"Expected role '{role}', got '{self._event.item.role}'")

return ChatMessageAssert(self._event, self._parent, self._index)

Verify this event is a message from the given role.

Args

role

:

ChatRole

, optional

Expected sender role.

Returns

ChatMessageAssert

Assertion for the message.

Raises

AssertionError

If the event is not a message or role mismatch.

Example

>>> ev_assert.is_message(role="assistant")

class

EventRangeAssert

(

events: list[RunEvent],

parent:

RunAssert

,

rng: slice)

Expand source code

class EventRangeAssert:

def __init__(self, events: list[RunEvent], parent: RunAssert, rng: slice):

self._events = events

self._parent = parent

self._rng = rng

def contains_function_call(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

) -> FunctionCallAssert:

"""

Assert that a function call matching criteria exists in the event range.

Args:

name (str, optional): Expected function name.

arguments (dict, optional): Expected call arguments.

Returns:

FunctionCallAssert: Assertion for the matched function call.

Raises:

AssertionError: If no matching function call is found in range.

Example:

>>> result.expect[0:3].contains_function_call(name="foo")

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_function_call(name=name, arguments=arguments)

self._parent._raise_with_debug_info(

f"No FunctionCallEvent satisfying criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

def contains_message(

self,

*,

role: NotGivenOr[llm.ChatRole] = NOT_GIVEN,

) -> ChatMessageAssert:

"""

Assert that a message matching criteria exists in the event range.

Args:

role (ChatRole, optional): Expected sender role.

Returns:

ChatMessageAssert: Assertion for the matched message.

Raises:

AssertionError: If no matching message is found in range.

Example:

>>> result.expect[:2].contains_message(role="assistant")

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_message(role=role)

self._parent._raise_with_debug_info(

f"No ChatMessageEvent matching criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

def contains_function_call_output(

self,

*,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

) -> FunctionCallOutputAssert:

"""

Assert that a function call output matching criteria exists in the event range.

Args:

output (str, optional): Expected output text.

is_error (bool, optional): Expected error flag.

Returns:

FunctionCallOutputAssert: Assertion for the matched output.

Raises:

AssertionError: If no matching output is found in range.

Example:

>>> result.expect[1:4].contains_function_call_output(is_error=True)

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_function_call_output(output=output, is_error=is_error)

self._parent._raise_with_debug_info(

f"No FunctionCallOutputEvent matching criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

def contains_agent_handoff(

self, *, new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN

) -> AgentHandoffAssert:

"""

Assert that an agent handoff matching criteria exists in the event range.

Args:

new_agent_type (type, optional): Expected new agent class.

Returns:

AgentHandoffAssert: Assertion for the matched handoff.

Raises:

AssertionError: If no matching handoff is found in range.

Example:

>>> result.expect[0:3].contains_agent_handoff(new_agent_type=MyAgent)

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_agent_handoff(new_agent_type=new_agent_type)

self._parent._raise_with_debug_info(

f"No AgentHandoffEvent matching criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

Methods

def

contains_agent_handoff

(

self,

*,

new_agent_type: NotGivenOr[type[

Agent

]] = NOT_GIVEN) ‑> AgentHandoffAssert

Expand source code

def contains_agent_handoff(

self, *, new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN

) -> AgentHandoffAssert:

"""

Assert that an agent handoff matching criteria exists in the event range.

Args:

new_agent_type (type, optional): Expected new agent class.

Returns:

AgentHandoffAssert: Assertion for the matched handoff.

Raises:

AssertionError: If no matching handoff is found in range.

Example:

>>> result.expect[0:3].contains_agent_handoff(new_agent_type=MyAgent)

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_agent_handoff(new_agent_type=new_agent_type)

self._parent._raise_with_debug_info(

f"No AgentHandoffEvent matching criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

Assert that an agent handoff matching criteria exists in the event range.

Args

new_agent_type

:

type

, optional

Expected new agent class.

Returns

AgentHandoffAssert

Assertion for the matched handoff.

Raises

AssertionError

If no matching handoff is found in range.

Example

>>> result.expect[0:3].contains_agent_handoff(new_agent_type=MyAgent)

def

contains_function_call

(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN) ‑>

FunctionCallAssert

Expand source code

def contains_function_call(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

) -> FunctionCallAssert:

"""

Assert that a function call matching criteria exists in the event range.

Args:

name (str, optional): Expected function name.

arguments (dict, optional): Expected call arguments.

Returns:

FunctionCallAssert: Assertion for the matched function call.

Raises:

AssertionError: If no matching function call is found in range.

Example:

>>> result.expect[0:3].contains_function_call(name="foo")

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_function_call(name=name, arguments=arguments)

self._parent._raise_with_debug_info(

f"No FunctionCallEvent satisfying criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

Assert that a function call matching criteria exists in the event range.

Args

name

:

str

, optional

Expected function name.

arguments

:

dict

, optional

Expected call arguments.

Returns

FunctionCallAssert

Assertion for the matched function call.

Raises

AssertionError

If no matching function call is found in range.

Example

>>> result.expect[0:3].contains_function_call(name="foo")

def

contains_function_call_output

(

self,

*,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN) ‑>

FunctionCallOutputAssert

Expand source code

def contains_function_call_output(

self,

*,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

) -> FunctionCallOutputAssert:

"""

Assert that a function call output matching criteria exists in the event range.

Args:

output (str, optional): Expected output text.

is_error (bool, optional): Expected error flag.

Returns:

FunctionCallOutputAssert: Assertion for the matched output.

Raises:

AssertionError: If no matching output is found in range.

Example:

>>> result.expect[1:4].contains_function_call_output(is_error=True)

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_function_call_output(output=output, is_error=is_error)

self._parent._raise_with_debug_info(

f"No FunctionCallOutputEvent matching criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

Assert that a function call output matching criteria exists in the event range.

Args

output

:

str

, optional

Expected output text.

is_error

:

bool

, optional

Expected error flag.

Returns

FunctionCallOutputAssert

Assertion for the matched output.

Raises

AssertionError

If no matching output is found in range.

Example

>>> result.expect[1:4].contains_function_call_output(is_error=True)

def

contains_message

(

self, *, role: NotGivenOr[llm.ChatRole] = NOT_GIVEN) ‑>

ChatMessageAssert

Expand source code

def contains_message(

self,

*,

role: NotGivenOr[llm.ChatRole] = NOT_GIVEN,

) -> ChatMessageAssert:

"""

Assert that a message matching criteria exists in the event range.

Args:

role (ChatRole, optional): Expected sender role.

Returns:

ChatMessageAssert: Assertion for the matched message.

Raises:

AssertionError: If no matching message is found in range.

Example:

>>> result.expect[:2].contains_message(role="assistant")

"""

__tracebackhide__ = True

for idx, ev in enumerate(self._events):

candidate = EventAssert(ev, self._parent, (self._rng.start or 0) + idx)

with contextlib.suppress(AssertionError):

return candidate.is_message(role=role)

self._parent._raise_with_debug_info(

f"No ChatMessageEvent matching criteria found in range {self._rng!r}"

)

raise RuntimeError("unreachable")

Assert that a message matching criteria exists in the event range.

Args

role

:

ChatRole

, optional

Expected sender role.

Returns

ChatMessageAssert

Assertion for the matched message.

Raises

AssertionError

If no matching message is found in range.

Example

>>> result.expect[:2].contains_message(role="assistant")

class

FunctionCall

(

**data: Any)

Expand source code

class FunctionCall(BaseModel):

id: str = Field(default_factory=lambda: utils.shortuuid("item_"))

type: Literal["function_call"] = "function_call"

call_id: str

arguments: str

name: str

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

arguments

: str

var

call_id

: str

var

created_at

: float

var

id

: str

var

model_config

var

name

: str

var

type

: Literal['function_call']

class

FunctionCallEvent

(

item:

FunctionCall

,

type: "Literal['function_call']" = 'function_call')

Expand source code

@dataclass

class FunctionCallEvent:

item: llm.FunctionCall

type: Literal["function_call"] = "function_call"

FunctionCallEvent(item: 'llm.FunctionCall', type: "Literal['function_call']" = 'function_call')

Instance variables

var

item

: livekit.agents.llm.chat_context.FunctionCall

var

type

: Literal['function_call']

class

FunctionCallOutput

(

**data: Any)

Expand source code

class FunctionCallOutput(BaseModel):

id: str = Field(default_factory=lambda: utils.shortuuid("item_"))

type: Literal["function_call_output"] = Field(default="function_call_output")

name: str = Field(default="")

call_id: str

output: str

is_error: bool

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

call_id

: str

var

created_at

: float

var

id

: str

var

is_error

: bool

var

model_config

var

name

: str

var

output

: str

var

type

: Literal['function_call_output']

class

FunctionCallOutputEvent

(

item:

FunctionCallOutput

,

type: "Literal['function_call_output']" = 'function_call_output')

Expand source code

@dataclass

class FunctionCallOutputEvent:

item: llm.FunctionCallOutput

type: Literal["function_call_output"] = "function_call_output"

FunctionCallOutputEvent(item: 'llm.FunctionCallOutput', type: "Literal['function_call_output']" = 'function_call_output')

Instance variables

var

item

: livekit.agents.llm.chat_context.FunctionCallOutput

var

type

: Literal['function_call_output']

class

FunctionTool

(

*args, **kwargs)

Expand source code

@runtime_checkable

class FunctionTool(Protocol):

__livekit_tool_info: _FunctionToolInfo

def __call__(self, *args: Any, **kwargs: Any) -> Any: ...

Base class for protocol classes.

Protocol classes are defined as::

class Proto(Protocol):

def meth(self) -> int:

...

Such classes are primarily used with static type checkers that recognize

structural subtyping (static duck-typing).

For example::

class C:

def meth(self) -> int:

return 0

def func(x: Proto) -> int:

return x.meth()

func(C())  # Passes static type check

See PEP 544 for details. Protocol classes decorated with

@typing.runtime_checkable act as simple-minded runtime protocols that check

only the presence of given attributes, ignoring their type signatures.

Protocol classes can be generic, they are defined as::

class GenProto[T](Protocol):

def meth(self) -> T:

...

Ancestors

typing.Protocol

typing.Generic

class

FunctionToolsExecutedEvent

(

**data: Any)

Expand source code

class FunctionToolsExecutedEvent(BaseModel):

type: Literal["function_tools_executed"] = "function_tools_executed"

function_calls: list[FunctionCall]

function_call_outputs: list[FunctionCallOutput | None]

created_at: float = Field(default_factory=time.time)

_reply_required: bool = PrivateAttr(default=False)

_handoff_required: bool = PrivateAttr(default=False)

def zipped(self) -> list[tuple[FunctionCall, FunctionCallOutput | None]]:

return list(zip(self.function_calls, self.function_call_outputs))

def cancel_tool_reply(self) -> None:

self._reply_required = False

def cancel_agent_handoff(self) -> None:

self._handoff_required = False

@property

def has_tool_reply(self) -> bool:

return self._reply_required

@property

def has_agent_handoff(self) -> bool:

return self._handoff_required

@model_validator(mode="after")

def verify_lists_length(self) -> Self:

if len(self.function_calls) != len(self.function_call_outputs):

raise ValueError("The number of function_calls and function_call_outputs must match.")

return self

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

function_call_outputs

: list[livekit.agents.llm.chat_context.FunctionCallOutput | None]

var

function_calls

: list[livekit.agents.llm.chat_context.FunctionCall]

var

model_config

var

type

: Literal['function_tools_executed']

Instance variables

prop

has_agent_handoff

: bool

Expand source code

@property

def has_agent_handoff(self) -> bool:

return self._handoff_required

prop

has_tool_reply

: bool

Expand source code

@property

def has_tool_reply(self) -> bool:

return self._reply_required

Methods

def

cancel_agent_handoff

(

self) ‑> None

Expand source code

def cancel_agent_handoff(self) -> None:

self._handoff_required = False

def

cancel_tool_reply

(

self) ‑> None

Expand source code

def cancel_tool_reply(self) -> None:

self._reply_required = False

def

model_post_init

(

self: BaseModel, context: Any, /) ‑> None

Expand source code

def init_private_attributes(self: BaseModel, context: Any, /) -> None:

"""This function is meant to behave like a BaseModel method to initialise private attributes.

It takes context as an argument since that's what pydantic-core passes when calling it.

Args:

self: The BaseModel instance.

context: The context.

"""

if getattr(self, '__pydantic_private__', None) is None:

pydantic_private = {}

for name, private_attr in self.__private_attributes__.items():

default = private_attr.get_default()

if default is not PydanticUndefined:

pydantic_private[name] = default

object_setattr(self, '__pydantic_private__', pydantic_private)

This function is meant to behave like a BaseModel method to initialise private attributes.

It takes context as an argument since that's what pydantic-core passes when calling it.

Args

self

The BaseModel instance.

context

The context.

def

verify_lists_length

(

self) ‑> Self

Expand source code

@model_validator(mode="after")

def verify_lists_length(self) -> Self:

if len(self.function_calls) != len(self.function_call_outputs):

raise ValueError("The number of function_calls and function_call_outputs must match.")

return self

def

zipped

(

self) ‑> list[tuple[livekit.agents.llm.chat_context.FunctionCall, livekit.agents.llm.chat_context.FunctionCallOutput | None]]

Expand source code

def zipped(self) -> list[tuple[FunctionCall, FunctionCallOutput | None]]:

return list(zip(self.function_calls, self.function_call_outputs))

class

JobContext

(

*,

proc:

JobProcess

,

info: RunningJobInfo,

room: rtc.Room,

on_connect: Callable[[], None],

on_shutdown: Callable[[str], None],

inference_executor: InferenceExecutor)

Expand source code

class JobContext:

_PARTICIPANT_ENTRYPOINT_CALLBACK = Callable[

["JobContext", rtc.RemoteParticipant], Coroutine[None, None, None]

]

# private ctor

def __init__(

self,

*,

proc: JobProcess,

info: RunningJobInfo,

room: rtc.Room,

on_connect: Callable[[], None],

on_shutdown: Callable[[str], None],

inference_executor: InferenceExecutor,

) -> None:

self._proc = proc

self._info = info

self._room = room

self._on_connect = on_connect

self._on_shutdown = on_shutdown

self._shutdown_callbacks: list[Callable[[str], Coroutine[None, None, None]]] = []

self._participant_entrypoints: list[

tuple[

JobContext._PARTICIPANT_ENTRYPOINT_CALLBACK,

list[rtc.ParticipantKind.ValueType] | rtc.ParticipantKind.ValueType,

]

] = []

self._participant_tasks = dict[

tuple[str, JobContext._PARTICIPANT_ENTRYPOINT_CALLBACK], asyncio.Task[None]

]()

self._pending_tasks = list[asyncio.Task[Any]]()

self._room.on("participant_connected", self._participant_available)

self._inf_executor = inference_executor

self._init_log_factory()

self._log_fields: dict[str, Any] = {}

self._connected = False

self._lock = asyncio.Lock()

def _init_log_factory(self) -> None:

old_factory = logging.getLogRecordFactory()

def record_factory(*args: Any, **kwargs: Any) -> logging.LogRecord:

record = old_factory(*args, **kwargs)

if self.proc.executor_type != JobExecutorType.PROCESS:

try:

ctx = get_job_context()

except RuntimeError:

return record

else:

if ctx != self:

return record

for key, value in self._log_fields.items():

setattr(record, key, value)

return record

logging.setLogRecordFactory(record_factory)

@property

def inference_executor(self) -> InferenceExecutor:

return self._inf_executor

@functools.cached_property

def api(self) -> api.LiveKitAPI:

"""Returns an LiveKitAPI for making API calls to LiveKit.

Credentials are sourced from environment variables if not provided explicitly.

When starting via the worker, values passed in `WorkerOptions` are exported to

LIVEKIT_URL, LIVEKIT_API_KEY, and LIVEKIT_API_SECRET so this API is always

usable inside job entrypoints.

"""

return api.LiveKitAPI(session=http_context.http_session())

@property

def proc(self) -> JobProcess:

"""Returns the process running the job. Useful for storing process-specific state."""

return self._proc

@property

def job(self) -> agent.Job:

"""Returns the current job that the worker is executing."""

return self._info.job

@property

def worker_id(self) -> str:

"""Returns the id of the worker."""

return self._info.worker_id

@property

def room(self) -> rtc.Room:

"""The Room object is the main interface that the worker should interact with.

When the entrypoint is called, the worker has not connected to the Room yet.

Certain properties of Room would not be available before calling JobContext.connect()

"""

return self._room

@property

def agent(self) -> rtc.LocalParticipant:

return self._room.local_participant

@property

def log_context_fields(self) -> dict[str, Any]:

"""

Returns the current dictionary of log fields that will be injected into log records.

These fields enable enriched structured logging and can include job metadata,

worker ID, trace IDs, or other diagnostic context.

The returned dictionary can be directly edited, or entirely replaced via assignment

(e.g., `job_context.log_context_fields = {...}`)

"""

return self._log_fields

@log_context_fields.setter

def log_context_fields(self, fields: dict[str, Any]) -> None:

"""

Sets the log fields to be injected into future log records.

Args:

fields (dict[str, Any]): A dictionary of key-value pairs representing

structured data to attach to each log entry. Typically includes contextual

information like job ID, trace information, or worker metadata.

"""

self._log_fields = fields

def add_shutdown_callback(

self,

callback: Callable[[], Coroutine[None, None, None]]

| Callable[[str], Coroutine[None, None, None]],

) -> None:

"""

Add a callback to be called when the job is shutting down.

Optionally the callback can take a single argument, the shutdown reason.

"""

min_args_num = 2 if inspect.ismethod(callback) else 1

if callback.__code__.co_argcount >= min_args_num:

self._shutdown_callbacks.append(callback)  # type: ignore

else:

async def wrapper(_: str) -> None:

await callback()  # type: ignore

self._shutdown_callbacks.append(wrapper)

async def wait_for_participant(

self,

*,

identity: str | None = None,

kind: list[rtc.ParticipantKind.ValueType]

| rtc.ParticipantKind.ValueType = DEFAULT_PARTICIPANT_KINDS,

) -> rtc.RemoteParticipant:

"""

Returns a participant that matches the given identity. If identity is None, the first

participant that joins the room will be returned.

If the participant has already joined, the function will return immediately.

"""

return await wait_for_participant(self._room, identity=identity, kind=kind)

async def connect(

self,

*,

e2ee: rtc.E2EEOptions | None = None,

auto_subscribe: AutoSubscribe = AutoSubscribe.SUBSCRIBE_ALL,

rtc_config: rtc.RtcConfiguration | None = None,

) -> None:

"""Connect to the room. This method should be called only once.

Args:

e2ee: End-to-end encryption options. If provided, the Agent will utilize end-to-end encryption. Note: clients will also need to handle E2EE.

auto_subscribe: Whether to automatically subscribe to tracks. Default is AutoSubscribe.SUBSCRIBE_ALL.

rtc_config: Custom RTC configuration to use when connecting to the room.

"""  # noqa: E501

async with self._lock:

if self._connected:

return

room_options = rtc.RoomOptions(

e2ee=e2ee,

auto_subscribe=auto_subscribe == AutoSubscribe.SUBSCRIBE_ALL,

rtc_config=rtc_config,

)

await self._room.connect(self._info.url, self._info.token, options=room_options)

self._on_connect()

for p in self._room.remote_participants.values():

self._participant_available(p)

_apply_auto_subscribe_opts(self._room, auto_subscribe)

self._connected = True

def delete_room(self) -> asyncio.Future[api.DeleteRoomResponse]:  # type: ignore

"""Deletes the room and disconnects all participants."""

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning("job_ctx.delete_room() is not executed while in console mode")

fut = asyncio.Future[api.DeleteRoomResponse]()

fut.set_result(api.DeleteRoomResponse())

return fut

async def _delete_room() -> None:

try:

await self.api.room.delete_room(api.DeleteRoomRequest(room=self._room.name))

except aiohttp.ServerDisconnectedError:

logger.warning("server disconnected while deleting room")

except api.TwirpError as e:

if e.code != api.TwirpErrorCode.NOT_FOUND:

logger.warning(f"error while deleting room: {e}")

except Exception:

logger.exception("unknown error while deleting room")

task = asyncio.create_task(_delete_room())

self._pending_tasks.append(task)

task.add_done_callback(lambda _: self._pending_tasks.remove(task))

return task

def add_sip_participant(

self,

*,

call_to: str,

trunk_id: str,

participant_identity: str,

participant_name: NotGivenOr[str] = "SIP-participant",

) -> asyncio.Future[api.SIPParticipantInfo]:  # type: ignore

"""

Add a SIP participant to the room.

Args:

call_to: The number or SIP destination to transfer the participant to.

This can either be a number (+12345555555) or a

sip host (sip:<user>@<host>)

trunk_id: The ID of the SIP trunk to use

participant_identity: The identity of the participant to add

participant_name: The name of the participant to add

Make sure you have an outbound SIP trunk created in LiveKit.

See https://docs.livekit.io/sip/trunk-outbound/ for more information.

"""

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning("job_ctx.add_sip_participant() is not executed while in console mode")

fut = asyncio.Future[api.SIPParticipantInfo]()

fut.set_result(api.SIPParticipantInfo())

return fut

task = asyncio.create_task(

self.api.sip.create_sip_participant(

api.CreateSIPParticipantRequest(

room_name=self._room.name,

participant_identity=participant_identity,

sip_trunk_id=trunk_id,

sip_call_to=call_to,

participant_name=participant_name if is_given(participant_name) else None,

)

),

)

self._pending_tasks.append(task)

task.add_done_callback(lambda _: self._pending_tasks.remove(task))

return task

def transfer_sip_participant(

self,

participant: rtc.RemoteParticipant | str,

transfer_to: str,

play_dialtone: bool = False,

) -> asyncio.Future[api.SIPParticipantInfo]:  # type: ignore

"""Transfer a SIP participant to another number.

Args:

participant: The participant to transfer

transfer_to: The number or SIP destination to transfer the participant to.

This can either be a number (+12345555555) or a

sip host (sip:<user>@<host>)

play_dialtone: Whether to play a dialtone during transfer. Defaults to True.

Returns:

Future that completes when the transfer is complete

Make sure you have enabled call transfer on your provider SIP trunk.

See https://docs.livekit.io/sip/transfer-cold/ for more information.

"""

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning(

"job_ctx.transfer_sip_participant() is not executed while in console mode"

)

fut = asyncio.Future[api.SIPParticipantInfo]()

fut.set_result(api.SIPParticipantInfo())

return fut

if isinstance(participant, rtc.RemoteParticipant):

assert participant.kind == rtc.ParticipantKind.PARTICIPANT_KIND_SIP, (

"Participant must be a SIP participant"

)

participant_identity = participant.identity

else:

participant_identity = participant

task = asyncio.create_task(

self.api.sip.transfer_sip_participant(

api.TransferSIPParticipantRequest(

room_name=self._room.name,

participant_identity=participant_identity,

transfer_to=transfer_to,

play_dialtone=play_dialtone,

)

),

)

self._pending_tasks.append(task)

task.add_done_callback(lambda _: self._pending_tasks.remove(task))

return task

def shutdown(self, reason: str = "") -> None:

self._on_shutdown(reason)

def add_participant_entrypoint(

self,

entrypoint_fnc: Callable[[JobContext, rtc.RemoteParticipant], Coroutine[None, None, None]],

*_: Any,

kind: list[rtc.ParticipantKind.ValueType]

| rtc.ParticipantKind.ValueType = DEFAULT_PARTICIPANT_KINDS,

) -> None:

"""Adds an entrypoint function to be run when a participant joins the room. In cases where

the participant has already joined, the entrypoint will be run immediately. Multiple unique entrypoints can be

added and they will each be run in parallel for each participant.

"""  # noqa: E501

if entrypoint_fnc in [e for (e, _) in self._participant_entrypoints]:

raise ValueError("entrypoints cannot be added more than once")

self._participant_entrypoints.append((entrypoint_fnc, kind))

def _participant_available(self, p: rtc.RemoteParticipant) -> None:

for coro, kind in self._participant_entrypoints:

if isinstance(kind, list):

if p.kind not in kind:

continue

else:

if p.kind != kind:

continue

if (p.identity, coro) in self._participant_tasks:

logger.warning(

f"a participant has joined before a prior participant task matching the same identity has finished: '{p.identity}'"  # noqa: E501

)

task_name = f"part-entry-{p.identity}-{coro.__name__}"

task = asyncio.create_task(coro(self, p), name=task_name)

self._participant_tasks[(p.identity, coro)] = task

task.add_done_callback(

lambda _, coro=coro: self._participant_tasks.pop((p.identity, coro))  # type: ignore

)

def token_claims(self) -> Claims:

return api.TokenVerifier().verify(self._info.token, verify_signature=False)

Instance variables

prop

agent

: rtc.LocalParticipant

Expand source code

@property

def agent(self) -> rtc.LocalParticipant:

return self._room.local_participant

var

api

: api.LiveKitAPI

Expand source code

@functools.cached_property

def api(self) -> api.LiveKitAPI:

"""Returns an LiveKitAPI for making API calls to LiveKit.

Credentials are sourced from environment variables if not provided explicitly.

When starting via the worker, values passed in `WorkerOptions` are exported to

LIVEKIT_URL, LIVEKIT_API_KEY, and LIVEKIT_API_SECRET so this API is always

usable inside job entrypoints.

"""

return api.LiveKitAPI(session=http_context.http_session())

Returns an LiveKitAPI for making API calls to LiveKit.

Credentials are sourced from environment variables if not provided explicitly.

When starting via the worker, values passed in

WorkerOptions

are exported to

LIVEKIT_URL, LIVEKIT_API_KEY, and LIVEKIT_API_SECRET so this API is always

usable inside job entrypoints.

prop

inference_executor

: InferenceExecutor

Expand source code

@property

def inference_executor(self) -> InferenceExecutor:

return self._inf_executor

prop

job

: agent.Job

Expand source code

@property

def job(self) -> agent.Job:

"""Returns the current job that the worker is executing."""

return self._info.job

Returns the current job that the worker is executing.

prop

log_context_fields

: dict[str, Any]

Expand source code

@property

def log_context_fields(self) -> dict[str, Any]:

"""

Returns the current dictionary of log fields that will be injected into log records.

These fields enable enriched structured logging and can include job metadata,

worker ID, trace IDs, or other diagnostic context.

The returned dictionary can be directly edited, or entirely replaced via assignment

(e.g., `job_context.log_context_fields = {...}`)

"""

return self._log_fields

Returns the current dictionary of log fields that will be injected into log records.

These fields enable enriched structured logging and can include job metadata,

worker ID, trace IDs, or other diagnostic context.

The returned dictionary can be directly edited, or entirely replaced via assignment

(e.g.,

job_context.log_context_fields = {...}

)

prop

proc

:

JobProcess

Expand source code

@property

def proc(self) -> JobProcess:

"""Returns the process running the job. Useful for storing process-specific state."""

return self._proc

Returns the process running the job. Useful for storing process-specific state.

prop

room

: rtc.Room

Expand source code

@property

def room(self) -> rtc.Room:

"""The Room object is the main interface that the worker should interact with.

When the entrypoint is called, the worker has not connected to the Room yet.

Certain properties of Room would not be available before calling JobContext.connect()

"""

return self._room

The Room object is the main interface that the worker should interact with.

When the entrypoint is called, the worker has not connected to the Room yet.

Certain properties of Room would not be available before calling JobContext.connect()

prop

worker_id

: str

Expand source code

@property

def worker_id(self) -> str:

"""Returns the id of the worker."""

return self._info.worker_id

Returns the id of the worker.

Methods

def

add_participant_entrypoint

(

self,

entrypoint_fnc: Callable[[

JobContext

, rtc.RemoteParticipant], Coroutine[None, None, None]],

*_: Any,

kind: list[rtc.ParticipantKind.ValueType] | rtc.ParticipantKind.ValueType = [3, 0]) ‑> None

Expand source code

def add_participant_entrypoint(

self,

entrypoint_fnc: Callable[[JobContext, rtc.RemoteParticipant], Coroutine[None, None, None]],

*_: Any,

kind: list[rtc.ParticipantKind.ValueType]

| rtc.ParticipantKind.ValueType = DEFAULT_PARTICIPANT_KINDS,

) -> None:

"""Adds an entrypoint function to be run when a participant joins the room. In cases where

the participant has already joined, the entrypoint will be run immediately. Multiple unique entrypoints can be

added and they will each be run in parallel for each participant.

"""  # noqa: E501

if entrypoint_fnc in [e for (e, _) in self._participant_entrypoints]:

raise ValueError("entrypoints cannot be added more than once")

self._participant_entrypoints.append((entrypoint_fnc, kind))

Adds an entrypoint function to be run when a participant joins the room. In cases where

the participant has already joined, the entrypoint will be run immediately. Multiple unique entrypoints can be

added and they will each be run in parallel for each participant.

def

add_shutdown_callback

(

self,

callback: Callable[[], Coroutine[None, None, None]] | Callable[[str], Coroutine[None, None, None]]) ‑> None

Expand source code

def add_shutdown_callback(

self,

callback: Callable[[], Coroutine[None, None, None]]

| Callable[[str], Coroutine[None, None, None]],

) -> None:

"""

Add a callback to be called when the job is shutting down.

Optionally the callback can take a single argument, the shutdown reason.

"""

min_args_num = 2 if inspect.ismethod(callback) else 1

if callback.__code__.co_argcount >= min_args_num:

self._shutdown_callbacks.append(callback)  # type: ignore

else:

async def wrapper(_: str) -> None:

await callback()  # type: ignore

self._shutdown_callbacks.append(wrapper)

Add a callback to be called when the job is shutting down.

Optionally the callback can take a single argument, the shutdown reason.

def

add_sip_participant

(

self,

*,

call_to: str,

trunk_id: str,

participant_identity: str,

participant_name: NotGivenOr[str] = 'SIP-participant') ‑> _asyncio.Future[sip.SIPParticipantInfo]

Expand source code

def add_sip_participant(

self,

*,

call_to: str,

trunk_id: str,

participant_identity: str,

participant_name: NotGivenOr[str] = "SIP-participant",

) -> asyncio.Future[api.SIPParticipantInfo]:  # type: ignore

"""

Add a SIP participant to the room.

Args:

call_to: The number or SIP destination to transfer the participant to.

This can either be a number (+12345555555) or a

sip host (sip:<user>@<host>)

trunk_id: The ID of the SIP trunk to use

participant_identity: The identity of the participant to add

participant_name: The name of the participant to add

Make sure you have an outbound SIP trunk created in LiveKit.

See https://docs.livekit.io/sip/trunk-outbound/ for more information.

"""

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning("job_ctx.add_sip_participant() is not executed while in console mode")

fut = asyncio.Future[api.SIPParticipantInfo]()

fut.set_result(api.SIPParticipantInfo())

return fut

task = asyncio.create_task(

self.api.sip.create_sip_participant(

api.CreateSIPParticipantRequest(

room_name=self._room.name,

participant_identity=participant_identity,

sip_trunk_id=trunk_id,

sip_call_to=call_to,

participant_name=participant_name if is_given(participant_name) else None,

)

),

)

self._pending_tasks.append(task)

task.add_done_callback(lambda _: self._pending_tasks.remove(task))

return task

Add a SIP participant to the room.

Args

call_to

The number or SIP destination to transfer the participant to.

This can either be a number (+12345555555) or a

sip host (sip:

@

)

trunk_id

The ID of the SIP trunk to use

participant_identity

The identity of the participant to add

participant_name

The name of the participant to add

Make sure you have an outbound SIP trunk created in LiveKit.

See

https://docs.livekit.io/sip/trunk-outbound/

for more information.

async def

connect

(

self,

*,

e2ee: rtc.E2EEOptions | None = None,

auto_subscribe:

AutoSubscribe

= AutoSubscribe.SUBSCRIBE_ALL,

rtc_config: rtc.RtcConfiguration | None = None) ‑> None

Expand source code

async def connect(

self,

*,

e2ee: rtc.E2EEOptions | None = None,

auto_subscribe: AutoSubscribe = AutoSubscribe.SUBSCRIBE_ALL,

rtc_config: rtc.RtcConfiguration | None = None,

) -> None:

"""Connect to the room. This method should be called only once.

Args:

e2ee: End-to-end encryption options. If provided, the Agent will utilize end-to-end encryption. Note: clients will also need to handle E2EE.

auto_subscribe: Whether to automatically subscribe to tracks. Default is AutoSubscribe.SUBSCRIBE_ALL.

rtc_config: Custom RTC configuration to use when connecting to the room.

"""  # noqa: E501

async with self._lock:

if self._connected:

return

room_options = rtc.RoomOptions(

e2ee=e2ee,

auto_subscribe=auto_subscribe == AutoSubscribe.SUBSCRIBE_ALL,

rtc_config=rtc_config,

)

await self._room.connect(self._info.url, self._info.token, options=room_options)

self._on_connect()

for p in self._room.remote_participants.values():

self._participant_available(p)

_apply_auto_subscribe_opts(self._room, auto_subscribe)

self._connected = True

Connect to the room. This method should be called only once.

Args

e2ee

End-to-end encryption options. If provided, the Agent will utilize end-to-end encryption. Note: clients will also need to handle E2EE.

auto_subscribe

Whether to automatically subscribe to tracks. Default is AutoSubscribe.SUBSCRIBE_ALL.

rtc_config

Custom RTC configuration to use when connecting to the room.

def

delete_room

(

self) ‑> _asyncio.Future[room.DeleteRoomResponse]

Expand source code

def delete_room(self) -> asyncio.Future[api.DeleteRoomResponse]:  # type: ignore

"""Deletes the room and disconnects all participants."""

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning("job_ctx.delete_room() is not executed while in console mode")

fut = asyncio.Future[api.DeleteRoomResponse]()

fut.set_result(api.DeleteRoomResponse())

return fut

async def _delete_room() -> None:

try:

await self.api.room.delete_room(api.DeleteRoomRequest(room=self._room.name))

except aiohttp.ServerDisconnectedError:

logger.warning("server disconnected while deleting room")

except api.TwirpError as e:

if e.code != api.TwirpErrorCode.NOT_FOUND:

logger.warning(f"error while deleting room: {e}")

except Exception:

logger.exception("unknown error while deleting room")

task = asyncio.create_task(_delete_room())

self._pending_tasks.append(task)

task.add_done_callback(lambda _: self._pending_tasks.remove(task))

return task

Deletes the room and disconnects all participants.

def

shutdown

(

self, reason: str = '') ‑> None

Expand source code

def shutdown(self, reason: str = "") -> None:

self._on_shutdown(reason)

def

token_claims

(

self) ‑>

Claims

Expand source code

def token_claims(self) -> Claims:

return api.TokenVerifier().verify(self._info.token, verify_signature=False)

def

transfer_sip_participant

(

self,

participant: rtc.RemoteParticipant | str,

transfer_to: str,

play_dialtone: bool = False) ‑> _asyncio.Future[sip.SIPParticipantInfo]

Expand source code

def transfer_sip_participant(

self,

participant: rtc.RemoteParticipant | str,

transfer_to: str,

play_dialtone: bool = False,

) -> asyncio.Future[api.SIPParticipantInfo]:  # type: ignore

"""Transfer a SIP participant to another number.

Args:

participant: The participant to transfer

transfer_to: The number or SIP destination to transfer the participant to.

This can either be a number (+12345555555) or a

sip host (sip:<user>@<host>)

play_dialtone: Whether to play a dialtone during transfer. Defaults to True.

Returns:

Future that completes when the transfer is complete

Make sure you have enabled call transfer on your provider SIP trunk.

See https://docs.livekit.io/sip/transfer-cold/ for more information.

"""

if cli.CLI_ARGUMENTS is not None and cli.CLI_ARGUMENTS.console:

logger.warning(

"job_ctx.transfer_sip_participant() is not executed while in console mode"

)

fut = asyncio.Future[api.SIPParticipantInfo]()

fut.set_result(api.SIPParticipantInfo())

return fut

if isinstance(participant, rtc.RemoteParticipant):

assert participant.kind == rtc.ParticipantKind.PARTICIPANT_KIND_SIP, (

"Participant must be a SIP participant"

)

participant_identity = participant.identity

else:

participant_identity = participant

task = asyncio.create_task(

self.api.sip.transfer_sip_participant(

api.TransferSIPParticipantRequest(

room_name=self._room.name,

participant_identity=participant_identity,

transfer_to=transfer_to,

play_dialtone=play_dialtone,

)

),

)

self._pending_tasks.append(task)

task.add_done_callback(lambda _: self._pending_tasks.remove(task))

return task

Transfer a SIP participant to another number.

Args

participant

The participant to transfer

transfer_to

The number or SIP destination to transfer the participant to.

This can either be a number (+12345555555) or a

sip host (sip:

@

)

play_dialtone

Whether to play a dialtone during transfer. Defaults to True.

Returns

Future that completes when the transfer is complete

Make sure you have enabled call transfer on your provider SIP trunk.

See

https://docs.livekit.io/sip/transfer-cold/

for more information.

async def

wait_for_participant

(

self,

*,

identity: str | None = None,

kind: list[rtc.ParticipantKind.ValueType] | rtc.ParticipantKind.ValueType = [3, 0]) ‑>

RemoteParticipant

Expand source code

async def wait_for_participant(

self,

*,

identity: str | None = None,

kind: list[rtc.ParticipantKind.ValueType]

| rtc.ParticipantKind.ValueType = DEFAULT_PARTICIPANT_KINDS,

) -> rtc.RemoteParticipant:

"""

Returns a participant that matches the given identity. If identity is None, the first

participant that joins the room will be returned.

If the participant has already joined, the function will return immediately.

"""

return await wait_for_participant(self._room, identity=identity, kind=kind)

Returns a participant that matches the given identity. If identity is None, the first

participant that joins the room will be returned.

If the participant has already joined, the function will return immediately.

class

JobExecutorType

(

*args, **kwds)

Expand source code

@unique

class JobExecutorType(Enum):

PROCESS = "process"

THREAD = "thread"

Create a collection of name/value pairs.

Example enumeration:

>>> class Color(Enum):

...     RED = 1

...     BLUE = 2

...     GREEN = 3

Access them by:

attribute access:

Color.RED

value lookup:

Color(1)

name lookup:

Color['RED']

Enumerations can be iterated over, and know how many members they have:

>>> len(Color)

3

>>> list(Color)

[<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]

Methods can be added to enumerations, and members can have their own

attributes – see the documentation for details.

Ancestors

enum.Enum

Class variables

var

PROCESS

var

THREAD

class

JobProcess

(

*,

executor_type:

JobExecutorType

,

user_arguments: Any | None,

http_proxy: str | None)

Expand source code

class JobProcess:

def __init__(

self,

*,

executor_type: JobExecutorType,

user_arguments: Any | None,

http_proxy: str | None,

) -> None:

self._executor_type = executor_type

self._mp_proc = mp.current_process()

self._userdata: dict[str, Any] = {}

self._user_arguments = user_arguments

self._http_proxy: str | None = http_proxy

@property

def executor_type(self) -> JobExecutorType:

return self._executor_type

@property

def pid(self) -> int | None:

return self._mp_proc.pid

@property

def userdata(self) -> dict[Any, Any]:

return self._userdata

@property

def user_arguments(self) -> Any | None:

return self._user_arguments

@property

def http_proxy(self) -> str | None:

return self._http_proxy

Instance variables

prop

executor_type

:

JobExecutorType

Expand source code

@property

def executor_type(self) -> JobExecutorType:

return self._executor_type

prop

http_proxy

: str | None

Expand source code

@property

def http_proxy(self) -> str | None:

return self._http_proxy

prop

pid

: int | None

Expand source code

@property

def pid(self) -> int | None:

return self._mp_proc.pid

prop

user_arguments

: Any | None

Expand source code

@property

def user_arguments(self) -> Any | None:

return self._user_arguments

prop

userdata

: dict[Any, Any]

Expand source code

@property

def userdata(self) -> dict[Any, Any]:

return self._userdata

class

JobRequest

(

*,

job: agent.Job,

on_reject: Callable[[], Coroutine[None, None, None]],

on_accept: Callable[[JobAcceptArguments], Coroutine[None, None, None]])

Expand source code

class JobRequest:

def __init__(

self,

*,

job: agent.Job,

on_reject: Callable[[], Coroutine[None, None, None]],

on_accept: Callable[[JobAcceptArguments], Coroutine[None, None, None]],

) -> None:

self._job = job

self._lock = asyncio.Lock()

self._on_reject = on_reject

self._on_accept = on_accept

@property

def id(self) -> str:

return self._job.id

@property

def job(self) -> agent.Job:

return self._job

@property

def room(self) -> models.Room:

return self._job.room

@property

def publisher(self) -> models.ParticipantInfo | None:

return self._job.participant

@property

def agent_name(self) -> str:

return self._job.agent_name

async def reject(self) -> None:

"""Reject the job request. The job may be assigned to another worker"""

await self._on_reject()

async def accept(

self,

*,

name: str = "",

identity: str = "",

metadata: str = "",

attributes: dict[str, str] | None = None,

) -> None:

"""Accept the job request, and start the job if the LiveKit SFU assigns the job to our worker."""  # noqa: E501

if not identity:

identity = "agent-" + self.id

accept_arguments = JobAcceptArguments(

name=name,

identity=identity,

metadata=metadata,

attributes=attributes,

)

await self._on_accept(accept_arguments)

Instance variables

prop

agent_name

: str

Expand source code

@property

def agent_name(self) -> str:

return self._job.agent_name

prop

id

: str

Expand source code

@property

def id(self) -> str:

return self._job.id

prop

job

: agent.Job

Expand source code

@property

def job(self) -> agent.Job:

return self._job

prop

publisher

: models.ParticipantInfo | None

Expand source code

@property

def publisher(self) -> models.ParticipantInfo | None:

return self._job.participant

prop

room

: models.Room

Expand source code

@property

def room(self) -> models.Room:

return self._job.room

Methods

async def

accept

(

self,

*,

name: str = '',

identity: str = '',

metadata: str = '',

attributes: dict[str, str] | None = None) ‑> None

Expand source code

async def accept(

self,

*,

name: str = "",

identity: str = "",

metadata: str = "",

attributes: dict[str, str] | None = None,

) -> None:

"""Accept the job request, and start the job if the LiveKit SFU assigns the job to our worker."""  # noqa: E501

if not identity:

identity = "agent-" + self.id

accept_arguments = JobAcceptArguments(

name=name,

identity=identity,

metadata=metadata,

attributes=attributes,

)

await self._on_accept(accept_arguments)

Accept the job request, and start the job if the LiveKit SFU assigns the job to our worker.

async def

reject

(

self) ‑> None

Expand source code

async def reject(self) -> None:

"""Reject the job request. The job may be assigned to another worker"""

await self._on_reject()

Reject the job request. The job may be assigned to another worker

class

MetricsCollectedEvent

(

**data: Any)

Expand source code

class MetricsCollectedEvent(BaseModel):

type: Literal["metrics_collected"] = "metrics_collected"

metrics: AgentMetrics

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

metrics

: livekit.agents.metrics.base.STTMetrics | livekit.agents.metrics.base.LLMMetrics | livekit.agents.metrics.base.TTSMetrics | livekit.agents.metrics.base.VADMetrics | livekit.agents.metrics.base.EOUMetrics | livekit.agents.metrics.base.RealtimeModelMetrics

var

model_config

var

type

: Literal['metrics_collected']

class

ModelSettings

(

tool_choice: NotGivenOr[llm.ToolChoice] = NOT_GIVEN)

Expand source code

@dataclass

class ModelSettings:

tool_choice: NotGivenOr[llm.ToolChoice] = NOT_GIVEN

"""The tool choice to use when calling the LLM."""

ModelSettings(tool_choice: 'NotGivenOr[llm.ToolChoice]' = NOT_GIVEN)

Instance variables

var

tool_choice

: livekit.agents.llm.tool_context.NamedToolChoice | Literal['auto', 'required', 'none'] | livekit.agents.types.NotGiven

The tool choice to use when calling the LLM.

class

NotGiven

Expand source code

class NotGiven:

def __bool__(self) -> Literal[False]:

return False

def __repr__(self) -> str:

return "NOT_GIVEN"

class

PlayHandle

Expand source code

class PlayHandle:

def __init__(self) -> None:

self._done_fut = asyncio.Future[None]()

self._stop_fut = asyncio.Future[None]()

def done(self) -> bool:

"""

Returns True if the sound has finished playing.

"""

return self._done_fut.done()

def stop(self) -> None:

"""

Stops the sound from playing.

"""

if self.done():

return

with contextlib.suppress(asyncio.InvalidStateError):

self._stop_fut.set_result(None)

self._mark_playout_done()  # TODO(theomonnom): move this to _play_task

async def wait_for_playout(self) -> None:

"""

Waits for the sound to finish playing.

"""

await asyncio.shield(self._done_fut)

def __await__(self) -> Generator[Any, None, PlayHandle]:

async def _await_impl() -> PlayHandle:

await self.wait_for_playout()

return self

return _await_impl().__await__()

def _mark_playout_done(self) -> None:

with contextlib.suppress(asyncio.InvalidStateError):

self._done_fut.set_result(None)

Methods

def

done

(

self) ‑> bool

Expand source code

def done(self) -> bool:

"""

Returns True if the sound has finished playing.

"""

return self._done_fut.done()

Returns True if the sound has finished playing.

def

stop

(

self) ‑> None

Expand source code

def stop(self) -> None:

"""

Stops the sound from playing.

"""

if self.done():

return

with contextlib.suppress(asyncio.InvalidStateError):

self._stop_fut.set_result(None)

self._mark_playout_done()  # TODO(theomonnom): move this to _play_task

Stops the sound from playing.

async def

wait_for_playout

(

self) ‑> None

Expand source code

async def wait_for_playout(self) -> None:

"""

Waits for the sound to finish playing.

"""

await asyncio.shield(self._done_fut)

Waits for the sound to finish playing.

class

Plugin

(

title: str, version: str, package: str, logger: logging.Logger | None = None)

Expand source code

class Plugin(ABC):  # noqa: B024

registered_plugins: list[Plugin] = []

emitter: utils.EventEmitter[EventTypes] = utils.EventEmitter()

# TODO(theomonnom): make logger mandatory once all plugins have been updated

def __init__(

self,

title: str,

version: str,

package: str,

logger: logging.Logger | None = None,

) -> None:

self._title = title

self._version = version

self._package = package

self._logger = logger

@classmethod

def register_plugin(cls, plugin: Plugin) -> None:

if threading.current_thread() != threading.main_thread():

raise RuntimeError("Plugins must be registered on the main thread")

cls.registered_plugins.append(plugin)

cls.emitter.emit("plugin_registered", plugin)

# plugin can implement an optional download_files method

def download_files(self) -> None:  # noqa: B027

pass

@property

def package(self) -> str:

return self._package

@property

def title(self) -> str:

return self._title

@property

def version(self) -> str:

return self._version

@property

def logger(self) -> logging.Logger | None:

return self._logger

Helper class that provides a standard way to create an ABC using

inheritance.

Ancestors

abc.ABC

Subclasses

livekit.plugins.anam.AnamPlugin

livekit.plugins.anthropic.AnthropicPlugin

livekit.plugins.assemblyai.AssemblyAIPlugin

livekit.plugins.aws.AWSPlugin

livekit.plugins.azure.AzurePlugin

livekit.plugins.baseten.BasetenPlugin

livekit.plugins.bey.BeyPlugin

livekit.plugins.bithuman.BitHumanPlugin

livekit.plugins.cartesia.CartesiaPlugin

livekit.plugins.clova.ClovaSTTPlugin

livekit.plugins.deepgram.DeepgramPlugin

livekit.plugins.elevenlabs.ElevenLabsPlugin

livekit.plugins.fal.FalPlugin

livekit.plugins.fireworksai.FireworksAIPlugin

livekit.plugins.gladia.GladiaPlugin

livekit.plugins.google.GooglePlugin

livekit.plugins.groq.GroqPlugin

livekit.plugins.hedra.HedraPlugin

livekit.plugins.hume.HumeAIPlugin

livekit.plugins.inworld.InworldPlugin

livekit.plugins.langchain.LangChainPlugin

livekit.plugins.lmnt.LMNTPlugin

MinimalPlugin

livekit.plugins.minimax.MiniMaxPlugin

livekit.plugins.mistralai.MistralAIPlugin

livekit.plugins.neuphonic.NeuphonicPlugin

livekit.plugins.nltk.NltkPlugin

livekit.plugins.openai.OpenAIPlugin

livekit.plugins.resemble.ResemblePlugin

livekit.plugins.rime.RimePlugin

livekit.plugins.rtzr.RTZRPlugin

livekit.plugins.sarvam.SarvamPlugin

livekit.plugins.silero.SileroPlugin

livekit.plugins.simli.SimliPlugin

livekit.plugins.smallestai.SmallestAIPlugin

livekit.plugins.soniox.SonioxPlugin

livekit.plugins.speechify.SpeechifyPlugin

livekit.plugins.speechmatics.SpeechmaticsPlugin

livekit.plugins.spitch.SpitchPlugin

livekit.plugins.tavus.TavusPlugin

livekit.plugins.turn_detector.EOUPlugin

livekit.plugins.ultravox.UltravoxPlugin

Class variables

var

emitter

:

EventEmitter

[typing.Literal['plugin_registered']]

var

registered_plugins

: list[livekit.agents.plugin.Plugin]

Static methods

def

register_plugin

(

plugin:

Plugin

) ‑> None

Instance variables

prop

logger

: logging.Logger | None

Expand source code

@property

def logger(self) -> logging.Logger | None:

return self._logger

prop

package

: str

Expand source code

@property

def package(self) -> str:

return self._package

prop

title

: str

Expand source code

@property

def title(self) -> str:

return self._title

prop

version

: str

Expand source code

@property

def version(self) -> str:

return self._version

Methods

def

download_files

(

self) ‑> None

Expand source code

def download_files(self) -> None:  # noqa: B027

pass

class

RoomIO

(

agent_session:

AgentSession

,

room: rtc.Room,

*,

participant: rtc.RemoteParticipant | str | None = None,

input_options:

RoomInputOptions

= RoomInputOptions(text_enabled=NOT_GIVEN, audio_enabled=NOT_GIVEN, video_enabled=NOT_GIVEN, audio_sample_rate=24000, audio_num_channels=1, noise_cancellation=None, text_input_cb=<function _default_text_input_cb>, participant_kinds=NOT_GIVEN, participant_identity=NOT_GIVEN, pre_connect_audio=True, pre_connect_audio_timeout=3.0, close_on_disconnect=True, delete_room_on_close=False),

output_options:

RoomOutputOptions

= RoomOutputOptions(transcription_enabled=NOT_GIVEN, audio_enabled=NOT_GIVEN, audio_sample_rate=24000, audio_num_channels=1, audio_publish_options=source: SOURCE_MICROPHONE

, audio_track_name=NOT_GIVEN, sync_transcription=NOT_GIVEN, transcription_speed_factor=1.0))

Expand source code

class RoomIO:

def __init__(

self,

agent_session: AgentSession,

room: rtc.Room,

*,

participant: rtc.RemoteParticipant | str | None = None,

input_options: RoomInputOptions = DEFAULT_ROOM_INPUT_OPTIONS,

output_options: RoomOutputOptions = DEFAULT_ROOM_OUTPUT_OPTIONS,

) -> None:

self._agent_session, self._room = agent_session, room

self._input_options = input_options

self._output_options = output_options

self._participant_identity = (

participant.identity if isinstance(participant, rtc.RemoteParticipant) else participant

)

if self._participant_identity is None and utils.is_given(

input_options.participant_identity

):

self._participant_identity = input_options.participant_identity

self._audio_input: _ParticipantAudioInputStream | None = None

self._video_input: _ParticipantVideoInputStream | None = None

self._audio_output: _ParticipantAudioOutput | None = None

self._user_tr_output: _ParticipantTranscriptionOutput | None = None

self._agent_tr_output: _ParticipantTranscriptionOutput | None = None

self._tr_synchronizer: TranscriptSynchronizer | None = None

self._participant_available_fut = asyncio.Future[rtc.RemoteParticipant]()

self._room_connected_fut = asyncio.Future[None]()

self._init_atask: asyncio.Task[None] | None = None

self._user_transcript_ch = utils.aio.Chan[UserInputTranscribedEvent]()

self._user_transcript_atask: asyncio.Task[None] | None = None

self._tasks: set[asyncio.Task[Any]] = set()

self._update_state_atask: asyncio.Task[None] | None = None

self._close_session_atask: asyncio.Task[None] | None = None

self._delete_room_task: asyncio.Future[api.DeleteRoomResponse] | None = None

self._pre_connect_audio_handler: PreConnectAudioHandler | None = None

self._text_stream_handler_registered = False

async def start(self) -> None:

# -- create inputs --

if self._input_options.pre_connect_audio:

self._pre_connect_audio_handler = PreConnectAudioHandler(

room=self._room,

timeout=self._input_options.pre_connect_audio_timeout,

)

self._pre_connect_audio_handler.register()

if self._input_options.text_enabled or not utils.is_given(self._input_options.text_enabled):

try:

self._room.register_text_stream_handler(TOPIC_CHAT, self._on_user_text_input)

self._text_stream_handler_registered = True

except ValueError:

if self._input_options.text_enabled:

logger.warning(

f"text stream handler for topic '{TOPIC_CHAT}' already set, ignoring"

)

if self._input_options.video_enabled:

self._video_input = _ParticipantVideoInputStream(self._room)

if self._input_options.audio_enabled or not utils.is_given(

self._input_options.audio_enabled

):

self._audio_input = _ParticipantAudioInputStream(

self._room,

sample_rate=self._input_options.audio_sample_rate,

num_channels=self._input_options.audio_num_channels,

noise_cancellation=self._input_options.noise_cancellation,

pre_connect_audio_handler=self._pre_connect_audio_handler,

)

# -- create outputs --

if self._output_options.audio_enabled or not utils.is_given(

self._output_options.audio_enabled

):

self._audio_output = _ParticipantAudioOutput(

self._room,

sample_rate=self._output_options.audio_sample_rate,

num_channels=self._output_options.audio_num_channels,

track_publish_options=self._output_options.audio_publish_options,

track_name=self._output_options.audio_track_name

if utils.is_given(self._output_options.audio_track_name)

else "roomio_audio",

)

if self._output_options.transcription_enabled or not utils.is_given(

self._output_options.transcription_enabled

):

self._user_tr_output = _ParticipantTranscriptionOutput(

room=self._room, is_delta_stream=False, participant=self._participant_identity

)

self._user_transcript_atask = asyncio.create_task(self._forward_user_transcript())

# TODO(long): add next in the chain for session.output.transcription

self._agent_tr_output = _ParticipantTranscriptionOutput(

room=self._room, is_delta_stream=True, participant=None

)

# use the RoomIO's audio output if available, otherwise use the agent's audio output

# (e.g the audio output isn't using RoomIO with our avatar datastream impl)

sync_transcription = True

if utils.is_given(self._output_options.sync_transcription):

sync_transcription = self._output_options.sync_transcription

if sync_transcription and (

audio_output := self._audio_output or self._agent_session.output.audio

):

self._tr_synchronizer = TranscriptSynchronizer(

next_in_chain_audio=audio_output,

next_in_chain_text=self._agent_tr_output,

speed=self._output_options.transcription_speed_factor,

)

# -- set the room event handlers --

self._room.on("participant_connected", self._on_participant_connected)

self._room.on("connection_state_changed", self._on_connection_state_changed)

self._room.on("participant_disconnected", self._on_participant_disconnected)

if self._room.isconnected():

self._on_connection_state_changed(rtc.ConnectionState.CONN_CONNECTED)

self._init_atask = asyncio.create_task(self._init_task())

# -- attach to the agent session --

if self.audio_input:

self._agent_session.input.audio = self.audio_input

if self.video_input:

self._agent_session.input.video = self.video_input

if self.audio_output:

self._agent_session.output.audio = self.audio_output

if self.transcription_output:

self._agent_session.output.transcription = self.transcription_output

self._agent_session.on("agent_state_changed", self._on_agent_state_changed)

self._agent_session.on("user_input_transcribed", self._on_user_input_transcribed)

self._agent_session.on("close", self._on_agent_session_close)

self._agent_session._room_io = self

async def aclose(self) -> None:

self._room.off("participant_connected", self._on_participant_connected)

self._room.off("connection_state_changed", self._on_connection_state_changed)

self._agent_session.off("agent_state_changed", self._on_agent_state_changed)

self._agent_session.off("user_input_transcribed", self._on_user_input_transcribed)

self._agent_session.off("close", self._on_agent_session_close)

if self._text_stream_handler_registered:

self._room.unregister_text_stream_handler(TOPIC_CHAT)

self._text_stream_handler_registered = False

if self._init_atask:

await utils.aio.cancel_and_wait(self._init_atask)

self._user_transcript_ch.close()

if self._user_transcript_atask:

await utils.aio.cancel_and_wait(self._user_transcript_atask)

if self._update_state_atask:

await utils.aio.cancel_and_wait(self._update_state_atask)

if self._pre_connect_audio_handler:

await self._pre_connect_audio_handler.aclose()

if self._audio_input:

await self._audio_input.aclose()

if self._video_input:

await self._video_input.aclose()

if self._tr_synchronizer:

await self._tr_synchronizer.aclose()

if self._audio_output:

await self._audio_output.aclose()

# cancel and wait for all pending tasks

await utils.aio.cancel_and_wait(*self._tasks)

self._tasks.clear()

@property

def audio_output(self) -> AudioOutput | None:

if self._tr_synchronizer:

return self._tr_synchronizer.audio_output

return self._audio_output

@property

def transcription_output(self) -> TextOutput | None:

if self._tr_synchronizer:

return self._tr_synchronizer.text_output

return self._agent_tr_output

@property

def audio_input(self) -> AudioInput | None:

return self._audio_input

@property

def video_input(self) -> VideoInput | None:

return self._video_input

@property

def linked_participant(self) -> rtc.RemoteParticipant | None:

if not self._participant_available_fut.done():

return None

return self._participant_available_fut.result()

@property

def subscribed_fut(self) -> asyncio.Future[None] | None:

if self._audio_output:

return self._audio_output.subscribed

return None

def set_participant(self, participant_identity: str | None) -> None:

"""Switch audio and video streams to specified participant"""

if participant_identity is None:

self.unset_participant()

return

if (

self._participant_identity is not None

and self._participant_identity != participant_identity

):

# reset future if switching to a different participant

self._participant_available_fut = asyncio.Future[rtc.RemoteParticipant]()

# check if new participant is already connected

for participant in self._room.remote_participants.values():

if participant.identity == participant_identity:

self._participant_available_fut.set_result(participant)

break

# update participant identity and handlers

self._participant_identity = participant_identity

if self._audio_input:

self._audio_input.set_participant(participant_identity)

if self._video_input:

self._video_input.set_participant(participant_identity)

if self._user_tr_output:

self._user_tr_output.set_participant(participant_identity)

def unset_participant(self) -> None:

self._participant_identity = None

self._participant_available_fut = asyncio.Future[rtc.RemoteParticipant]()

if self._audio_input:

self._audio_input.set_participant(None)

if self._video_input:

self._video_input.set_participant(None)

if self._user_tr_output:

self._user_tr_output.set_participant(None)

@utils.log_exceptions(logger=logger)

async def _init_task(self) -> None:

await self._room_connected_fut

# check existing participants

for participant in self._room.remote_participants.values():

self._on_participant_connected(participant)

participant = await self._participant_available_fut

self.set_participant(participant.identity)

# init outputs

if self._agent_tr_output:

self._agent_tr_output.set_participant(self._room.local_participant.identity)

if self._audio_output:

await self._audio_output.start()

@utils.log_exceptions(logger=logger)

async def _forward_user_transcript(self) -> None:

async for ev in self._user_transcript_ch:

if self._user_tr_output is None:

continue

await self._user_tr_output.capture_text(ev.transcript)

if ev.is_final:

self._user_tr_output.flush()

def _on_connection_state_changed(self, state: rtc.ConnectionState.ValueType) -> None:

if self._room.isconnected() and not self._room_connected_fut.done():

self._room_connected_fut.set_result(None)

def _on_participant_connected(self, participant: rtc.RemoteParticipant) -> None:

if self._participant_available_fut.done():

return

if self._participant_identity is not None:

if participant.identity != self._participant_identity:

return

# otherwise, skip participants that are marked as publishing for this agent

elif (

participant.attributes.get(ATTRIBUTE_PUBLISH_ON_BEHALF)

== self._room.local_participant.identity

):

return

accepted_kinds = self._input_options.participant_kinds or DEFAULT_PARTICIPANT_KINDS

if participant.kind not in accepted_kinds:

# not an accepted participant kind, skip

return

self._participant_available_fut.set_result(participant)

def _on_participant_disconnected(self, participant: rtc.RemoteParticipant) -> None:

if not (linked := self.linked_participant) or participant.identity != linked.identity:

return

self._participant_available_fut = asyncio.Future[rtc.RemoteParticipant]()

if (

self._input_options.close_on_disconnect

and participant.disconnect_reason in DEFAULT_CLOSE_ON_DISCONNECT_REASONS

and not self._close_session_atask

and not self._delete_room_task

):

logger.info(

"closing agent session due to participant disconnect "

"(disable via `RoomInputOptions.close_on_disconnect=False`)",

extra={

"participant": participant.identity,

"reason": rtc.DisconnectReason.Name(

participant.disconnect_reason or rtc.DisconnectReason.UNKNOWN_REASON

),

},

)

self._agent_session._close_soon(reason=CloseReason.PARTICIPANT_DISCONNECTED)

def _on_user_input_transcribed(self, ev: UserInputTranscribedEvent) -> None:

if self._user_transcript_atask:

self._user_transcript_ch.send_nowait(ev)

def _on_user_text_input(self, reader: rtc.TextStreamReader, participant_identity: str) -> None:

if participant_identity != self._participant_identity:

return

participant = self._room.remote_participants.get(participant_identity)

if not participant:

logger.warning("participant not found, ignoring text input")

return

async def _read_text() -> None:

text = await reader.read_all()

text_input_result = self._input_options.text_input_cb(

self._agent_session,

TextInputEvent(text=text, info=reader.info, participant=participant),

)

if asyncio.iscoroutine(text_input_result):

await text_input_result

task = asyncio.create_task(_read_text())

self._tasks.add(task)

task.add_done_callback(self._tasks.discard)

def _on_agent_state_changed(self, ev: AgentStateChangedEvent) -> None:

@utils.log_exceptions(logger=logger)

async def _set_state() -> None:

if self._room.isconnected():

await self._room.local_participant.set_attributes(

{ATTRIBUTE_AGENT_STATE: ev.new_state}

)

if self._update_state_atask is not None:

self._update_state_atask.cancel()

self._update_state_atask = asyncio.create_task(_set_state())

def _on_agent_session_close(self, ev: CloseEvent) -> None:

def _on_delete_room_task_done(task: asyncio.Future[api.DeleteRoomResponse]) -> None:

self._delete_room_task = None

if self._input_options.delete_room_on_close and self._delete_room_task is None:

job_ctx = get_job_context()

logger.info(

"deleting room on agent session close (disable via `RoomInputOptions.delete_room_on_close=False`)"

)

self._delete_room_task = job_ctx.delete_room()

self._delete_room_task.add_done_callback(_on_delete_room_task_done)

Instance variables

prop

audio_input

: AudioInput | None

Expand source code

@property

def audio_input(self) -> AudioInput | None:

return self._audio_input

prop

audio_output

: AudioOutput | None

Expand source code

@property

def audio_output(self) -> AudioOutput | None:

if self._tr_synchronizer:

return self._tr_synchronizer.audio_output

return self._audio_output

prop

linked_participant

: rtc.RemoteParticipant | None

Expand source code

@property

def linked_participant(self) -> rtc.RemoteParticipant | None:

if not self._participant_available_fut.done():

return None

return self._participant_available_fut.result()

prop

subscribed_fut

: asyncio.Future[None] | None

Expand source code

@property

def subscribed_fut(self) -> asyncio.Future[None] | None:

if self._audio_output:

return self._audio_output.subscribed

return None

prop

transcription_output

: TextOutput | None

Expand source code

@property

def transcription_output(self) -> TextOutput | None:

if self._tr_synchronizer:

return self._tr_synchronizer.text_output

return self._agent_tr_output

prop

video_input

: VideoInput | None

Expand source code

@property

def video_input(self) -> VideoInput | None:

return self._video_input

Methods

async def

aclose

(

self) ‑> None

Expand source code

async def aclose(self) -> None:

self._room.off("participant_connected", self._on_participant_connected)

self._room.off("connection_state_changed", self._on_connection_state_changed)

self._agent_session.off("agent_state_changed", self._on_agent_state_changed)

self._agent_session.off("user_input_transcribed", self._on_user_input_transcribed)

self._agent_session.off("close", self._on_agent_session_close)

if self._text_stream_handler_registered:

self._room.unregister_text_stream_handler(TOPIC_CHAT)

self._text_stream_handler_registered = False

if self._init_atask:

await utils.aio.cancel_and_wait(self._init_atask)

self._user_transcript_ch.close()

if self._user_transcript_atask:

await utils.aio.cancel_and_wait(self._user_transcript_atask)

if self._update_state_atask:

await utils.aio.cancel_and_wait(self._update_state_atask)

if self._pre_connect_audio_handler:

await self._pre_connect_audio_handler.aclose()

if self._audio_input:

await self._audio_input.aclose()

if self._video_input:

await self._video_input.aclose()

if self._tr_synchronizer:

await self._tr_synchronizer.aclose()

if self._audio_output:

await self._audio_output.aclose()

# cancel and wait for all pending tasks

await utils.aio.cancel_and_wait(*self._tasks)

self._tasks.clear()

def

set_participant

(

self, participant_identity: str | None) ‑> None

Expand source code

def set_participant(self, participant_identity: str | None) -> None:

"""Switch audio and video streams to specified participant"""

if participant_identity is None:

self.unset_participant()

return

if (

self._participant_identity is not None

and self._participant_identity != participant_identity

):

# reset future if switching to a different participant

self._participant_available_fut = asyncio.Future[rtc.RemoteParticipant]()

# check if new participant is already connected

for participant in self._room.remote_participants.values():

if participant.identity == participant_identity:

self._participant_available_fut.set_result(participant)

break

# update participant identity and handlers

self._participant_identity = participant_identity

if self._audio_input:

self._audio_input.set_participant(participant_identity)

if self._video_input:

self._video_input.set_participant(participant_identity)

if self._user_tr_output:

self._user_tr_output.set_participant(participant_identity)

Switch audio and video streams to specified participant

async def

start

(

self) ‑> None

Expand source code

async def start(self) -> None:

# -- create inputs --

if self._input_options.pre_connect_audio:

self._pre_connect_audio_handler = PreConnectAudioHandler(

room=self._room,

timeout=self._input_options.pre_connect_audio_timeout,

)

self._pre_connect_audio_handler.register()

if self._input_options.text_enabled or not utils.is_given(self._input_options.text_enabled):

try:

self._room.register_text_stream_handler(TOPIC_CHAT, self._on_user_text_input)

self._text_stream_handler_registered = True

except ValueError:

if self._input_options.text_enabled:

logger.warning(

f"text stream handler for topic '{TOPIC_CHAT}' already set, ignoring"

)

if self._input_options.video_enabled:

self._video_input = _ParticipantVideoInputStream(self._room)

if self._input_options.audio_enabled or not utils.is_given(

self._input_options.audio_enabled

):

self._audio_input = _ParticipantAudioInputStream(

self._room,

sample_rate=self._input_options.audio_sample_rate,

num_channels=self._input_options.audio_num_channels,

noise_cancellation=self._input_options.noise_cancellation,

pre_connect_audio_handler=self._pre_connect_audio_handler,

)

# -- create outputs --

if self._output_options.audio_enabled or not utils.is_given(

self._output_options.audio_enabled

):

self._audio_output = _ParticipantAudioOutput(

self._room,

sample_rate=self._output_options.audio_sample_rate,

num_channels=self._output_options.audio_num_channels,

track_publish_options=self._output_options.audio_publish_options,

track_name=self._output_options.audio_track_name

if utils.is_given(self._output_options.audio_track_name)

else "roomio_audio",

)

if self._output_options.transcription_enabled or not utils.is_given(

self._output_options.transcription_enabled

):

self._user_tr_output = _ParticipantTranscriptionOutput(

room=self._room, is_delta_stream=False, participant=self._participant_identity

)

self._user_transcript_atask = asyncio.create_task(self._forward_user_transcript())

# TODO(long): add next in the chain for session.output.transcription

self._agent_tr_output = _ParticipantTranscriptionOutput(

room=self._room, is_delta_stream=True, participant=None

)

# use the RoomIO's audio output if available, otherwise use the agent's audio output

# (e.g the audio output isn't using RoomIO with our avatar datastream impl)

sync_transcription = True

if utils.is_given(self._output_options.sync_transcription):

sync_transcription = self._output_options.sync_transcription

if sync_transcription and (

audio_output := self._audio_output or self._agent_session.output.audio

):

self._tr_synchronizer = TranscriptSynchronizer(

next_in_chain_audio=audio_output,

next_in_chain_text=self._agent_tr_output,

speed=self._output_options.transcription_speed_factor,

)

# -- set the room event handlers --

self._room.on("participant_connected", self._on_participant_connected)

self._room.on("connection_state_changed", self._on_connection_state_changed)

self._room.on("participant_disconnected", self._on_participant_disconnected)

if self._room.isconnected():

self._on_connection_state_changed(rtc.ConnectionState.CONN_CONNECTED)

self._init_atask = asyncio.create_task(self._init_task())

# -- attach to the agent session --

if self.audio_input:

self._agent_session.input.audio = self.audio_input

if self.video_input:

self._agent_session.input.video = self.video_input

if self.audio_output:

self._agent_session.output.audio = self.audio_output

if self.transcription_output:

self._agent_session.output.transcription = self.transcription_output

self._agent_session.on("agent_state_changed", self._on_agent_state_changed)

self._agent_session.on("user_input_transcribed", self._on_user_input_transcribed)

self._agent_session.on("close", self._on_agent_session_close)

self._agent_session._room_io = self

def

unset_participant

(

self) ‑> None

Expand source code

def unset_participant(self) -> None:

self._participant_identity = None

self._participant_available_fut = asyncio.Future[rtc.RemoteParticipant]()

if self._audio_input:

self._audio_input.set_participant(None)

if self._video_input:

self._video_input.set_participant(None)

if self._user_tr_output:

self._user_tr_output.set_participant(None)

class

RoomInputOptions

(

text_enabled: NotGivenOr[bool] = NOT_GIVEN,

audio_enabled: NotGivenOr[bool] = NOT_GIVEN,

video_enabled: NotGivenOr[bool] = NOT_GIVEN,

audio_sample_rate: int = 24000,

audio_num_channels: int = 1,

noise_cancellation: rtc.NoiseCancellationOptions | None = None,

text_input_cb: TextInputCallback = <function _default_text_input_cb>,

participant_kinds: NotGivenOr[list[rtc.ParticipantKind.ValueType]] = NOT_GIVEN,

participant_identity: NotGivenOr[str] = NOT_GIVEN,

pre_connect_audio: bool = True,

pre_connect_audio_timeout: float = 3.0,

close_on_disconnect: bool = True,

delete_room_on_close: bool = False)

Expand source code

@dataclass

class RoomInputOptions:

text_enabled: NotGivenOr[bool] = NOT_GIVEN

"""If not given, default to True."""

audio_enabled: NotGivenOr[bool] = NOT_GIVEN

"""If not given, default to True."""

video_enabled: NotGivenOr[bool] = NOT_GIVEN

"""If not given, default to False."""

audio_sample_rate: int = 24000

audio_num_channels: int = 1

noise_cancellation: rtc.NoiseCancellationOptions | None = None

text_input_cb: TextInputCallback = _default_text_input_cb

participant_kinds: NotGivenOr[list[rtc.ParticipantKind.ValueType]] = NOT_GIVEN

"""Participant kinds accepted for auto subscription. If not provided,

accept `DEFAULT_PARTICIPANT_KINDS`."""

participant_identity: NotGivenOr[str] = NOT_GIVEN

"""The participant to link to. If not provided, link to the first participant.

Can be overridden by the `participant` argument of RoomIO constructor or `set_participant`."""

pre_connect_audio: bool = True

"""Pre-connect audio enabled or not."""

pre_connect_audio_timeout: float = 3.0

"""The pre-connect audio will be ignored if it doesn't arrive within this time."""

close_on_disconnect: bool = True

"""Close the AgentSession if the linked participant disconnects with reasons in

CLIENT_INITIATED, ROOM_DELETED, or USER_REJECTED."""

delete_room_on_close: bool = False

"""Delete the room when the AgentSession is closed, default to False"""

RoomInputOptions(text_enabled: 'NotGivenOr[bool]' = NOT_GIVEN, audio_enabled: 'NotGivenOr[bool]' = NOT_GIVEN, video_enabled: 'NotGivenOr[bool]' = NOT_GIVEN, audio_sample_rate: 'int' = 24000, audio_num_channels: 'int' = 1, noise_cancellation: 'rtc.NoiseCancellationOptions | None' = None, text_input_cb: 'TextInputCallback' =

, participant_kinds: 'NotGivenOr[list[rtc.ParticipantKind.ValueType]]' = NOT_GIVEN, participant_identity: 'NotGivenOr[str]' = NOT_GIVEN, pre_connect_audio: 'bool' = True, pre_connect_audio_timeout: 'float' = 3.0, close_on_disconnect: 'bool' = True, delete_room_on_close: 'bool' = False)

Instance variables

var

audio_enabled

: NotGivenOr[bool]

If not given, default to True.

var

audio_num_channels

: int

var

audio_sample_rate

: int

var

close_on_disconnect

: bool

Close the AgentSession if the linked participant disconnects with reasons in

CLIENT_INITIATED, ROOM_DELETED, or USER_REJECTED.

var

delete_room_on_close

: bool

Delete the room when the AgentSession is closed, default to False

var

noise_cancellation

: rtc.NoiseCancellationOptions | None

var

participant_identity

: NotGivenOr[str]

The participant to link to. If not provided, link to the first participant.

Can be overridden by the

participant

argument of RoomIO constructor or

set_participant

.

var

participant_kinds

: NotGivenOr[list[rtc.ParticipantKind.ValueType]]

Participant kinds accepted for auto subscription. If not provided,

accept

DEFAULT_PARTICIPANT_KINDS

.

var

pre_connect_audio

: bool

Pre-connect audio enabled or not.

var

pre_connect_audio_timeout

: float

The pre-connect audio will be ignored if it doesn't arrive within this time.

var

text_enabled

: NotGivenOr[bool]

If not given, default to True.

var

video_enabled

: NotGivenOr[bool]

If not given, default to False.

Methods

def

text_input_cb

(

sess:

AgentSession

,

ev: TextInputEvent) ‑> None

Expand source code

def _default_text_input_cb(sess: AgentSession, ev: TextInputEvent) -> None:

sess.interrupt()

sess.generate_reply(user_input=ev.text)

class

RoomOutputOptions

(

transcription_enabled: NotGivenOr[bool] = NOT_GIVEN,

audio_enabled: NotGivenOr[bool] = NOT_GIVEN,

audio_sample_rate: int = 24000,

audio_num_channels: int = 1,

audio_publish_options: rtc.TrackPublishOptions = <factory>,

audio_track_name: NotGivenOr[str] = NOT_GIVEN,

sync_transcription: NotGivenOr[bool] = NOT_GIVEN,

transcription_speed_factor: float = 1.0)

Expand source code

@dataclass

class RoomOutputOptions:

transcription_enabled: NotGivenOr[bool] = NOT_GIVEN

"""If not given, default to True."""

audio_enabled: NotGivenOr[bool] = NOT_GIVEN

"""If not given, default to True."""

audio_sample_rate: int = 24000

audio_num_channels: int = 1

audio_publish_options: rtc.TrackPublishOptions = field(

default_factory=lambda: rtc.TrackPublishOptions(source=rtc.TrackSource.SOURCE_MICROPHONE)

)

audio_track_name: NotGivenOr[str] = NOT_GIVEN

"""The name of the audio track to publish. If not provided, default to "roomio_audio"."""

sync_transcription: NotGivenOr[bool] = NOT_GIVEN

"""False to disable transcription synchronization with audio output.

Otherwise, transcription is emitted as quickly as available."""

transcription_speed_factor: float = 1.0

"""Speed factor of transcription synchronization with audio output.

Only effective if `sync_transcription` is True."""

RoomOutputOptions(transcription_enabled: 'NotGivenOr[bool]' = NOT_GIVEN, audio_enabled: 'NotGivenOr[bool]' = NOT_GIVEN, audio_sample_rate: 'int' = 24000, audio_num_channels: 'int' = 1, audio_publish_options: 'rtc.TrackPublishOptions' =

, audio_track_name: 'NotGivenOr[str]' = NOT_GIVEN, sync_transcription: 'NotGivenOr[bool]' = NOT_GIVEN, transcription_speed_factor: 'float' = 1.0)

Instance variables

var

audio_enabled

: bool | livekit.agents.types.NotGiven

If not given, default to True.

var

audio_num_channels

: int

var

audio_publish_options

: room_pb2.TrackPublishOptions

var

audio_sample_rate

: int

var

audio_track_name

: str | livekit.agents.types.NotGiven

The name of the audio track to publish. If not provided, default to "roomio_audio".

var

sync_transcription

: bool | livekit.agents.types.NotGiven

False to disable transcription synchronization with audio output.

Otherwise, transcription is emitted as quickly as available.

var

transcription_enabled

: bool | livekit.agents.types.NotGiven

If not given, default to True.

var

transcription_speed_factor

: float

Speed factor of transcription synchronization with audio output.

Only effective if

sync_transcription

is True.

class

RunAssert

(

run_result:

RunResult

)

Expand source code

class RunAssert:

def __init__(self, run_result: RunResult):

self._events_list = run_result.events

self._current_index = 0

@overload

def __getitem__(self, index: int) -> EventAssert: ...

@overload

def __getitem__(self, s: slice) -> EventRangeAssert: ...

def __getitem__(self, key: [int, slice]) -> EventAssert | EventRangeAssert:  # type: ignore

"""

Access a specific event or range for assertions.

Args:

key (int | slice): Index or slice of events.

Returns:

EventAssert: Assertion for a single event when key is int.

EventRangeAssert: Assertion for a span of events when key is slice.

Raises:

TypeError: If key is not an int or slice.

AssertionError: If index is out of range.

Examples:

# Single event access

>>> result.expect[0].is_message(role="user")

>>> result.expect[-1].is_message(role="assistant")

# Full range access

>>> result.expect[:].contains_function_call(name="foo")

# Partial range access

>>> result.expect[0:2].contains_message(role="assistant")

"""

if isinstance(key, slice):

events = self._events_list[key]

return EventRangeAssert(events, self, key)

if isinstance(key, int):

if key < 0:

key += len(self._events_list)

if not (0 <= key < len(self._events_list)):

self._raise_with_debug_info(

f"nth({key}) out of range (total events: {len(self._events_list)})",

index=key,

)

return EventAssert(self._events_list[key], self, key)

raise TypeError(

f"{type(self).__name__} indices must be int or slice, not {type(key).__name__}"

)

def _current_event(self) -> EventAssert:

__tracebackhide__ = True

if self._current_index >= len(self._events_list):

self._raise_with_debug_info("Expected another event, but none left.")

event = self[self._current_index]

return event

def _raise_with_debug_info(self, message: str, index: int | None = None) -> None:

__tracebackhide__ = True

marker_index = self._current_index if index is None else index

events_str = "\n".join(_format_events(self._events_list, selected_index=marker_index))

raise AssertionError(f"{message}\nContext around failure:\n" + events_str)

@overload

def next_event(self, *, type: None = None) -> EventAssert: ...

@overload

def next_event(self, *, type: Literal["message"]) -> ChatMessageAssert: ...

@overload

def next_event(self, *, type: Literal["function_call"]) -> FunctionCallAssert: ...

@overload

def next_event(self, *, type: Literal["function_call_output"]) -> FunctionCallOutputAssert: ...

@overload

def next_event(self, *, type: Literal["agent_handoff"]) -> AgentHandoffAssert: ...

def next_event(

self,

*,

type: Literal["message", "function_call", "function_call_output", "agent_handoff"]

| None = None,

) -> (

EventAssert

| ChatMessageAssert

| FunctionCallAssert

| FunctionCallOutputAssert

| AgentHandoffAssert

):

"""

Advance to the next event, optionally filtering by type.

Args:

type (str, optional): Event type to match.

Returns:

EventAssert or subclass: Assertion object for the matched event.

Example:

>>> result.expect.next_event(type="function_call").is_function_call(name="foo")

"""

__tracebackhide__ = True

while True:

ev_assert = self._current_event()

self._current_index += 1

if type is None or ev_assert.event().type == type:

break

if type == "message":

return ev_assert.is_message()

elif type == "function_call":

return ev_assert.is_function_call()

elif type == "function_call_output":

return ev_assert.is_function_call_output()

elif type == "agent_handoff":

return ev_assert.is_agent_handoff()

return ev_assert

@overload

def skip_next_event_if(

self, *, type: Literal["message"], role: NotGivenOr[llm.ChatRole] = NOT_GIVEN

) -> ChatMessageAssert | None: ...

@overload

def skip_next_event_if(

self,

*,

type: Literal["function_call"],

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

) -> FunctionCallAssert | None: ...

@overload

def skip_next_event_if(

self,

*,

type: Literal["function_call_output"],

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

) -> FunctionCallOutputAssert | None: ...

@overload

def skip_next_event_if(

self, *, type: Literal["agent_handoff"], new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN

) -> AgentHandoffAssert | None: ...

def skip_next_event_if(

self,

*,

type: Literal["message", "function_call", "function_call_output", "agent_handoff"],

role: NotGivenOr[llm.ChatRole] = NOT_GIVEN,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN,

) -> (

ChatMessageAssert

| AgentHandoffAssert

| FunctionCallAssert

| FunctionCallOutputAssert

| None

):

"""

Conditionally skip the next event if it matches criteria.

Args:

type (str): Type of event to check.

role (ChatRole, optional): Required role for message events.

name (str, optional): Required function name for calls.

arguments (dict, optional): Required args for function calls.

output (str, optional): Required output for function call outputs.

is_error (bool, optional): Required error flag for call outputs.

new_agent_type (type, optional): Required agent class for handoffs.

Returns:

EventAssert or None: The skipped event assertion if matched.

Example:

>>> skipped = result.expect.skip_next_event_if(type="message", role="assistant")

"""

__tracebackhide__ = True

try:

ev: (

ChatMessageAssert

| FunctionCallAssert

| FunctionCallOutputAssert

| AgentHandoffAssert

| None

) = None

if type == "message":

ev = self._current_event().is_message(role=role)

elif type == "function_call":

ev = self._current_event().is_function_call(name=name, arguments=arguments)

elif type == "function_call_output":

ev = self._current_event().is_function_call_output(output=output, is_error=is_error)

elif type == "agent_handoff":

ev = self._current_event().is_agent_handoff(new_agent_type=new_agent_type)

self._current_index += 1

return ev

except AssertionError:

return None

raise RuntimeError("unknown event type")

def skip_next(self, count: int = 1) -> RunAssert:

"""

Skip a specified number of upcoming events without assertions.

Args:

count (int): Number of events to skip.

Returns:

RunAssert: Self for chaining.

Example:

>>> result.expect.skip_next(2)

"""

__tracebackhide__ = True

for i in range(count):

if self._current_index >= len(self._events_list):

self._raise_with_debug_info(

f"Tried to skip {count} event(s), but only {i} were available."

)

self._current_index += 1

return self

def no_more_events(self) -> None:

"""

Assert that there are no further events.

Raises:

AssertionError: If unexpected events remain.

Example:

>>> result.expect.no_more_events()

"""

__tracebackhide__ = True

if self._current_index < len(self._events_list):

event = self._events_list[self._current_index]

self._raise_with_debug_info(

f"Expected no more events, but found: {type(event).__name__}"

)

def contains_function_call(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

) -> FunctionCallAssert:

"""

Assert existence of a function call event matching criteria.

Args:

name (str, optional): Function name to match.

arguments (dict, optional): Arguments to match.

Returns:

FunctionCallAssert: Assertion for the matching call.

Example:

>>> result.expect.contains_function_call(name="foo")

"""

__tracebackhide__ = True

return self[:].contains_function_call(name=name, arguments=arguments)

def contains_message(

self,

*,

role: NotGivenOr[llm.ChatRole] = NOT_GIVEN,

) -> ChatMessageAssert:

"""

Assert existence of a message event matching criteria.

Args:

role (ChatRole, optional): Role to match.

Returns:

ChatMessageAssert: Assertion for the matching message.

Example:

>>> result.expect.contains_message(role="user")

"""

__tracebackhide__ = True

return self[:].contains_message(role=role)

def contains_function_call_output(

self,

*,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

) -> FunctionCallOutputAssert:

"""

Assert existence of a function call output event matching criteria.

Args:

output (str, optional): Output string to match.

is_error (bool, optional): Error flag to match.

Returns:

FunctionCallOutputAssert: Assertion for the matching output.

Example:

>>> result.expect.contains_function_call_output(is_error=True)

"""

__tracebackhide__ = True

return self[:].contains_function_call_output(output=output, is_error=is_error)

def contains_agent_handoff(

self, *, new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN

) -> AgentHandoffAssert:

"""

Assert existence of an agent handoff event matching criteria.

Args:

new_agent_type (type, optional): Expected new agent class.

Returns:

AgentHandoffAssert: Assertion for the matching handoff.

Example:

>>> result.expect.contains_agent_handoff(new_agent_type=MyAgent)

"""

__tracebackhide__ = True

return self[:].contains_agent_handoff(new_agent_type=new_agent_type)

Methods

def

contains_agent_handoff

(

self,

*,

new_agent_type: NotGivenOr[type[

Agent

]] = NOT_GIVEN) ‑> AgentHandoffAssert

Expand source code

def contains_agent_handoff(

self, *, new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN

) -> AgentHandoffAssert:

"""

Assert existence of an agent handoff event matching criteria.

Args:

new_agent_type (type, optional): Expected new agent class.

Returns:

AgentHandoffAssert: Assertion for the matching handoff.

Example:

>>> result.expect.contains_agent_handoff(new_agent_type=MyAgent)

"""

__tracebackhide__ = True

return self[:].contains_agent_handoff(new_agent_type=new_agent_type)

Assert existence of an agent handoff event matching criteria.

Args

new_agent_type

:

type

, optional

Expected new agent class.

Returns

AgentHandoffAssert

Assertion for the matching handoff.

Example

>>> result.expect.contains_agent_handoff(new_agent_type=MyAgent)

def

contains_function_call

(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN) ‑>

FunctionCallAssert

Expand source code

def contains_function_call(

self,

*,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

) -> FunctionCallAssert:

"""

Assert existence of a function call event matching criteria.

Args:

name (str, optional): Function name to match.

arguments (dict, optional): Arguments to match.

Returns:

FunctionCallAssert: Assertion for the matching call.

Example:

>>> result.expect.contains_function_call(name="foo")

"""

__tracebackhide__ = True

return self[:].contains_function_call(name=name, arguments=arguments)

Assert existence of a function call event matching criteria.

Args

name

:

str

, optional

Function name to match.

arguments

:

dict

, optional

Arguments to match.

Returns

FunctionCallAssert

Assertion for the matching call.

Example

>>> result.expect.contains_function_call(name="foo")

def

contains_function_call_output

(

self,

*,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN) ‑>

FunctionCallOutputAssert

Expand source code

def contains_function_call_output(

self,

*,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

) -> FunctionCallOutputAssert:

"""

Assert existence of a function call output event matching criteria.

Args:

output (str, optional): Output string to match.

is_error (bool, optional): Error flag to match.

Returns:

FunctionCallOutputAssert: Assertion for the matching output.

Example:

>>> result.expect.contains_function_call_output(is_error=True)

"""

__tracebackhide__ = True

return self[:].contains_function_call_output(output=output, is_error=is_error)

Assert existence of a function call output event matching criteria.

Args

output

:

str

, optional

Output string to match.

is_error

:

bool

, optional

Error flag to match.

Returns

FunctionCallOutputAssert

Assertion for the matching output.

Example

>>> result.expect.contains_function_call_output(is_error=True)

def

contains_message

(

self, *, role: NotGivenOr[llm.ChatRole] = NOT_GIVEN) ‑>

ChatMessageAssert

Expand source code

def contains_message(

self,

*,

role: NotGivenOr[llm.ChatRole] = NOT_GIVEN,

) -> ChatMessageAssert:

"""

Assert existence of a message event matching criteria.

Args:

role (ChatRole, optional): Role to match.

Returns:

ChatMessageAssert: Assertion for the matching message.

Example:

>>> result.expect.contains_message(role="user")

"""

__tracebackhide__ = True

return self[:].contains_message(role=role)

Assert existence of a message event matching criteria.

Args

role

:

ChatRole

, optional

Role to match.

Returns

ChatMessageAssert

Assertion for the matching message.

Example

>>> result.expect.contains_message(role="user")

def

next_event

(

self,

*,

type: "Literal['message', 'function_call', 'function_call_output', 'agent_handoff'] | None" = None) ‑>

EventAssert

|

ChatMessageAssert

|

FunctionCallAssert

|

FunctionCallOutputAssert

|

AgentHandoffAssert

Expand source code

def next_event(

self,

*,

type: Literal["message", "function_call", "function_call_output", "agent_handoff"]

| None = None,

) -> (

EventAssert

| ChatMessageAssert

| FunctionCallAssert

| FunctionCallOutputAssert

| AgentHandoffAssert

):

"""

Advance to the next event, optionally filtering by type.

Args:

type (str, optional): Event type to match.

Returns:

EventAssert or subclass: Assertion object for the matched event.

Example:

>>> result.expect.next_event(type="function_call").is_function_call(name="foo")

"""

__tracebackhide__ = True

while True:

ev_assert = self._current_event()

self._current_index += 1

if type is None or ev_assert.event().type == type:

break

if type == "message":

return ev_assert.is_message()

elif type == "function_call":

return ev_assert.is_function_call()

elif type == "function_call_output":

return ev_assert.is_function_call_output()

elif type == "agent_handoff":

return ev_assert.is_agent_handoff()

return ev_assert

Advance to the next event, optionally filtering by type.

Args

type

:

str

, optional

Event type to match.

Returns

EventAssert

or

subclass

Assertion object for the matched event.

Example

>>> result.expect.next_event(type="function_call").is_function_call(name="foo")

def

no_more_events

(

self) ‑> None

Expand source code

def no_more_events(self) -> None:

"""

Assert that there are no further events.

Raises:

AssertionError: If unexpected events remain.

Example:

>>> result.expect.no_more_events()

"""

__tracebackhide__ = True

if self._current_index < len(self._events_list):

event = self._events_list[self._current_index]

self._raise_with_debug_info(

f"Expected no more events, but found: {type(event).__name__}"

)

Assert that there are no further events.

Raises

AssertionError

If unexpected events remain.

Example

>>> result.expect.no_more_events()

def

skip_next

(

self, count: int = 1) ‑>

RunAssert

Expand source code

def skip_next(self, count: int = 1) -> RunAssert:

"""

Skip a specified number of upcoming events without assertions.

Args:

count (int): Number of events to skip.

Returns:

RunAssert: Self for chaining.

Example:

>>> result.expect.skip_next(2)

"""

__tracebackhide__ = True

for i in range(count):

if self._current_index >= len(self._events_list):

self._raise_with_debug_info(

f"Tried to skip {count} event(s), but only {i} were available."

)

self._current_index += 1

return self

Skip a specified number of upcoming events without assertions.

Args

count

:

int

Number of events to skip.

Returns

RunAssert

Self for chaining.

Example

>>> result.expect.skip_next(2)

def

skip_next_event_if

(

self,

*,

type: "Literal['message', 'function_call', 'function_call_output', 'agent_handoff']",

role: NotGivenOr[llm.ChatRole] = NOT_GIVEN,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

new_agent_type: NotGivenOr[type[

Agent

]] = NOT_GIVEN) ‑> ChatMessageAssert | AgentHandoffAssert | FunctionCallAssert | FunctionCallOutputAssert | None

Expand source code

def skip_next_event_if(

self,

*,

type: Literal["message", "function_call", "function_call_output", "agent_handoff"],

role: NotGivenOr[llm.ChatRole] = NOT_GIVEN,

name: NotGivenOr[str] = NOT_GIVEN,

arguments: NotGivenOr[dict[str, Any]] = NOT_GIVEN,

output: NotGivenOr[str] = NOT_GIVEN,

is_error: NotGivenOr[bool] = NOT_GIVEN,

new_agent_type: NotGivenOr[type[Agent]] = NOT_GIVEN,

) -> (

ChatMessageAssert

| AgentHandoffAssert

| FunctionCallAssert

| FunctionCallOutputAssert

| None

):

"""

Conditionally skip the next event if it matches criteria.

Args:

type (str): Type of event to check.

role (ChatRole, optional): Required role for message events.

name (str, optional): Required function name for calls.

arguments (dict, optional): Required args for function calls.

output (str, optional): Required output for function call outputs.

is_error (bool, optional): Required error flag for call outputs.

new_agent_type (type, optional): Required agent class for handoffs.

Returns:

EventAssert or None: The skipped event assertion if matched.

Example:

>>> skipped = result.expect.skip_next_event_if(type="message", role="assistant")

"""

__tracebackhide__ = True

try:

ev: (

ChatMessageAssert

| FunctionCallAssert

| FunctionCallOutputAssert

| AgentHandoffAssert

| None

) = None

if type == "message":

ev = self._current_event().is_message(role=role)

elif type == "function_call":

ev = self._current_event().is_function_call(name=name, arguments=arguments)

elif type == "function_call_output":

ev = self._current_event().is_function_call_output(output=output, is_error=is_error)

elif type == "agent_handoff":

ev = self._current_event().is_agent_handoff(new_agent_type=new_agent_type)

self._current_index += 1

return ev

except AssertionError:

return None

raise RuntimeError("unknown event type")

Conditionally skip the next event if it matches criteria.

Args

type

:

str

Type of event to check.

role

:

ChatRole

, optional

Required role for message events.

name

:

str

, optional

Required function name for calls.

arguments

:

dict

, optional

Required args for function calls.

output

:

str

, optional

Required output for function call outputs.

is_error

:

bool

, optional

Required error flag for call outputs.

new_agent_type

:

type

, optional

Required agent class for handoffs.

Returns

EventAssert

or

None

The skipped event assertion if matched.

Example

>>> skipped = result.expect.skip_next_event_if(type="message", role="assistant")

class

RunContext

(

*,

session:

AgentSession

[Userdata_T],

speech_handle: SpeechHandle,

function_call:

FunctionCall

)

Expand source code

class RunContext(Generic[Userdata_T]):

# private ctor

def __init__(

self,

*,

session: AgentSession[Userdata_T],

speech_handle: SpeechHandle,

function_call: FunctionCall,

) -> None:

self._session = session

self._speech_handle = speech_handle

self._function_call = function_call

self._initial_step_idx = speech_handle.num_steps - 1

@property

def session(self) -> AgentSession[Userdata_T]:

return self._session

@property

def speech_handle(self) -> SpeechHandle:

return self._speech_handle

@property

def function_call(self) -> FunctionCall:

return self._function_call

@property

def userdata(self) -> Userdata_T:

return self.session.userdata

def disallow_interruptions(self) -> None:

"""Disable interruptions for this FunctionCall.

Delegates to the SpeechHandle.allow_interruptions setter,

which will raise a RuntimeError if the handle is already interrupted.

Raises:

RuntimeError: If the SpeechHandle is already interrupted.

"""

self.speech_handle.allow_interruptions = False

async def wait_for_playout(self) -> None:

"""Waits for the speech playout corresponding to this function call step.

Unlike `SpeechHandle.wait_for_playout`, which waits for the full

assistant turn to complete (including all function tools),

this method only waits for the assistant's spoken response prior running

this tool to finish playing."""

await self.speech_handle._wait_for_generation(step_idx=self._initial_step_idx)

Abstract base class for generic types.

On Python 3.12 and newer, generic classes implicitly inherit from

Generic when they declare a parameter list after the class's name::

class Mapping[KT, VT]:

def __getitem__(self, key: KT) -> VT:

...

# Etc.

On older versions of Python, however, generic classes have to

explicitly inherit from Generic.

After a class has been declared to be generic, it can then be used as

follows::

def lookup_name[KT, VT](mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:

try:

return mapping[key]

except KeyError:

return default

Ancestors

typing.Generic

Instance variables

prop

function_call

:

FunctionCall

Expand source code

@property

def function_call(self) -> FunctionCall:

return self._function_call

prop

session

:

AgentSession

[Userdata_T]

Expand source code

@property

def session(self) -> AgentSession[Userdata_T]:

return self._session

prop

speech_handle

: SpeechHandle

Expand source code

@property

def speech_handle(self) -> SpeechHandle:

return self._speech_handle

prop

userdata

: Userdata_T

Expand source code

@property

def userdata(self) -> Userdata_T:

return self.session.userdata

Methods

def

disallow_interruptions

(

self) ‑> None

Expand source code

def disallow_interruptions(self) -> None:

"""Disable interruptions for this FunctionCall.

Delegates to the SpeechHandle.allow_interruptions setter,

which will raise a RuntimeError if the handle is already interrupted.

Raises:

RuntimeError: If the SpeechHandle is already interrupted.

"""

self.speech_handle.allow_interruptions = False

Disable interruptions for this FunctionCall.

Delegates to the SpeechHandle.allow_interruptions setter,

which will raise a RuntimeError if the handle is already interrupted.

Raises

RuntimeError

If the SpeechHandle is already interrupted.

async def

wait_for_playout

(

self) ‑> None

Expand source code

async def wait_for_playout(self) -> None:

"""Waits for the speech playout corresponding to this function call step.

Unlike `SpeechHandle.wait_for_playout`, which waits for the full

assistant turn to complete (including all function tools),

this method only waits for the assistant's spoken response prior running

this tool to finish playing."""

await self.speech_handle._wait_for_generation(step_idx=self._initial_step_idx)

Waits for the speech playout corresponding to this function call step.

Unlike

SpeechHandle.wait_for_playout

, which waits for the full

assistant turn to complete (including all function tools),

this method only waits for the assistant's spoken response prior running

this tool to finish playing.

class

RunResult

(

*, user_input: str | None = None, output_type: type[Run_T] | None)

Expand source code

class RunResult(Generic[Run_T]):

def __init__(self, *, user_input: str | None = None, output_type: type[Run_T] | None) -> None:

self._handles: set[SpeechHandle | asyncio.Task] = set()

self._done_fut = asyncio.Future[None]()

self._user_input = user_input

self._output_type = output_type

self._recorded_items: list[RunEvent] = []

self._final_output: Run_T | None = None

self.__last_speech_handle: SpeechHandle | None = None

@property

def events(self) -> list[RunEvent]:

"""List of all recorded events generated during the run."""

return self._recorded_items

@functools.cached_property

def expect(self) -> RunAssert:

"""

Provides an assertion helper for verifying the run events.

Returns:

RunAssert: Assertion interface for run events.

"""

# TODO(theomonnom): probably not the best place to log

if lk_evals_verbose:

events_str = "\n    ".join(_format_events(self.events))

print(

"\n+ RunResult(\n"

f"   user_input=`{self._user_input}`\n"

f"   events:\n    {events_str}\n"

")"

)

return RunAssert(self)

@property

def final_output(self) -> Run_T:

"""

Returns the final output of the run after completion.

Raises:

RuntimeError: If the run is not complete or no output is set.

Returns:

Run_T: The final result output.

"""

if not self._done_fut.done():

raise RuntimeError("cannot retrieve final_output, RunResult is not done")

if not self._final_output:

raise RuntimeError("no final output")

return self._final_output

def done(self) -> bool:

"""Indicates whether the run has finished processing all events."""

return self._done_fut.done()

def __await__(self) -> Generator[None, None, RunResult[Run_T]]:

async def _await_impl() -> RunResult[Run_T]:

await asyncio.shield(self._done_fut)

return self

return _await_impl().__await__()

def _agent_handoff(self, *, old_agent: Agent | None, new_agent: Agent) -> None:

self._recorded_items.append(AgentHandoffEvent(old_agent=old_agent, new_agent=new_agent))

def _item_added(self, item: llm.ChatItem) -> None:

if self._done_fut.done():

return

if item.type == "message":

self._recorded_items.append(ChatMessageEvent(item=item))

elif item.type == "function_call":

self._recorded_items.append(FunctionCallEvent(item=item))

elif item.type == "function_call_output":

self._recorded_items.append(FunctionCallOutputEvent(item=item))

def _watch_handle(self, handle: SpeechHandle | asyncio.Task) -> None:

self._handles.add(handle)

if isinstance(handle, SpeechHandle):

handle._add_item_added_callback(self._item_added)

handle.add_done_callback(self._mark_done_if_needed)

def _unwatch_handle(self, handle: SpeechHandle | asyncio.Task) -> None:

self._handles.discard(handle)

handle.remove_done_callback(self._mark_done_if_needed)

if isinstance(handle, SpeechHandle):

handle._remove_item_added_callback(self._item_added)

def _mark_done_if_needed(self, handle: SpeechHandle | asyncio.Task | None) -> None:

if isinstance(handle, SpeechHandle):

self.__last_speech_handle = handle

if all(handle.done() for handle in self._handles):

self._mark_done()

def _mark_done(self) -> None:

with contextlib.suppress(asyncio.InvalidStateError):

if self.__last_speech_handle is None:

self._done_fut.set_result(None)

return

final_output = self.__last_speech_handle._maybe_run_final_output

if not isinstance(final_output, BaseException):

if self._output_type and not isinstance(final_output, self._output_type):

self._done_fut.set_exception(

RuntimeError(

f"Expected output of type {self._output_type.__name__}, "

f"got {type(self._final_output).__name__}"

)

)

else:

self._final_output = final_output

self._done_fut.set_result(None)

else:

self._done_fut.set_exception(final_output)

Abstract base class for generic types.

On Python 3.12 and newer, generic classes implicitly inherit from

Generic when they declare a parameter list after the class's name::

class Mapping[KT, VT]:

def __getitem__(self, key: KT) -> VT:

...

# Etc.

On older versions of Python, however, generic classes have to

explicitly inherit from Generic.

After a class has been declared to be generic, it can then be used as

follows::

def lookup_name[KT, VT](mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:

try:

return mapping[key]

except KeyError:

return default

Ancestors

typing.Generic

Instance variables

prop

events

: list[RunEvent]

Expand source code

@property

def events(self) -> list[RunEvent]:

"""List of all recorded events generated during the run."""

return self._recorded_items

List of all recorded events generated during the run.

var

expect

:

RunAssert

Expand source code

@functools.cached_property

def expect(self) -> RunAssert:

"""

Provides an assertion helper for verifying the run events.

Returns:

RunAssert: Assertion interface for run events.

"""

# TODO(theomonnom): probably not the best place to log

if lk_evals_verbose:

events_str = "\n    ".join(_format_events(self.events))

print(

"\n+ RunResult(\n"

f"   user_input=`{self._user_input}`\n"

f"   events:\n    {events_str}\n"

")"

)

return RunAssert(self)

Provides an assertion helper for verifying the run events.

Returns

RunAssert

Assertion interface for run events.

prop

final_output

: Run_T

Expand source code

@property

def final_output(self) -> Run_T:

"""

Returns the final output of the run after completion.

Raises:

RuntimeError: If the run is not complete or no output is set.

Returns:

Run_T: The final result output.

"""

if not self._done_fut.done():

raise RuntimeError("cannot retrieve final_output, RunResult is not done")

if not self._final_output:

raise RuntimeError("no final output")

return self._final_output

Returns the final output of the run after completion.

Raises

RuntimeError

If the run is not complete or no output is set.

Returns

Run_T

The final result output.

Methods

def

done

(

self) ‑> bool

Expand source code

def done(self) -> bool:

"""Indicates whether the run has finished processing all events."""

return self._done_fut.done()

Indicates whether the run has finished processing all events.

class

SimulateJobInfo

(

room: str, participant_identity: str | None = None)

Expand source code

@dataclass

class SimulateJobInfo:

room: str

participant_identity: str | None = None

SimulateJobInfo(room: 'str', participant_identity: 'str | None' = None)

Instance variables

var

participant_identity

: str | None

var

room

: str

class

SpeechCreatedEvent

(

**data: Any)

Expand source code

class SpeechCreatedEvent(BaseModel):

model_config = ConfigDict(arbitrary_types_allowed=True)

type: Literal["speech_created"] = "speech_created"

user_initiated: bool

"""True if the speech was created using public methods like `say` or `generate_reply`"""

source: Literal["say", "generate_reply", "tool_response"]

"""Source indicating how the speech handle was created"""

speech_handle: SpeechHandle = Field(..., exclude=True)

"""The speech handle that was created"""

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

model_config

var

source

: Literal['say', 'generate_reply', 'tool_response']

Source indicating how the speech handle was created

var

speech_handle

: livekit.agents.voice.speech_handle.SpeechHandle

The speech handle that was created

var

type

: Literal['speech_created']

var

user_initiated

: bool

True if the speech was created using public methods like

say

or

generate_reply

class

StopResponse

Expand source code

class StopResponse(Exception):

def __init__(self) -> None:

"""

Exception raised within AI functions.

This exception can be raised by the user to indicate that

the agent should not generate a response for the current

function call.

"""

super().__init__()

Common base class for all non-exit exceptions.

Exception raised within AI functions.

This exception can be raised by the user to indicate that

the agent should not generate a response for the current

function call.

Ancestors

builtins.Exception

builtins.BaseException

class

ToolError

(

message: str)

Expand source code

class ToolError(Exception):

def __init__(self, message: str) -> None:

"""

Exception raised within AI functions.

This exception should be raised by users when an error occurs

in the context of AI operations. The provided message will be

visible to the LLM, allowing it to understand the context of

the error during FunctionOutput generation.

"""

super().__init__(message)

self._message = message

@property

def message(self) -> str:

return self._message

Common base class for all non-exit exceptions.

Exception raised within AI functions.

This exception should be raised by users when an error occurs

in the context of AI operations. The provided message will be

visible to the LLM, allowing it to understand the context of

the error during FunctionOutput generation.

Ancestors

builtins.Exception

builtins.BaseException

Instance variables

prop

message

: str

Expand source code

@property

def message(self) -> str:

return self._message

class

UserInputTranscribedEvent

(

**data: Any)

Expand source code

class UserInputTranscribedEvent(BaseModel):

type: Literal["user_input_transcribed"] = "user_input_transcribed"

transcript: str

is_final: bool

speaker_id: str | None = None

language: str | None = None

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

is_final

: bool

var

language

: str | None

var

model_config

var

speaker_id

: str | None

var

transcript

: str

var

type

: Literal['user_input_transcribed']

class

UserStateChangedEvent

(

**data: Any)

Expand source code

class UserStateChangedEvent(BaseModel):

type: Literal["user_state_changed"] = "user_state_changed"

old_state: UserState

new_state: UserState

created_at: float = Field(default_factory=time.time)

Usage docs:

https://docs.pydantic.dev/2.10/concepts/models/

A base class for creating Pydantic models.

Attributes

__class_vars__

The names of the class variables defined on the model.

__private_attributes__

Metadata about the private attributes of the model.

__signature__

The synthesized

__init__

[

Signature

][inspect.Signature] of the model.

__pydantic_complete__

Whether model building is completed, or if there are still undefined fields.

__pydantic_core_schema__

The core schema of the model.

__pydantic_custom_init__

Whether the model has a custom

__init__

function.

__pydantic_decorators__

Metadata containing the decorators defined on the model.

This replaces

Model.__validators__

and

Model.__root_validators__

from Pydantic V1.

__pydantic_generic_metadata__

Metadata for generic models; contains data used for a similar purpose to

args

,

origin

,

parameters

in typing-module generics. May eventually be replaced by these.

__pydantic_parent_namespace__

Parent namespace of the model, used for automatic rebuilding of models.

__pydantic_post_init__

The name of the post-init method for the model, if defined.

__pydantic_root_model__

Whether the model is a [

RootModel

][pydantic.root_model.RootModel].

__pydantic_serializer__

The

pydantic-core

SchemaSerializer

used to dump instances of the model.

__pydantic_validator__

The

pydantic-core

SchemaValidator

used to validate instances of the model.

__pydantic_fields__

A dictionary of field names and their corresponding [

FieldInfo

][pydantic.fields.FieldInfo] objects.

__pydantic_computed_fields__

A dictionary of computed field names and their corresponding [

ComputedFieldInfo

][pydantic.fields.ComputedFieldInfo] objects.

__pydantic_extra__

A dictionary containing extra values, if [

extra

][pydantic.config.ConfigDict.extra]

is set to

'allow'

.

__pydantic_fields_set__

The names of fields explicitly set during instantiation.

__pydantic_private__

Values of private attributes set on the model instance.

Create a new model by parsing and validating input data from keyword arguments.

Raises [

ValidationError

][pydantic_core.ValidationError] if the input data cannot be

validated to form a valid model.

self

is explicitly positional-only to allow

self

as a field name.

Ancestors

pydantic.main.BaseModel

Class variables

var

created_at

: float

var

model_config

var

new_state

: Literal['speaking', 'listening', 'away']

var

old_state

: Literal['speaking', 'listening', 'away']

var

type

: Literal['user_state_changed']

class

Worker

(

opts:

WorkerOptions

,

*,

devmode: bool = True,

register: bool = True,

loop: asyncio.AbstractEventLoop | None = None)

Expand source code

class Worker(utils.EventEmitter[EventTypes]):

def __init__(

self,

opts: WorkerOptions,

*,

devmode: bool = True,

register: bool = True,

loop: asyncio.AbstractEventLoop | None = None,

) -> None:

super().__init__()

opts.ws_url = opts.ws_url or os.environ.get("LIVEKIT_URL", "")

opts.api_key = opts.api_key or os.environ.get("LIVEKIT_API_KEY", "")

opts.api_secret = opts.api_secret or os.environ.get("LIVEKIT_API_SECRET", "")

opts._worker_token = os.environ.get("LIVEKIT_WORKER_TOKEN", None)

if not opts.ws_url:

raise ValueError("ws_url is required, or add LIVEKIT_URL in your environment")

if not opts.api_key:

raise ValueError("api_key is required, or add LIVEKIT_API_KEY in your environment")

if not opts.api_secret:

raise ValueError(

"api_secret is required, or add LIVEKIT_API_SECRET in your environment"

)

# Ensure job processes and thread executors can initialize JobContext.api

# by inheriting credentials from environment variables. This guarantees that

# ctx.api works even when credentials are only supplied via WorkerOptions.

os.environ["LIVEKIT_URL"] = opts.ws_url

os.environ["LIVEKIT_API_KEY"] = opts.api_key

os.environ["LIVEKIT_API_SECRET"] = opts.api_secret

if opts.job_memory_limit_mb > 0 and opts.job_executor_type != JobExecutorType.PROCESS:

logger.warning(

"max_job_memory_usage is only supported for process-based job executors, "

"ignoring max_job_memory_usage"

)

if not is_given(opts.http_proxy):

opts.http_proxy = os.environ.get("HTTPS_PROXY") or os.environ.get("HTTP_PROXY")

if opts._worker_token:

if opts.load_fnc != _DefaultLoadCalc.get_load:

logger.warning(

"custom load_fnc is not supported when hosting on Cloud, reverting to default"

)

opts.load_fnc = _DefaultLoadCalc.get_load

if opts.load_threshold != _default_load_threshold:

logger.warning(

"custom load_threshold is not supported when hosting on Cloud, reverting to default"

)

opts.load_threshold = _default_load_threshold

self._opts = opts

self._loop = loop or asyncio.get_event_loop()

self._id = "unregistered"

self._closed, self._draining, self._connecting = True, False, False

self._tasks = set[asyncio.Task[Any]]()

self._pending_assignments: dict[str, asyncio.Future[agent.JobAssignment]] = {}

self._close_future: asyncio.Future[None] | None = None

self._msg_chan = utils.aio.Chan[agent.WorkerMessage](128, loop=self._loop)

self._devmode = devmode

self._register = register

self._mp_ctx = mp.get_context(self._opts.multiprocessing_context)

self._inference_executor: ipc.inference_proc_executor.InferenceProcExecutor | None = None

if len(_InferenceRunner.registered_runners) > 0:

self._inference_executor = ipc.inference_proc_executor.InferenceProcExecutor(

runners=_InferenceRunner.registered_runners,

initialize_timeout=opts.initialize_process_timeout,

close_timeout=5,

memory_warn_mb=2000,

memory_limit_mb=0,  # no limit

ping_interval=5,

ping_timeout=60,

high_ping_threshold=2.5,

mp_ctx=self._mp_ctx,

loop=self._loop,

http_proxy=opts.http_proxy or None,

)

self._proc_pool = ipc.proc_pool.ProcPool(

initialize_process_fnc=opts.prewarm_fnc,

job_entrypoint_fnc=opts.entrypoint_fnc,

num_idle_processes=_WorkerEnvOption.getvalue(opts.num_idle_processes, self._devmode),

loop=self._loop,

job_executor_type=opts.job_executor_type,

inference_executor=self._inference_executor,

mp_ctx=self._mp_ctx,

initialize_timeout=opts.initialize_process_timeout,

close_timeout=opts.shutdown_process_timeout,

memory_warn_mb=opts.job_memory_warn_mb,

memory_limit_mb=opts.job_memory_limit_mb,

http_proxy=opts.http_proxy or None,

)

self._previous_status = agent.WorkerStatus.WS_AVAILABLE

self._api: api.LiveKitAPI | None = None

self._http_session: aiohttp.ClientSession | None = None

self._http_server = http_server.HttpServer(

opts.host,

_WorkerEnvOption.getvalue(opts.port, self._devmode),

loop=self._loop,

)

async def health_check(_: Any) -> web.Response:

if self._inference_executor and not self._inference_executor.is_alive():

return web.Response(status=503, text="inference process not running")

return web.Response(text="OK")

async def worker(_: Any) -> web.Response:

body = json.dumps(

{

"agent_name": self._opts.agent_name,

"worker_type": agent.JobType.Name(self._opts.worker_type.value),

"active_jobs": len(self.active_jobs),

"sdk_version": __version__,

"project_type": "python",

}

)

return web.Response(body=body, content_type="application/json")

self._http_server.app.add_routes([web.get("/", health_check)])

self._http_server.app.add_routes([web.get("/worker", worker)])

self._prometheus_server: telemetry.http_server.HttpServer | None = None

self._prometheus_multiproc_dir: str | None = None

# Setup prometheus multiprocess mode if explicitly configured

if opts.prometheus_multiproc_dir:

self._prometheus_multiproc_dir = opts.prometheus_multiproc_dir

# Set environment variable for prometheus multiprocess mode

os.environ["PROMETHEUS_MULTIPROC_DIR"] = self._prometheus_multiproc_dir

elif "PROMETHEUS_MULTIPROC_DIR" in os.environ:

# Use existing environment variable if already set

self._prometheus_multiproc_dir = os.environ["PROMETHEUS_MULTIPROC_DIR"]

# Create prometheus directory if it doesn't exist

if self._prometheus_multiproc_dir:

os.makedirs(self._prometheus_multiproc_dir, exist_ok=True)

if is_given(self._opts.prometheus_port):

self._prometheus_server = telemetry.http_server.HttpServer(

opts.host, self._opts.prometheus_port, loop=self._loop

)

self._conn_task: asyncio.Task[None] | None = None

self._load_task: asyncio.Task[None] | None = None

self._worker_load: float = 0.0

@property

def worker_info(self) -> WorkerInfo:

return WorkerInfo(http_port=self._http_server.port)

async def run(self) -> None:

if not self._closed:

raise Exception("worker is already running")

logger.info(

"starting worker",

extra={"version": __version__, "rtc-version": rtc.__version__},

)

# Clean prometheus multiprocess directory to avoid stale metrics (only if it exists)

if self._prometheus_multiproc_dir and os.path.exists(self._prometheus_multiproc_dir):

logger.debug(

"cleaning prometheus multiprocess directory",

extra={"dir": self._prometheus_multiproc_dir},

)

# Remove all files in the directory but keep the directory itself

for filename in os.listdir(self._prometheus_multiproc_dir):

file_path = os.path.join(self._prometheus_multiproc_dir, filename)

try:

if os.path.isfile(file_path):

os.unlink(file_path)

except Exception as e:

logger.warning(f"failed to remove {file_path}: {e}")

if self._opts.multiprocessing_context == "forkserver":

plugin_packages = [p.package for p in Plugin.registered_plugins] + ["av"]

logger.info("preloading plugins", extra={"packages": plugin_packages})

self._mp_ctx.set_forkserver_preload(plugin_packages)

if self._inference_executor is not None:

logger.info("starting inference executor")

await self._inference_executor.start()

await self._inference_executor.initialize()

self._closed = False

def _update_job_status(proc: ipc.job_executor.JobExecutor) -> None:

t = self._loop.create_task(self._update_job_status(proc))

self._tasks.add(t)

t.add_done_callback(self._tasks.discard)

await self._http_server.start()

if self._prometheus_server:

await self._prometheus_server.start()

self._proc_pool.on("process_started", _update_job_status)

self._proc_pool.on("process_closed", _update_job_status)

self._proc_pool.on("process_job_launched", _update_job_status)

await self._proc_pool.start()

self._http_session = aiohttp.ClientSession(proxy=self._opts.http_proxy or None)

self._api = api.LiveKitAPI(

self._opts.ws_url, self._opts.api_key, self._opts.api_secret, session=self._http_session

)

self._close_future = asyncio.Future(loop=self._loop)

@utils.log_exceptions(logger=logger)

async def _load_task() -> None:

"""periodically check load"""

interval = utils.aio.interval(UPDATE_LOAD_INTERVAL)

while True:

await interval.tick()

def load_fnc() -> float:

signature = inspect.signature(self._opts.load_fnc)

parameters = list(signature.parameters.values())

if len(parameters) == 0:

return self._opts.load_fnc()  # type: ignore

return self._opts.load_fnc(self)  # type: ignore

self._worker_load = await asyncio.get_event_loop().run_in_executor(None, load_fnc)

# Update child process count metric for prometheus multiprocess mode

if self._prometheus_multiproc_dir:

telemetry.metrics._update_child_proc_count()

load_threshold = _WorkerEnvOption.getvalue(self._opts.load_threshold, self._devmode)

default_num_idle_processes = _WorkerEnvOption.getvalue(

self._opts.num_idle_processes, self._devmode

)

if not math.isinf(load_threshold):

active_jobs = len(self.active_jobs)

if active_jobs > 0:

job_load = self._worker_load / len(self.active_jobs)

if job_load > 0.0:

available_load = max(load_threshold - self._worker_load, 0.0)

available_job = min(

math.ceil(available_load / job_load), default_num_idle_processes

)

self._proc_pool.set_target_idle_processes(available_job)

else:

self._proc_pool.set_target_idle_processes(default_num_idle_processes)

tasks = []

self._load_task = asyncio.create_task(_load_task(), name="load_task")

tasks.append(self._load_task)

if self._register:

self._conn_task = asyncio.create_task(self._connection_task(), name="worker_conn_task")

tasks.append(self._conn_task)

self.emit("worker_started")

try:

await asyncio.gather(*tasks)

finally:

await utils.aio.cancel_and_wait(*tasks)

if not self._close_future.done():

self._close_future.set_result(None)

@property

def id(self) -> str:

return self._id

@property

def active_jobs(self) -> list[RunningJobInfo]:

return [proc.running_job for proc in self._proc_pool.processes if proc.running_job]

async def drain(self, timeout: int | None = None) -> None:

"""When timeout isn't None, it will raise asyncio.TimeoutError if the processes didn't finish in time."""  # noqa: E501

if self._draining:

return

logger.info("draining worker", extra={"id": self.id, "timeout": timeout})

self._draining = True

await self._update_worker_status()

async def _join_jobs() -> None:

for proc in list(self._proc_pool.processes):

if proc.running_job:

await proc.join()

if timeout:

await asyncio.wait_for(_join_jobs(), timeout)  # raises asyncio.TimeoutError on timeout

else:

await _join_jobs()

async def simulate_job(

self,

info: SimulateJobInfo | str,

) -> None:

"""

Simulate a job by creating a room and participant.

Args:

info: SimulateJobInfo or a join token for an existing room

"""

assert self._api is not None

# TODO(theomonnom): some fake information can still be found in the token

from livekit.protocol.models import Room

room = info.room if isinstance(info, SimulateJobInfo) else "unknown-room"

participant_identity = (

info.participant_identity

if isinstance(info, SimulateJobInfo)

else "unknown-participant"

)

agent_id = utils.shortuuid("simulated-agent-")

room_info = Room(sid=utils.shortuuid("RM_"), name=room)

participant_info = None

if isinstance(info, SimulateJobInfo):

from .cli import cli

if cli.CLI_ARGUMENTS is None or not cli.CLI_ARGUMENTS.console:

room_info = await self._api.room.create_room(api.CreateRoomRequest(name=room))

if participant_identity:

participant_info = await self._api.room.get_participant(

api.RoomParticipantIdentity(room=room, identity=participant_identity)

)

token = (

api.AccessToken(self._opts.api_key, self._opts.api_secret)

.with_identity(agent_id)

.with_kind("agent")

.with_grants(api.VideoGrants(room_join=True, room=room, agent=True))

.to_jwt()

)

else:

token = info

job = agent.Job(

id=utils.shortuuid("simulated-job-"),

room=room_info,

type=agent.JobType.JT_ROOM,

participant=participant_info,

)

running_info = RunningJobInfo(

worker_id=self._id,

accept_arguments=JobAcceptArguments(identity=agent_id, name="", metadata=""),

job=job,

url=self._opts.ws_url,

token=token,

)

await self._proc_pool.launch_job(running_info)

async def aclose(self) -> None:

if self._closed:

if self._close_future is not None:

await self._close_future

return

logger.info("shutting down worker", extra={"id": self.id})

assert self._close_future is not None

assert self._http_session is not None

assert self._api is not None

self._closed = True

if self._conn_task is not None:

await utils.aio.cancel_and_wait(self._conn_task)

if self._load_task is not None:

await utils.aio.cancel_and_wait(self._load_task)

await self._proc_pool.aclose()

if self._inference_executor is not None:

await self._inference_executor.aclose()

await self._http_session.close()

await self._http_server.aclose()

if self._prometheus_server:

await self._prometheus_server.aclose()

await self._api.aclose()  # type: ignore

await asyncio.gather(*self._tasks, return_exceptions=True)

# await asyncio.sleep(0.25)  # see https://github.com/aio-libs/aiohttp/issues/1925

self._msg_chan.close()

await self._close_future

async def _queue_msg(self, msg: agent.WorkerMessage) -> None:

"""_queue_msg raises aio.ChanClosed when the worker is closing/closed"""

if self._connecting:

which = msg.WhichOneof("message")

if which == "update_worker":

return

elif which == "ping":

return

await self._msg_chan.send(msg)

@utils.log_exceptions(logger=logger)

async def _connection_task(self) -> None:

assert self._http_session is not None

retry_count = 0

ws: aiohttp.ClientWebSocketResponse | None = None

while not self._closed:

try:

self._connecting = True

join_jwt = (

api.AccessToken(self._opts.api_key, self._opts.api_secret)

.with_grants(api.VideoGrants(agent=True))

.to_jwt()

)

headers = {"Authorization": f"Bearer {join_jwt}"}

parse = urlparse(self._opts.ws_url)

scheme = parse.scheme

if scheme.startswith("http"):

scheme = scheme.replace("http", "ws")

base = f"{scheme}://{parse.netloc}{parse.path}".rstrip("/") + "/"

agent_url = urljoin(base, "agent")

params = {}

if self._opts._worker_token:

params["worker_token"] = self._opts._worker_token

ws = await self._http_session.ws_connect(

agent_url,

headers=headers,

params=params,

autoping=True,

heartbeat=HEARTBEAT_INTERVAL,

proxy=self._opts.http_proxy or None,

)

retry_count = 0

# register the worker

req = agent.WorkerMessage()

req.register.type = self._opts.worker_type.value

req.register.allowed_permissions.CopyFrom(

models.ParticipantPermission(

can_publish=self._opts.permissions.can_publish,

can_subscribe=self._opts.permissions.can_subscribe,

can_publish_data=self._opts.permissions.can_publish_data,

can_update_metadata=self._opts.permissions.can_update_metadata,

can_publish_sources=self._opts.permissions.can_publish_sources,

hidden=self._opts.permissions.hidden,

agent=True,

)

)

req.register.agent_name = self._opts.agent_name

req.register.version = __version__

await ws.send_bytes(req.SerializeToString())

# wait for the register response before running this connection

first_msg_b = await ws.receive_bytes()

msg = agent.ServerMessage()

msg.ParseFromString(first_msg_b)

if not msg.HasField("register"):

raise Exception("expected register response as first message")

self._handle_register(msg.register)

self._connecting = False

await self._run_ws(ws)

except Exception as e:

if self._closed:

break

if retry_count >= self._opts.max_retry:

raise RuntimeError(

f"failed to connect to livekit after {retry_count} attempts",

) from None

retry_delay = min(retry_count * 2, 10)

retry_count += 1

logger.warning(

f"failed to connect to livekit, retrying in {retry_delay}s", exc_info=e

)

await asyncio.sleep(retry_delay)

finally:

if ws is not None:

await ws.close()

async def _run_ws(self, ws: aiohttp.ClientWebSocketResponse) -> None:

closing_ws = False

async def _load_task() -> None:

"""periodically update worker status"""

interval = utils.aio.interval(UPDATE_STATUS_INTERVAL)

while True:

await interval.tick()

await self._update_worker_status()

async def _send_task() -> None:

nonlocal closing_ws

while True:

try:

msg = await self._msg_chan.recv()

await ws.send_bytes(msg.SerializeToString())

except utils.aio.ChanClosed:

closing_ws = True

return

async def _recv_task() -> None:

nonlocal closing_ws

while True:

msg = await ws.receive()

if msg.type in (

aiohttp.WSMsgType.CLOSE,

aiohttp.WSMsgType.CLOSED,

aiohttp.WSMsgType.CLOSING,

):

if closing_ws:

return

raise Exception("worker connection closed unexpectedly")

if msg.type != aiohttp.WSMsgType.BINARY:

logger.warning("unexpected message type: %s", msg.type)

continue

data = msg.data

server_msg = agent.ServerMessage()

server_msg.ParseFromString(data)

which = server_msg.WhichOneof("message")

if which == "availability":

self._handle_availability(server_msg.availability)

elif which == "assignment":

self._handle_assignment(server_msg.assignment)

elif which == "termination":

user_task = self._loop.create_task(

self._handle_termination(server_msg.termination),

name="agent_job_termination",

)

self._tasks.add(user_task)

user_task.add_done_callback(self._tasks.discard)

tasks = [

asyncio.create_task(_load_task()),

asyncio.create_task(_send_task()),

asyncio.create_task(_recv_task()),

]

try:

await asyncio.gather(*tasks)

finally:

await utils.aio.cancel_and_wait(*tasks)

async def _reload_jobs(self, jobs: list[RunningJobInfo]) -> None:

if not self._opts.api_secret:

raise RuntimeError("api_secret is required to reload jobs")

for aj in jobs:

logger.log(

DEV_LEVEL,

"reloading job",

extra={"job_id": aj.job.id, "agent_name": aj.job.agent_name},

)

# take the original jwt token and extend it while keeping all the same data that was generated  # noqa: E501

# by the SFU for the original join token.

original_token = aj.token

decoded = jwt.decode(original_token, self._opts.api_secret, algorithms=["HS256"])

decoded["exp"] = int(datetime.datetime.now(datetime.timezone.utc).timestamp()) + 3600

running_info = RunningJobInfo(

accept_arguments=aj.accept_arguments,

job=aj.job,

url=self._opts.ws_url,

token=jwt.encode(decoded, self._opts.api_secret, algorithm="HS256"),

worker_id=aj.worker_id,

)

await self._proc_pool.launch_job(running_info)

def _handle_register(self, reg: agent.RegisterWorkerResponse) -> None:

self._id = reg.worker_id

logger.info(

"registered worker",

extra={

"id": reg.worker_id,

"url": self._opts.ws_url,

"region": reg.server_info.region,

"protocol": reg.server_info.protocol,

},

)

self.emit("worker_registered", reg.worker_id, reg.server_info)

def _handle_availability(self, msg: agent.AvailabilityRequest) -> None:

task = self._loop.create_task(self._answer_availability(msg))

self._tasks.add(task)

task.add_done_callback(self._tasks.discard)

async def _answer_availability(self, msg: agent.AvailabilityRequest) -> None:

"""Ask the user if they want to accept this job and forward the answer to the server.

If we get the job assigned, we start a new process."""

answered = False

async def _on_reject() -> None:

nonlocal answered

answered = True

availability_resp = agent.WorkerMessage()

availability_resp.availability.job_id = msg.job.id

availability_resp.availability.available = False

await self._queue_msg(availability_resp)

async def _on_accept(args: JobAcceptArguments) -> None:

nonlocal answered

answered = True

availability_resp = agent.WorkerMessage()

availability_resp.availability.job_id = msg.job.id

availability_resp.availability.available = True

availability_resp.availability.participant_identity = args.identity

availability_resp.availability.participant_name = args.name

availability_resp.availability.participant_metadata = args.metadata

if args.attributes:

availability_resp.availability.participant_attributes.update(args.attributes)

await self._queue_msg(availability_resp)

wait_assignment = asyncio.Future[agent.JobAssignment]()

self._pending_assignments[job_req.id] = wait_assignment

# the job was accepted by the user, wait for the server assignment

try:

await asyncio.wait_for(wait_assignment, ASSIGNMENT_TIMEOUT)

except asyncio.TimeoutError:

logger.warning(

f"assignment for job {job_req.id} timed out",

extra={"job_request": job_req, "agent_name": self._opts.agent_name},

)

raise AssignmentTimeoutError() from None

job_assign = wait_assignment.result()

running_info = RunningJobInfo(

accept_arguments=args,

job=msg.job,

url=job_assign.url or self._opts.ws_url,

token=job_assign.token,

worker_id=self._id,

)

await self._proc_pool.launch_job(running_info)

job_req = JobRequest(job=msg.job, on_reject=_on_reject, on_accept=_on_accept)

logger.info(

"received job request",

extra={

"job_id": msg.job.id,

"dispatch_id": msg.job.dispatch_id,

"room_name": msg.job.room.name,

"agent_name": self._opts.agent_name,

"resuming": msg.resuming,

},

)

@utils.log_exceptions(logger=logger)

async def _job_request_task() -> None:

try:

await self._opts.request_fnc(job_req)

except Exception:

logger.exception(

"job_request_fnc failed",

extra={"job_request": job_req, "agent_name": self._opts.agent_name},

)

if not answered:

logger.warning(

"no answer was given inside the job_request_fnc, automatically rejecting the job",  # noqa: E501

extra={"job_request": job_req, "agent_name": self._opts.agent_name},

)

await _on_reject()

user_task = self._loop.create_task(_job_request_task(), name="job_request")

self._tasks.add(user_task)

user_task.add_done_callback(self._tasks.discard)

def _handle_assignment(self, assignment: agent.JobAssignment) -> None:

if assignment.job.id in self._pending_assignments:

with contextlib.suppress(asyncio.InvalidStateError):

fut = self._pending_assignments.pop(assignment.job.id)

fut.set_result(assignment)

else:

logger.warning(

"received assignment for an unknown job",

extra={"job": assignment.job, "agent_name": self._opts.agent_name},

)

async def _handle_termination(self, msg: agent.JobTermination) -> None:

proc = self._proc_pool.get_by_job_id(msg.job_id)

if not proc:

# safe to ignore

return

await proc.aclose()

async def _update_worker_status(self) -> None:

job_cnt = len(self.active_jobs)

if self._draining:

update = agent.UpdateWorkerStatus(status=agent.WorkerStatus.WS_FULL, job_count=job_cnt)

msg = agent.WorkerMessage(update_worker=update)

await self._queue_msg(msg)

return

load_threshold = _WorkerEnvOption.getvalue(self._opts.load_threshold, self._devmode)

is_full = self._worker_load >= load_threshold

currently_available = not is_full and not self._draining

status = (

agent.WorkerStatus.WS_AVAILABLE if currently_available else agent.WorkerStatus.WS_FULL

)

update = agent.UpdateWorkerStatus(load=self._worker_load, status=status, job_count=job_cnt)

# only log if status has changed

if self._previous_status != status and not self._draining:

self._previous_status = status

extra = {

"load": self._worker_load,

"threshold": self._opts.load_threshold,

}

if is_full:

logger.info(

"worker is at full capacity, marking as unavailable",

extra=extra,

)

else:

logger.info(

"worker is below capacity, marking as available",

extra=extra,

)

msg = agent.WorkerMessage(update_worker=update)

with contextlib.suppress(utils.aio.ChanClosed):

await self._queue_msg(msg)

async def _update_job_status(self, proc: ipc.job_executor.JobExecutor) -> None:

job_info = proc.running_job

if job_info is None:

return

status: agent.JobStatus = agent.JobStatus.JS_RUNNING

if proc.status == ipc.job_executor.JobStatus.FAILED:

status = agent.JobStatus.JS_FAILED

elif proc.status == ipc.job_executor.JobStatus.SUCCESS:

status = agent.JobStatus.JS_SUCCESS

elif proc.status == ipc.job_executor.JobStatus.RUNNING:

status = agent.JobStatus.JS_RUNNING

update = agent.UpdateJobStatus(job_id=job_info.job.id, status=status, error="")

msg = agent.WorkerMessage(update_job=update)

await self._queue_msg(msg)

Abstract base class for generic types.

On Python 3.12 and newer, generic classes implicitly inherit from

Generic when they declare a parameter list after the class's name::

class Mapping[KT, VT]:

def __getitem__(self, key: KT) -> VT:

...

# Etc.

On older versions of Python, however, generic classes have to

explicitly inherit from Generic.

After a class has been declared to be generic, it can then be used as

follows::

def lookup_name[KT, VT](mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:

try:

return mapping[key]

except KeyError:

return default

Initialize a new instance of EventEmitter.

Ancestors

EventEmitter

typing.Generic

Instance variables

prop

active_jobs

: list[RunningJobInfo]

Expand source code

@property

def active_jobs(self) -> list[RunningJobInfo]:

return [proc.running_job for proc in self._proc_pool.processes if proc.running_job]

prop

id

: str

Expand source code

@property

def id(self) -> str:

return self._id

prop

worker_info

: WorkerInfo

Expand source code

@property

def worker_info(self) -> WorkerInfo:

return WorkerInfo(http_port=self._http_server.port)

Methods

async def

aclose

(

self) ‑> None

Expand source code

async def aclose(self) -> None:

if self._closed:

if self._close_future is not None:

await self._close_future

return

logger.info("shutting down worker", extra={"id": self.id})

assert self._close_future is not None

assert self._http_session is not None

assert self._api is not None

self._closed = True

if self._conn_task is not None:

await utils.aio.cancel_and_wait(self._conn_task)

if self._load_task is not None:

await utils.aio.cancel_and_wait(self._load_task)

await self._proc_pool.aclose()

if self._inference_executor is not None:

await self._inference_executor.aclose()

await self._http_session.close()

await self._http_server.aclose()

if self._prometheus_server:

await self._prometheus_server.aclose()

await self._api.aclose()  # type: ignore

await asyncio.gather(*self._tasks, return_exceptions=True)

# await asyncio.sleep(0.25)  # see https://github.com/aio-libs/aiohttp/issues/1925

self._msg_chan.close()

await self._close_future

async def

drain

(

self, timeout: int | None = None) ‑> None

Expand source code

async def drain(self, timeout: int | None = None) -> None:

"""When timeout isn't None, it will raise asyncio.TimeoutError if the processes didn't finish in time."""  # noqa: E501

if self._draining:

return

logger.info("draining worker", extra={"id": self.id, "timeout": timeout})

self._draining = True

await self._update_worker_status()

async def _join_jobs() -> None:

for proc in list(self._proc_pool.processes):

if proc.running_job:

await proc.join()

if timeout:

await asyncio.wait_for(_join_jobs(), timeout)  # raises asyncio.TimeoutError on timeout

else:

await _join_jobs()

When timeout isn't None, it will raise asyncio.TimeoutError if the processes didn't finish in time.

async def

run

(

self) ‑> None

Expand source code

async def run(self) -> None:

if not self._closed:

raise Exception("worker is already running")

logger.info(

"starting worker",

extra={"version": __version__, "rtc-version": rtc.__version__},

)

# Clean prometheus multiprocess directory to avoid stale metrics (only if it exists)

if self._prometheus_multiproc_dir and os.path.exists(self._prometheus_multiproc_dir):

logger.debug(

"cleaning prometheus multiprocess directory",

extra={"dir": self._prometheus_multiproc_dir},

)

# Remove all files in the directory but keep the directory itself

for filename in os.listdir(self._prometheus_multiproc_dir):

file_path = os.path.join(self._prometheus_multiproc_dir, filename)

try:

if os.path.isfile(file_path):

os.unlink(file_path)

except Exception as e:

logger.warning(f"failed to remove {file_path}: {e}")

if self._opts.multiprocessing_context == "forkserver":

plugin_packages = [p.package for p in Plugin.registered_plugins] + ["av"]

logger.info("preloading plugins", extra={"packages": plugin_packages})

self._mp_ctx.set_forkserver_preload(plugin_packages)

if self._inference_executor is not None:

logger.info("starting inference executor")

await self._inference_executor.start()

await self._inference_executor.initialize()

self._closed = False

def _update_job_status(proc: ipc.job_executor.JobExecutor) -> None:

t = self._loop.create_task(self._update_job_status(proc))

self._tasks.add(t)

t.add_done_callback(self._tasks.discard)

await self._http_server.start()

if self._prometheus_server:

await self._prometheus_server.start()

self._proc_pool.on("process_started", _update_job_status)

self._proc_pool.on("process_closed", _update_job_status)

self._proc_pool.on("process_job_launched", _update_job_status)

await self._proc_pool.start()

self._http_session = aiohttp.ClientSession(proxy=self._opts.http_proxy or None)

self._api = api.LiveKitAPI(

self._opts.ws_url, self._opts.api_key, self._opts.api_secret, session=self._http_session

)

self._close_future = asyncio.Future(loop=self._loop)

@utils.log_exceptions(logger=logger)

async def _load_task() -> None:

"""periodically check load"""

interval = utils.aio.interval(UPDATE_LOAD_INTERVAL)

while True:

await interval.tick()

def load_fnc() -> float:

signature = inspect.signature(self._opts.load_fnc)

parameters = list(signature.parameters.values())

if len(parameters) == 0:

return self._opts.load_fnc()  # type: ignore

return self._opts.load_fnc(self)  # type: ignore

self._worker_load = await asyncio.get_event_loop().run_in_executor(None, load_fnc)

# Update child process count metric for prometheus multiprocess mode

if self._prometheus_multiproc_dir:

telemetry.metrics._update_child_proc_count()

load_threshold = _WorkerEnvOption.getvalue(self._opts.load_threshold, self._devmode)

default_num_idle_processes = _WorkerEnvOption.getvalue(

self._opts.num_idle_processes, self._devmode

)

if not math.isinf(load_threshold):

active_jobs = len(self.active_jobs)

if active_jobs > 0:

job_load = self._worker_load / len(self.active_jobs)

if job_load > 0.0:

available_load = max(load_threshold - self._worker_load, 0.0)

available_job = min(

math.ceil(available_load / job_load), default_num_idle_processes

)

self._proc_pool.set_target_idle_processes(available_job)

else:

self._proc_pool.set_target_idle_processes(default_num_idle_processes)

tasks = []

self._load_task = asyncio.create_task(_load_task(), name="load_task")

tasks.append(self._load_task)

if self._register:

self._conn_task = asyncio.create_task(self._connection_task(), name="worker_conn_task")

tasks.append(self._conn_task)

self.emit("worker_started")

try:

await asyncio.gather(*tasks)

finally:

await utils.aio.cancel_and_wait(*tasks)

if not self._close_future.done():

self._close_future.set_result(None)

async def

simulate_job

(

self,

info:

SimulateJobInfo

| str) ‑> None

Expand source code

async def simulate_job(

self,

info: SimulateJobInfo | str,

) -> None:

"""

Simulate a job by creating a room and participant.

Args:

info: SimulateJobInfo or a join token for an existing room

"""

assert self._api is not None

# TODO(theomonnom): some fake information can still be found in the token

from livekit.protocol.models import Room

room = info.room if isinstance(info, SimulateJobInfo) else "unknown-room"

participant_identity = (

info.participant_identity

if isinstance(info, SimulateJobInfo)

else "unknown-participant"

)

agent_id = utils.shortuuid("simulated-agent-")

room_info = Room(sid=utils.shortuuid("RM_"), name=room)

participant_info = None

if isinstance(info, SimulateJobInfo):

from .cli import cli

if cli.CLI_ARGUMENTS is None or not cli.CLI_ARGUMENTS.console:

room_info = await self._api.room.create_room(api.CreateRoomRequest(name=room))

if participant_identity:

participant_info = await self._api.room.get_participant(

api.RoomParticipantIdentity(room=room, identity=participant_identity)

)

token = (

api.AccessToken(self._opts.api_key, self._opts.api_secret)

.with_identity(agent_id)

.with_kind("agent")

.with_grants(api.VideoGrants(room_join=True, room=room, agent=True))

.to_jwt()

)

else:

token = info

job = agent.Job(

id=utils.shortuuid("simulated-job-"),

room=room_info,

type=agent.JobType.JT_ROOM,

participant=participant_info,

)

running_info = RunningJobInfo(

worker_id=self._id,

accept_arguments=JobAcceptArguments(identity=agent_id, name="", metadata=""),

job=job,

url=self._opts.ws_url,

token=token,

)

await self._proc_pool.launch_job(running_info)

Simulate a job by creating a room and participant.

Args

info

SimulateJobInfo or a join token for an existing room

Inherited members

EventEmitter

:

emit

off

on

once

class

WorkerOptions

(

entrypoint_fnc: Callable[[

JobContext

], Awaitable[None]],

request_fnc: Callable[[

JobRequest

], Awaitable[None]] = <function _default_request_fnc>,

prewarm_fnc: Callable[[

JobProcess

], Any] = <function _default_initialize_process_fnc>,

load_fnc: Callable[[

Worker

], float] | Callable[[], float] = <bound method _DefaultLoadCalc.get_load of <class 'livekit.agents.worker._DefaultLoadCalc'>>,

job_executor_type:

JobExecutorType

= JobExecutorType.PROCESS,

load_threshold: float | _WorkerEnvOption[float] = _WorkerEnvOption(dev_default=inf, prod_default=0.7),

job_memory_warn_mb: float = 500,

job_memory_limit_mb: float = 0,

drain_timeout: int = 1800,

num_idle_processes: int | _WorkerEnvOption[int] = _WorkerEnvOption(dev_default=0, prod_default=4),

shutdown_process_timeout: float = 60.0,

initialize_process_timeout: float = 10.0,

permissions:

WorkerPermissions

= <factory>,

agent_name: str = '',

worker_type:

WorkerType

= WorkerType.ROOM,

max_retry: int = 16,

ws_url: str = 'ws://localhost:7880',

api_key: str | None = None,

api_secret: str | None = None,

host: str = '',

port: int | _WorkerEnvOption[int] = _WorkerEnvOption(dev_default=0, prod_default=8081),

http_proxy: NotGivenOr[str | None] = NOT_GIVEN,

multiprocessing_context: "Literal['spawn', 'forkserver']" = 'forkserver',

prometheus_port: NotGivenOr[int] = NOT_GIVEN,

prometheus_multiproc_dir: str | None = None)

Expand source code

@dataclass

class WorkerOptions:

entrypoint_fnc: Callable[[JobContext], Awaitable[None]]

"""Entrypoint function that will be called when a job is assigned to this worker."""

request_fnc: Callable[[JobRequest], Awaitable[None]] = _default_request_fnc

"""Inspect the request and decide if the current worker should handle it.

When left empty, all jobs are accepted."""

prewarm_fnc: Callable[[JobProcess], Any] = _default_initialize_process_fnc

"""A function to perform any necessary initialization before the job starts."""

load_fnc: Callable[[Worker], float] | Callable[[], float] = _DefaultLoadCalc.get_load

"""Called to determine the current load of the worker. Should return a value between 0 and 1."""

job_executor_type: JobExecutorType = _default_job_executor_type

"""Which executor to use to run jobs. (currently thread or process are supported)"""

load_threshold: float | _WorkerEnvOption[float] = _default_load_threshold

"""When the load exceeds this threshold, the worker will be marked as unavailable.

Defaults to 0.7 on "production" mode, and is disabled in "development" mode.

"""

job_memory_warn_mb: float = 500

"""Memory warning threshold in MB. If the job process exceeds this limit, a warning will be logged."""  # noqa: E501

job_memory_limit_mb: float = 0

"""Maximum memory usage for a job in MB, the job process will be killed if it exceeds this limit.

Defaults to 0 (disabled).

"""  # noqa: E501

drain_timeout: int = 1800

"""Number of seconds to wait for current jobs to finish upon receiving TERM or INT signal."""

num_idle_processes: int | _WorkerEnvOption[int] = _WorkerEnvOption(

dev_default=0, prod_default=min(math.ceil(get_cpu_monitor().cpu_count()), 4)

)

"""Number of idle processes to keep warm."""

shutdown_process_timeout: float = 60.0

"""Maximum amount of time to wait for a job to shut down gracefully"""

initialize_process_timeout: float = 10.0

"""Maximum amount of time to wait for a process to initialize/prewarm"""

permissions: WorkerPermissions = field(default_factory=WorkerPermissions)

"""Permissions that the agent should join the room with."""

agent_name: str = ""

"""Set agent_name to enable explicit dispatch. When explicit dispatch is enabled, jobs will not be dispatched to rooms automatically. Instead, you can either specify the agent(s) to be dispatched in the end-user's token, or use the AgentDispatch.createDispatch API"""  # noqa: E501

worker_type: WorkerType = WorkerType.ROOM

"""Whether to spin up an agent for each room or publisher."""

max_retry: int = 16

"""Maximum number of times to retry connecting to LiveKit."""

ws_url: str = "ws://localhost:7880"

"""URL to connect to the LiveKit server.

By default it uses ``LIVEKIT_URL`` from environment"""

api_key: str | None = None

"""API key to authenticate with LiveKit.

By default it uses ``LIVEKIT_API_KEY`` from environment"""

api_secret: str | None = None

"""API secret to authenticate with LiveKit.

By default it uses ``LIVEKIT_API_SECRET`` from environment"""

_worker_token: str | None = None

"""Internal token."""

host: str = ""  # default to all interfaces

port: int | _WorkerEnvOption[int] = _WorkerEnvOption(dev_default=0, prod_default=8081)

"""Port for local HTTP server to listen on.

The HTTP server is used as a health check endpoint.

"""

http_proxy: NotGivenOr[str | None] = NOT_GIVEN

"""HTTP proxy used to connect to the LiveKit server.

By default it uses ``HTTP_PROXY`` or ``HTTPS_PROXY`` from environment

"""

multiprocessing_context: Literal["spawn", "forkserver"] = (

"spawn" if not sys.platform.startswith("linux") else "forkserver"

)

"""The multiprocessing context to use.

By default it uses "spawn" on all platforms, but "forkserver" on Linux.

"""

prometheus_port: NotGivenOr[int] = NOT_GIVEN

"""When enabled, will expose prometheus metrics on :{prometheus_port}/metrics"""

prometheus_multiproc_dir: str | None = None

"""Directory for prometheus multiprocess mode to enable metrics collection from child job processes.

When set, the PROMETHEUS_MULTIPROC_DIR environment variable will be configured automatically.

When None (default), multiprocess mode is disabled and only main process metrics are collected.

Users can also set PROMETHEUS_MULTIPROC_DIR environment variable directly before starting the worker."""

def validate_config(self, devmode: bool) -> None:

load_threshold = _WorkerEnvOption.getvalue(self.load_threshold, devmode)

if load_threshold > 1 and not devmode:

logger.warning(

f"load_threshold in prod env must be less than 1, current value: {load_threshold}"

)

WorkerOptions(entrypoint_fnc: 'Callable[[JobContext], Awaitable[None]]', request_fnc: 'Callable[[JobRequest], Awaitable[None]]' =

, prewarm_fnc: 'Callable[[JobProcess], Any]' =

, load_fnc: 'Callable[[Worker], float] | Callable[[], float]' =

>, job_executor_type: 'JobExecutorType' =

, load_threshold: 'float | _WorkerEnvOption[float]' = _WorkerEnvOption(dev_default=inf, prod_default=0.7), job_memory_warn_mb: 'float' = 500, job_memory_limit_mb: 'float' = 0, drain_timeout: 'int' = 1800, num_idle_processes: 'int | _WorkerEnvOption[int]' = _WorkerEnvOption(dev_default=0, prod_default=4), shutdown_process_timeout: 'float' = 60.0, initialize_process_timeout: 'float' = 10.0, permissions: 'WorkerPermissions' =

, agent_name: 'str' = '', worker_type: 'WorkerType' =

, max_retry: 'int' = 16, ws_url: 'str' = 'ws://localhost:7880', api_key: 'str | None' = None, api_secret: 'str | None' = None, _worker_token: 'str | None' = None, host: 'str' = '', port: 'int | _WorkerEnvOption[int]' = _WorkerEnvOption(dev_default=0, prod_default=8081), http_proxy: 'NotGivenOr[str | None]' = NOT_GIVEN, multiprocessing_context: "Literal['spawn', 'forkserver']" = 'forkserver', prometheus_port: 'NotGivenOr[int]' = NOT_GIVEN, prometheus_multiproc_dir: 'str | None' = None)

Static methods

def

load_fnc

(

worker:

Worker

) ‑> float

Instance variables

var

agent_name

: str

Set agent_name to enable explicit dispatch. When explicit dispatch is enabled, jobs will not be dispatched to rooms automatically. Instead, you can either specify the agent(s) to be dispatched in the end-user's token, or use the AgentDispatch.createDispatch API

var

api_key

: str | None

API key to authenticate with LiveKit.

By default it uses

LIVEKIT_API_KEY

from environment

var

api_secret

: str | None

API secret to authenticate with LiveKit.

By default it uses

LIVEKIT_API_SECRET

from environment

var

drain_timeout

: int

Number of seconds to wait for current jobs to finish upon receiving TERM or INT signal.

var

entrypoint_fnc

: Callable[[livekit.agents.job.JobContext], Awaitable[None]]

Entrypoint function that will be called when a job is assigned to this worker.

var

host

: str

var

http_proxy

: str | livekit.agents.types.NotGiven | None

HTTP proxy used to connect to the LiveKit server.

By default it uses

HTTP_PROXY

or

HTTPS_PROXY

from environment

var

initialize_process_timeout

: float

Maximum amount of time to wait for a process to initialize/prewarm

var

job_executor_type

: livekit.agents.job.JobExecutorType

Which executor to use to run jobs. (currently thread or process are supported)

var

job_memory_limit_mb

: float

Maximum memory usage for a job in MB, the job process will be killed if it exceeds this limit.

Defaults to 0 (disabled).

var

job_memory_warn_mb

: float

Memory warning threshold in MB. If the job process exceeds this limit, a warning will be logged.

var

load_threshold

: float | livekit.agents.worker._WorkerEnvOption[float]

When the load exceeds this threshold, the worker will be marked as unavailable.

Defaults to 0.7 on "production" mode, and is disabled in "development" mode.

var

max_retry

: int

Maximum number of times to retry connecting to LiveKit.

var

multiprocessing_context

: Literal['spawn', 'forkserver']

The multiprocessing context to use.

By default it uses "spawn" on all platforms, but "forkserver" on Linux.

var

num_idle_processes

: int | livekit.agents.worker._WorkerEnvOption[int]

Number of idle processes to keep warm.

var

permissions

: livekit.agents.worker.WorkerPermissions

Permissions that the agent should join the room with.

var

port

: int | livekit.agents.worker._WorkerEnvOption[int]

Port for local HTTP server to listen on.

The HTTP server is used as a health check endpoint.

var

prometheus_multiproc_dir

: str | None

Directory for prometheus multiprocess mode to enable metrics collection from child job processes.

When set, the PROMETHEUS_MULTIPROC_DIR environment variable will be configured automatically.

When None (default), multiprocess mode is disabled and only main process metrics are collected.

Users can also set PROMETHEUS_MULTIPROC_DIR environment variable directly before starting the worker.

var

prometheus_port

: int | livekit.agents.types.NotGiven

When enabled, will expose prometheus metrics on :{prometheus_port}/metrics

var

shutdown_process_timeout

: float

Maximum amount of time to wait for a job to shut down gracefully

var

worker_type

: livekit.agents.worker.WorkerType

Whether to spin up an agent for each room or publisher.

var

ws_url

: str

URL to connect to the LiveKit server.

By default it uses

LIVEKIT_URL

from environment

Methods

def

prewarm_fnc

(

proc:

JobProcess

) ‑> Any

Expand source code

def _default_initialize_process_fnc(proc: JobProcess) -> Any:

return

async def

request_fnc

(

ctx:

JobRequest

) ‑> None

Expand source code

async def _default_request_fnc(ctx: JobRequest) -> None:

await ctx.accept()

def

validate_config

(

self, devmode: bool) ‑> None

Expand source code

def validate_config(self, devmode: bool) -> None:

load_threshold = _WorkerEnvOption.getvalue(self.load_threshold, devmode)

if load_threshold > 1 and not devmode:

logger.warning(

f"load_threshold in prod env must be less than 1, current value: {load_threshold}"

)

class

WorkerPermissions

(

can_publish: bool = True,

can_subscribe: bool = True,

can_publish_data: bool = True,

can_update_metadata: bool = True,

can_publish_sources: list[models.TrackSource] = <factory>,

hidden: bool = False)

Expand source code

@dataclass

class WorkerPermissions:

can_publish: bool = True

can_subscribe: bool = True

can_publish_data: bool = True

can_update_metadata: bool = True

can_publish_sources: list[models.TrackSource] = field(default_factory=list)

hidden: bool = False

WorkerPermissions(can_publish: 'bool' = True, can_subscribe: 'bool' = True, can_publish_data: 'bool' = True, can_update_metadata: 'bool' = True, can_publish_sources: 'list[models.TrackSource]' =

, hidden: 'bool' = False)

Instance variables

var

can_publish

: bool

var

can_publish_data

: bool

var

can_publish_sources

: list[

]

var

can_subscribe

: bool

var

can_update_metadata

: bool

var

hidden

: bool

class

WorkerType

(

*args, **kwds)

Expand source code

class WorkerType(Enum):

ROOM = agent.JobType.JT_ROOM

PUBLISHER = agent.JobType.JT_PUBLISHER

Create a collection of name/value pairs.

Example enumeration:

>>> class Color(Enum):

...     RED = 1

...     BLUE = 2

...     GREEN = 3

Access them by:

attribute access:

Color.RED

value lookup:

Color(1)

name lookup:

Color['RED']

Enumerations can be iterated over, and know how many members they have:

>>> len(Color)

3

>>> list(Color)

[<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]

Methods can be added to enumerations, and members can have their own

attributes – see the documentation for details.

Ancestors

enum.Enum

Class variables

var

PUBLISHER

var

ROOM