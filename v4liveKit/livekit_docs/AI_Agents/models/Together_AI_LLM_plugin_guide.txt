================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/agents/models/llm/plugins/together/
Title: 
Crawled: 2025-11-01 21:21:52
================================================================================

On this page

Overview

Usage

Parameters

Additional resources

Copy page

See more page options

Available in

Python

|

Node.js

Overview

This plugin allows you to use

Together AI

as an LLM provider for your voice agents.

Usage

Install the OpenAI plugin to add Together AI support:

Python

Node.js

uv

add

"livekit-agents[openai]~=1.2"

pnpm

add@livekit/agents-plugin-openai@1.x

Set the following environment variable in your

.env

file:

TOGETHER_API_KEY

=

<

your-together-api-key

>

Create a Together AI LLM using the

with_together

method:

Python

Node.js

from

livekit

.

plugins

import

openai

session

=

AgentSession

(

llm

=

openai

.

LLM

.

with_together

(

model

=

"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"

,

)

,

# ... tts, stt, vad, turn_detection, etc.

)

import

*

as

openai

from

'@livekit/agents-plugin-openai'

;

const

session

=

new

voice

.

AgentSession

(

llm

:

new

openai

.

LLM

.

withTogether

(

model

:

"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"

,

)

,

// ... tts, stt, vad, turn_detection, etc.

)

;

Parameters

This section describes some of the available parameters. For a complete reference of all available parameters, see the

plugin reference links in the

Additional resources

section.

model

str | TogetherChatModels

Optional

Default:

meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo

#

Model to use for inference. To learn more, see

supported models

.

temperature

float

Optional

Default:

1.0

#

Controls the randomness of the model's output. Higher values, for example 0.8, make the output more random, while lower values, for example 0.2, make it more focused and deterministic.

Valid values are between

0

and

1

.

parallel_tool_calls

bool

Optional

#

Controls whether the model can make multiple tool calls in parallel. When enabled, the model can make multiple tool calls simultaneously, which can improve performance for complex tasks.

tool_choice

ToolChoice | Literal['auto', 'required', 'none']

Optional

Default:

auto

#

Controls how the model uses tools. Set to 'auto' to let the model decide, 'required' to force tool usage, or 'none' to disable tool usage.

Additional resources

The following links provide more information about the Together AI LLM integration.

Python plugin

Reference

GitHub

PyPI

Node.js plugin

Reference

GitHub

NPM

Together AI docs

Together AI API documentation.

Voice AI quickstart

Get started with LiveKit Agents and Together AI.

On this page

Overview

Usage

Parameters

Additional resources