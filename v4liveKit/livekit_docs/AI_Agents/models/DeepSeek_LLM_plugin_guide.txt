================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/agents/models/llm/plugins/deepseek/
Title: 
Crawled: 2025-11-01 21:21:49
================================================================================

On this page

Overview

Usage

Parameters

Additional resources

Copy page

See more page options

Available in

Python

|

Node.js

Overview

This plugin allows you to use the

DeepSeek API

as an LLM provider for your voice agents.

LiveKit Inference

DeepSeek models are also available in various providers in LiveKit Inference, with billing and integration handled automatically. See

the docs

for more information.

Usage

Use the OpenAI plugin's

with_deepseek

method to set the default agent session LLM to DeepSeek:

Python

Node.js

uv

add

"livekit-agents[openai]~=1.2"

pnpm

add

@livekit/agents-plugin-openai@1.x

Set the following environment variable in your

.env

file:

DEEPSEEK_API_KEY

=

<

your-deepseek-api-key

>

Python

Node.js

from

livekit

.

plugins

import

openai

session

=

AgentSession

(

llm

=

openai

.

LLM

.

with_deepseek

(

model

=

"deepseek-chat"

,

# this is DeepSeek-V3

)

,

)

import

*

as

openai

from

'@livekit/agents-plugin-openai'

;

const

session

=

new

voice

.

AgentSession

(

{

llm

:

openai

.

LLM

.

withDeepSeek

(

{

model

:

"deepseek-chat"

,

// this is DeepSeek-V3

}

)

}

)

;

Parameters

This section describes some of the available parameters. For a complete reference of all available parameters, see the plugin reference links in the

Additional resources

section.

model

str | DeepSeekChatModels

Optional

Default:

deepseek-chat

#

DeepSeek model to use. See

models and pricing

for a complete list.

temperature

float

Optional

Default:

1.0

#

Controls the randomness of the model's output. Higher values, for example 0.8, make the output more random, while lower values, for example 0.2, make it more focused and deterministic.

Valid values are between

0

and

2

.

parallel_tool_calls

bool

Optional

#

Controls whether the model can make multiple tool calls in parallel. When enabled, the model can make multiple tool calls simultaneously, which can improve performance for complex tasks.

tool_choice

ToolChoice | Literal['auto', 'required', 'none']

Optional

Default:

auto

#

Controls how the model uses tools. Set to 'auto' to let the model decide, 'required' to force tool usage, or 'none' to disable tool usage.

Additional resources

The following links provide more information about the DeepSeek LLM integration.

Python plugin

Reference

GitHub

PyPI

Node.js plugin

Reference

GitHub

NPM

DeepSeek docs

DeepSeek API documentation.

Voice AI quickstart

Get started with LiveKit Agents and DeepSeek.

On this page

Overview

Usage

Parameters

Additional resources