================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/agents/models/llm/plugins/openrouter/
Title: 
Crawled: 2025-11-01 21:22:00
================================================================================

On this page

Overview

Usage

Authentication

Parameters

Examples

Additional resources

Copy page

See more page options

Available in

Python

Overview

This plugin allows you to use

OpenRouter

as an LLM provider for your voice agents. OpenRouter provides access to hundreds of models from multiple providers through a unified API, with automatic fallback support and intelligent routing.

Usage

Install the OpenAI plugin to add OpenRouter support:

uv

add

"livekit-agents[openai]~=1.2"

Authentication

The OpenRouter plugin requires an

OpenRouter API key

.

Set

OPENROUTER_API_KEY

in your

.env

file.

Create an OpenRouter LLM using the

with_openrouter

method:

from

livekit

.

plugins

import

openai

session

=

AgentSession

(

llm

=

openai

.

LLM

.

with_openrouter

(

model

=

"anthropic/claude-sonnet-4.5"

)

,

# ... tts, stt, vad, turn_detection, etc.

)

Parameters

This section describes some of the available parameters. See the usage examples below and the plugin reference links in the

Additional resources

section for a complete list of all available parameters.

model

string

Optional

Default:

openrouter/auto

#

Model to use. Can be "openrouter/auto" to let OpenRouter choose, or specify a specific model like "anthropic/claude-sonnet-4.5". For a list of available models, see

OpenRouter models

.

site_url

string

Optional

#

Your site URL for analytics and ranking on OpenRouter. This is sent as the

HTTP-Referer

header.

app_name

string

Optional

#

Your app name for analytics on OpenRouter. This is sent as the

X-Title

header.

fallback_models

list[string]

Optional

#

List of fallback models to use if the primary model is unavailable. Example:

fallback_models=["anthropic/claude-sonnet-4", "openai/gpt-5-mini"]

.

provider

dict

Optional

#

Provider routing preferences for fine-grained control over model selection. Can include:

order

: List of preferred providers in order

allow_fallbacks

: Whether to allow fallback to other providers

require_parameters

: Whether to require specific parameters

data_collection

: Data collection preference, either "allow" or "deny"

only

: List of providers to exclusively use

ignore

: List of providers to exclude

quantizations

: List of accepted quantization levels

sort

: Sort providers by "price", "throughput", or "latency"

max_price

: Maximum price per token

Refer to the

OpenRouter documentation

for more information.

plugins

list[OpenRouterWebPlugin]

Optional

#

List of OpenRouter plugins to enable. Currently supports web search plugin with configuration for max results and search prompts.

Examples

The following examples demonstrate usage of various OpenRouter parameters.

Configure multiple fallback models to use if the primary model is unavailable:

from

livekit

.

plugins

import

openai

llm

=

openai

.

LLM

.

with_openrouter

(

model

=

"openai/gpt-4o"

,

fallback_models

=

[

"anthropic/claude-sonnet-4"

,

"openai/gpt-5-mini"

,

]

,

)

Control which providers are used for model inference:

from

livekit

.

plugins

import

openai

llm

=

openai

.

LLM

.

with_openrouter

(

model

=

"deepseek/deepseek-chat-v3.1"

,

provider

=

{

"order"

:

[

"novita/fp8"

,

"gmicloud/fp8"

,

"google-vertex"

]

,

"allow_fallbacks"

:

True

,

"sort"

:

"latency"

,

}

,

)

Enable OpenRouter's web search capabilities:

from

livekit

.

plugins

import

openai

llm

=

openai

.

LLM

.

with_openrouter

(

model

=

"google/gemini-2.5-flash-preview-09-2025"

,

plugins

=

[

openai

.

OpenRouterWebPlugin

(

max_results

=

5

,

search_prompt

=

"Search for relevant information"

,

)

]

,

)

Include site and app information for OpenRouter analytics:

from

livekit

.

plugins

import

openai

llm

=

openai

.

LLM

.

with_openrouter

(

model

=

"openrouter/auto"

,

site_url

=

"https://myapp.com"

,

app_name

=

"My Voice Agent"

,

)

Additional resources

The following links provide more information about the OpenRouter integration.

Python plugin

Reference

GitHub

PyPI

GitHub repo

View the source or contribute to the LiveKit OpenAI LLM plugin.

OpenRouter docs

OpenRouter API documentation and model list.

Voice AI quickstart

Get started with LiveKit Agents and OpenRouter.

On this page

Overview

Usage

Authentication

Parameters

Examples

Additional resources