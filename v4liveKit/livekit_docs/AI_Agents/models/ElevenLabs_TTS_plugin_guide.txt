================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/agents/models/tts/plugins/elevenlabs/
Title: 
Crawled: 2025-11-01 21:21:05
================================================================================

On this page

Overview

Quick reference

Installation

Authentication

Usage

Parameters

Customizing pronunciation

Transcription timing

Additional resources

Copy page

See more page options

Available in

Python

|

Node.js

Overview

This plugin allows you to use

ElevenLabs

as a TTS provider for your voice agents.

LiveKit Inference

ElevenLabs TTS is also available in LiveKit Inference, with billing and integration handled automatically. See

the docs

for more information.

Quick reference

This section provides a quick reference for the ElevenLabs TTS plugin. For more information, see

Additional resources

.

Installation

Install the plugin from PyPI:

Python

Node.js

uv

add

"livekit-agents[elevenlabs]~=1.2"

pnpm

add

@livekit/agents-plugin-elevenlabs@1.x

Authentication

The ElevenLabs plugin requires an

ElevenLabs API key

.

Set

ELEVEN_API_KEY

in your

.env

file.

Usage

Use ElevenLabs TTS within an

AgentSession

or as a standalone speech generator. For example,

you can use this TTS in the

Voice AI quickstart

.

Python

Node.js

from

livekit

.

plugins

import

elevenlabs

session

=

AgentSession

(

tts

=

elevenlabs

.

TTS

(

voice_id

=

"ODq5zmih8GrVes37Dizd"

,

model

=

"eleven_multilingual_v2"

)

# ... llm, stt, etc.

)

import

*

as

elevenlabs

from

'@livekit/agents-plugin-elevenlabs'

;

const

session

=

new

voice

.

AgentSession

(

{

tts

:

new

elevenlabs

.

TTS

(

voice

:

{

id

:

"ODq5zmih8GrVes37Dizd"

}

,

model

:

"eleven_multilingual_v2"

)

,

// ... llm, stt, etc.

}

)

;

Parameters

This section describes some of the parameters you can set when you create an ElevenLabs TTS. See the plugin reference links in the

Additional resources

section for a complete list of all available parameters.

model

string

Optional

Default:

eleven_flash_v2_5

#

ID of the model to use for generation. To learn more, see the

ElevenLabs documentation

.

voice_id

string

Optional

Default:

EXAVITQu4vr4xnSDxMaL

#

ID of the voice to use for generation. To learn more, see the

ElevenLabs documentation

.

voice_settings

VoiceSettings

Optional

#

Voice configuration. To learn more, see the

ElevenLabs documentation

.

stability

float

Optional

#

similarity_boost

float

Optional

#

style

float

Optional

#

use_speaker_boost

bool

Optional

#

speed

float

Optional

#

language

string

Optional

Default:

en

#

Language of output audio in

ISO-639-1

format. To learn more,

see the

ElevenLabs documentation

.

streaming_latency

int

Optional

Default:

3

#

Latency in seconds for streaming.

enable_ssml_parsing

bool

Optional

Default:

false

#

Enable Speech Synthesis Markup Language (SSML) parsing for input text. Set to

true

to

customize pronunciation

using SSML.

chunk_length_schedule

list[int]

Optional

Default:

[80, 120, 200, 260]

#

Schedule for chunk lengths. Valid values range from

50

to

500

.

Customizing pronunciation

ElevenLabs supports custom pronunciation for specific words or phrases with SSML

phoneme

tags. This is useful to ensure correct pronunciation of certain words, even when missing from the voice's lexicon. To learn more, see

Pronunciation

.

Transcription timing

ElevenLabs TTS supports aligned transcription forwarding, which improves transcription synchronization in your frontend. Set

use_tts_aligned_transcript=True

in your

AgentSession

configuration to enable this feature. To learn more, see

the docs

.

Additional resources

The following resources provide more information about using ElevenLabs with LiveKit Agents.

Python plugin

Reference

GitHub

PyPI

Node.js plugin

Reference

GitHub

NPM

ElevenLabs docs

ElevenLabs TTS docs.

Voice AI quickstart

Get started with LiveKit Agents and ElevenLabs TTS.

On this page

Overview

Quick reference

Installation

Authentication

Usage

Parameters

Customizing pronunciation

Transcription timing

Additional resources