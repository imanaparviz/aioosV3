================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/agents/models/llm/plugins/langchain/
Title: 
Crawled: 2025-11-01 21:21:51
================================================================================

On this page

Overview

Quick reference

Installation

Usage

Parameters

Additional resources

Copy page

See more page options

Available in

Python

Overview

This plugin allows you to use

LangGraph

as an LLM provider for your voice agents.

Quick reference

This section includes a basic usage example and some reference material. For links to more detailed documentation, see

Additional resources

.

Installation

Install the LiveKit LangChain plugin from PyPI:

uv

add

"livekit-agents[langchain]~=1.2"

Usage

Use LangGraph workflows within an

AgentSession

by wrapping them with the

LLMAdapter

. For example,

you can use this LLM in the

Voice AI quickstart

.

from

langgraph

.

graph

import

StateGraph

from

livekit

.

agents

import

AgentSession

,

Agent

from

livekit

.

plugins

import

langchain

# Define your LangGraph workflow

def

create_workflow

(

)

:

workflow

=

StateGraph

(

.

.

.

)

# Add your nodes and edges

return

workflow

.

compile

(

)

# Use the workflow as an LLM

session

=

AgentSession

(

llm

=

langchain

.

LLMAdapter

(

graph

=

create_workflow

(

)

)

,

# ... stt, tts, vad, turn_detection, etc.

)

The

LLMAdapter

automatically converts the LiveKit chat context to

LangChain messages

. The mapping is as follows:

system

and

developer

messages to

SystemMessage

user

messages to

HumanMessage

assistant

messages to

AIMessage

Parameters

This section describes the available parameters for the

LLMAdapter

. See the

plugin reference

for a complete list of all available parameters.

graph

PregelProtocol

Required

#

The LangGraph workflow to use as an LLM. Must be a locally compiled graph. To learn more, see

Graph Definitions

.

config

RunnableConfig | None

Optional

Default:

None

#

Configuration options for the LangGraph workflow execution. This can include runtime configuration, callbacks, and other LangGraph-specific options. To learn more, see

RunnableConfig

.

Additional resources

The following resources provide more information about using LangChain with LiveKit Agents.

Python package

The

livekit-plugins-langchain

package on PyPI.

Plugin reference

Reference for the LangChain LLM adapter.

GitHub repo

View the source or contribute to the LiveKit LangChain plugin.

LangChain docs

LangChain documentation and tutorials.

LangGraph docs

LangGraph documentation for building stateful workflows.

Voice AI quickstart

Get started with LiveKit Agents and LangChain.

On this page

Overview

Quick reference

Installation

Usage

Parameters

Additional resources