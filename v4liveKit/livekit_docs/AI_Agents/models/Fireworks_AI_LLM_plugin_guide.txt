================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/agents/models/llm/plugins/fireworks/
Title: 
Crawled: 2025-11-01 21:21:56
================================================================================

On this page

Overview

Usage

Parameters

Additional resources

Copy page

See more page options

Available in

Python

|

Node.js

Overview

This plugin allows you to use

Fireworks AI

as an LLM provider for your voice agents.

Usage

Install the OpenAI plugin to add Fireworks AI support:

Python

Node.js

uv

add

"livekit-agents[openai]~=1.2"

pnpm

add

@livekit/agents-plugin-openai@1.x

Set the following environment variable in your

.env

file:

FIREWORKS_API_KEY

=

<

your-fireworks-api-key

>

Create a Fireworks AI LLM using the

with_fireworks

method:

Python

Node.js

from

livekit

.

plugins

import

openai

session

=

AgentSession

(

llm

=

openai

.

LLM

.

with_fireworks

(

model

=

"accounts/fireworks/models/llama-v3p3-70b-instruct"

,

)

,

# ... tts, stt, vad, turn_detection, etc.

)

import

*

as

openai

from

'@livekit/agents-plugin-openai'

;

const

session

=

new

voice

.

AgentSession

(

{

llm

:

openai

.

LLM

.

withFireworks

(

{

model

:

"accounts/fireworks/models/llama-v3p3-70b-instruct"

,

}

)

,

// ... tts, stt, vad, turn_detection, etc.

}

)

;

Parameters

This section describes some of the available parameters. For a complete reference of all available parameters, see the plugin reference links in the

Additional resources

section.

model

str

Optional

Default:

accounts/fireworks/models/llama-v3p3-70b-instruct

#

Model to use for inference. To learn more, see

supported models

.

temperature

float

Optional

Default:

1.0

#

Controls the randomness of the model's output. Higher values, for example 0.8, make the output more random, while lower values, for example 0.2, make it more focused and deterministic.

Valid values are between

0

and

1.5

.

parallel_tool_calls

bool

Optional

#

Controls whether the model can make multiple tool calls in parallel. When enabled, the model can make multiple tool calls simultaneously, which can improve performance for complex tasks.

tool_choice

ToolChoice | Literal['auto', 'required', 'none']

Optional

Default:

auto

#

Controls how the model uses tools. Set to 'auto' to let the model decide, 'required' to force tool usage, or 'none' to disable tool usage.

Additional resources

The following links provide more information about the Fireworks AI LLM integration.

Python plugin

Reference

GitHub

PyPI

Node.js plugin

Reference

GitHub

NPM

Fireworks AI docs

Fireworks AI API documentation.

Voice AI quickstart

Get started with LiveKit Agents and Fireworks AI.

On this page

Overview

Usage

Parameters

Additional resources