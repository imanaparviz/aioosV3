================================================================================
LiveKit Documentation
================================================================================
URL: https://docs.livekit.io/agents/models/llm/plugins/anthropic/
Title: 
Crawled: 2025-11-01 21:22:04
================================================================================

On this page

Overview

Quick reference

Installation

Authentication

Usage

Parameters

Additional resources

Copy page

See more page options

Available in

Python

Overview

This plugin allows you to use the the

Claude API

as a LLM provider for your voice agents.

Quick reference

This section includes a basic usage example and some reference material. For links to more detailed documentation, see

Additional resources

.

Installation

Install the plugin from PyPI:

uv

add

"livekit-agents[anthropic]~=1.2"

Authentication

The Anthropic plugin requires an

Anthropic API key

.

Set

ANTHROPIC_API_KEY

in your

.env

file.

Usage

Use Claude within an

AgentSession

or as a standalone LLM service. For example,

you can use this LLM in the

Voice AI quickstart

.

from

livekit

.

plugins

import

anthropic

session

=

AgentSession

(

llm

=

anthropic

.

LLM

(

model

=

"claude-3-5-sonnet-20241022"

,

temperature

=

0.8

,

)

,

# ... tts, stt, vad, turn_detection, etc.

)

Parameters

This section describes some of the available parameters. See the

plugin reference

for a complete list of all available parameters.

model

str | ChatModels

Optional

Default:

claude-3-5-sonnet-20241022

#

Model to use. For a full list of available models, see the

Model options

.

max_tokens

int

Optional

#

The maximum number of tokens to generate before stopping. To learn more, see the

Anthropic API reference

.

temperature

float

Optional

Default:

1

#

Controls the randomness of the model's output. Higher values, for example 0.8, make the output more random, while lower values, for example 0.2, make it more focused and deterministic.

Valid values are between

0

and

1

. To learn more, see the

Anthropic API reference

.

parallel_tool_calls

bool

Optional

#

Controls whether the model can make multiple tool calls in parallel. When enabled, the model can make multiple tool calls simultaneously, which can improve performance for complex tasks.

tool_choice

ToolChoice | Literal['auto', 'required', 'none']

Optional

Default:

auto

#

Controls how the model uses tools. Set to 'auto' to let the model decide, 'required' to force tool usage, or 'none' to disable tool usage.

Additional resources

The following links provide more information about the Anthropic LLM plugin.

Python package

The

livekit-plugins-anthropic

package on PyPI.

Plugin reference

Reference for the Anthropic LLM plugin.

GitHub repo

View the source or contribute to the LiveKit Anthropic LLM plugin.

Anthropic docs

Anthropic Claude docs.

Voice AI quickstart

Get started with LiveKit Agents and Anthropic.

On this page

Overview

Quick reference

Installation

Authentication

Usage

Parameters

Additional resources